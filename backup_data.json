{
    "users": [
        {
            "email": "keerthanat190@gmail.com",
            "name": "Keerthana",
            "hashed_password": "$2b$12$wZT1LcWYSLuzqrUGXRDuhOFMgT1pf2dNBKC2gvkR65eG7ZDULDbIu",
            "last_view": 1723468038,
            "dice_password": "Keers@123"
        },
        {
            "email": "sample1test.it2@gmail.com",
            "name": "Sarkeshwar",
            "hashed_password": "$2b$12$JKU436LqQa7SAmTIKAJvkOJV7pHIBz3eYcl6Eurlhxz2YUIVZeRtq",
            "last_view": 1723644322,
            "dice_password": "Qwerty@213"
        },
        {
            "email": "sandhyasamudrala24@gmail.com",
            "name": "Sandhya",
            "hashed_password": "$2b$12$CXY6MGEZ4/5YPd3.w6LD2edV8PoXzqo1Rl1aJ9vxGKRBWvwaV1vtG",
            "last_view": 1723647942,
            "dice_password": "Thankyou$7404"
        },
        {
            "email": "utsav28.devops@gmail.com",
            "name": "Utsav",
            "hashed_password": "$2b$12$CjG7BbCUuees8zTLSP2Kx.RnTiL.5sxf/GhIiOF1gO.y1SwrdAX3e",
            "last_view": 1723736335,
            "dice_password": "Application@123z"
        }
    ],
    "allData": [
        {
            "id": "011d0a46-1031-4bc8-bf2c-f0f5d2251f57",
            "title": "Senior Full Stack Engineer",
            "location": "Westlake, Texas, USA",
            "company": "Pyramid Consulting, Inc.",
            "description": "Immediate need for a talented \n \nSenior Full Stack Engineer \n \n. This is a \n \n06+months contract \n \nopportunity with long-term potential and is located in \n \nWestlake, TX (Hybrid) \n \n. Please review the job description below and contact me ASAP if you are interested. \n \nJob ID:23-09412 \n \nPay Range:$75/hour.  Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location). \n \nKey Requirements and Technology Experience: \n \nDemonstrable experience with REST API Design & Development using Java or NodeJS Proven experience working in a Cloud environment using AWS, Azure, Google etc. \n \nDemonstrable experience with any major JavaScript framework (Angular, React etc.) \n \nStrong Experience with Automation Tools/Frameworks (Junit, Cucumber, Mocha, Selenium etc.) \n \nProven experience with DevOps, CI/CD using tools like Jenkins, uDeploy, Cloud Formation etc. \n \nKnowledge of architecture and design patterns to build highly scalable and resilient systems using frameworks like Hystrix, RxJava, Akka etc. \n \nStrong intellectual curiosity and willingness to explore new technology stacks \n \nDemonstrable experience with REST API Design & Development using Java or NodeJS \n \nProven experience working in a Cloud environment using AWS, Azure, Google etc. \n \nDemonstrable experience with any major JavaScript framework (Angular, React etc. \n \nOur client is a leading \n \nE-commerce Industry \n \n, and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration. \n \nPyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n",
            "dateupdated": 1723662810
        },
        {
            "id": "034ee51f-e4a4-49ed-b7a4-5994fa7ce1a9",
            "title": "Scrum Master",
            "location": "Richmond, Virginia, USA",
            "company": "Datasoft Technologies, Inc.",
            "description": "Scrum Master \nHybrid \nAbout the Job \nDuration: 12 Months Contract (possibility of extension) \n \nLocation: Hybrid- Richmond, VA \n \nPay rate: Hourly, depending on experience \n \nJob ID: 744365 \n \nResponsibilities: \nDrives consistent project delivery through the entire project lifecycle, including: project plans, release plans, resource allocation, and management of project risks, scope, schedule, and delivery of value. \n \nCoordinates Agile Ceremonies such as Sprint Planning, Daily Standups, Retrospectives, Sprint Demos, Story Refinement, and Release Planning. \n \nTracks and communicates project's progress from a schedule, cost, and risk perspective to the project team, stakeholders, and management. \n \nEstablishes an environment where the teams can be effective and helps removing obstacles. \n \nProtects the team from outside interruptions and distractions. \n \nEnsures a good relationship between the team and product owner as well as others outside the team. \n \nTracks and reports team velocity and other project metrics. \n \nPromotes continuous improvement and helps teams to increase productivity. \n \nHelps Product Owner and team with Product backlog management. \n \nAdheres to Client and VITA project management practices as defined. \n \nAdditional responsibilities as assigned. \n \nCommunicate timelines and expectations to technical and business staff. \n \nCollaborate with stakeholders to understand project requirements and support data management needs. \n \nEnsure data is collected, stored, and processed securely and in compliance with all applicable regulations. \n \nAnalyze data and provide insights to support decision-making by project management teams. \n \nProvide training and support for end-users to ensure the platform is used effectively. \n \nDemonstrable capability and experience in planning, implementing and maintenance of local master data systems and processes across business units and functions. \n \nUnderstanding of data and leveraging it to deliver business value. Ability to discuss requirements with data teams \n \nExperience in data governance concepts, and data governance implementations. \n \nAbility to use agile approach and methodology to drive master data governance processes. \n \nEnsure documentation of requirements and uses cases, facilitate design workshops for assigned project. \n \nEnsure definition of test objectives, designed test plans and test cases for assigned project. \n \nProvide the management of project milestones and deliverables for on-time and on-budget delivery. \n \nDefine, measure, and clearly communicate progress with metrics \n \nQualifications: \nSolid understanding of software development life cycle models as well as expert knowledge of Agile project management principles and practices. \n \nExperience managing cloud-based solutions for data management and analytics. \n \nAbility to work with customers, understand their business practices and manage their expectations. \n \nAbility to set clear performance standards and hold team members accountable, while keeping team engaged and on track. \n \nAbility to help Product Owners to create and prioritize Product Backlog. \n \nStrong interpersonal skills including mentoring, coaching, collaborating, and team building. \n \nStrong analytical, organizational and decision-making skills. \n \nAbility to analyze and document business and system processes. \n \nAbility to balance the competing demands for quality, scope, schedule, and cost. \n \nWell-versed with Scrum and Kanban Agile methodologies. \n \nPMP and CSM Certifications required. \n \nSAFe Certification preferred. \n \nExperience with SAFe framework is a plus. \n \nPreferred: \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nExcellent analytical, problem-solving, and communication skills. \n \nKnowledge of transportation data and project management with transportation data is a plus. \n \nExperience in IT Infrastructure delivery(networking, physical plant, vendor management, site provisioning) is preferred. \n \nExperience managing large, multi-stream projects. \n \nPMP or Qualified under Commonwealth of Virginia Qualification Standards for IT Project Managers for Category 4Projects. \n \nMicrosoft Office products (Word, Excel, Access, Outlook, Visio, PowerPoint, Project Server) \n \nSpecial Instructions to Applicants: \n \nThis position requires a fingerprint-based background check. \n \nAbout our Company \n \nDataSoft Technologies is a highly recognized provider of professional IT Consulting services in the US. Founded in 1994, DataSoft Technologies, Inc. provides staff augmentation services for Information Technology and Automotive Services. Our team member benefits include: \nPaid Holidays/Paid Time Off (PTO) \n \nMedical/Dental Insurance \n \nVision Insurance \n \nShort Term/Long Term Disability \n \nLife Insurance \n \n401 (K) \n",
            "dateupdated": 1723647892
        },
        {
            "id": "03b49513-87c9-4723-8382-7e9b6fe9b4e9",
            "title": "WebSphere Admin",
            "location": "Austin, Texas, USA",
            "company": "Navtech, LLC",
            "description": "Role WebSphere Admin \n \nLocation Austin TX REMOTE \n \nLocal to Austin \n \nDuration 12 months \n \nThe role includes being a member of the team that is the focal point for all Middleware activities between TIERS Operations management and Social Services Applications \n \nT \n \nhe role also provides the coordination for all TIERS Releases and Maintenance schedules with respect to Middleware servers and the applications that those server host \n \nWhen issues arise within the TIERS operational ecosystem, the role asses  problems, communicates up to management, and leads the effort of all required fixes. From an architecture standpoint, the role will advise on any technical implementation, schedules, automation, and division of labor within the Middleware Team \n \nThe role performs work related to supporting the core TIERS applications on-premise and those which will be migrated and hosted on AWS Cloud Services. The role works under minimal supervision \n \nwith extensive latitude for the use of initiative and independent judgment. The role collaborates across teams under the direction of the Director of TIERS Operations. \n \nExperience With Install, deploy, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines and tuning large complex Java based web applications in a Service Oriented Architecture \n \nExperience troubleshooting large complex Java based web applications in a Service Oriented Architecture Knowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model \n \nExperience creating pipelines in Jenkins to automate WebSphere Application Server configurations and creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments \n \nExperience with different scripting methodologies - UNIX, Jython, YAML, JSON and Java and all phases of the SDLC (Systems Development Life Cycle). Use of Application Performance Management tools such as DynaTrace and Splunk \n \nsshyam at navtechconsulting com \n",
            "dateupdated": 1723644938
        },
        {
            "id": "083d0cbf-ddb9-44d1-83e2-4fee136637f4",
            "title": "Sr Websphere Administrator(Local To Austin)",
            "location": "Remote",
            "company": "Nextgen Information Services",
            "description": "Job Description \n \nLevel Description \n \n4-7 years of experience in the field or in a related area. Familiar with standard concepts, practices, and procedures within a particular field. Relies on limited experience and judgment to plan and accomplish goals. A certain degree of creativity and latitude is required. Works under limited supervision with considerable latitude for the use of initiative and independent judgment. \n \nJob Description \n \nUnderstands business objectives and problems, identifies alternative solutions, performs studies and cost/benefit analysis of alternatives. Analyzes user requirements, procedures, and problems to automate processing or to improve existing computer system: Confers with personnel of organizational units involved to analyze current operational procedures, identify problems, and learn specific input and output requirements, such as forms of data input, how data is to be; summarized, and formats for reports. Writes detailed description of user needs, program functions, and steps required to develop or modify computer program. Reviews computer system capabilities, specifications, and scheduling limitations to determine if requested program or program change is possible within existing system. \n \nAdditional job details and special considerations \n \nThe role includes being a member of the team that is the focal point for all Middleware activities between TIERS Operations management and Social Services Applications. The role also provides the coordination for all TIERS Releases and Maintenance schedules with respect to Middleware servers and the applications that those server host. When issues arise within the TIERS operational ecosystem, the role asses  problems, communicates up to management, and leads the effort of all required fixes. From an architecture standpoint, the role will advise on any technical implementation, schedules, automation, and division of labor within the Middleware Team. The role performs work related to supporting the core TIERS applications on-premise and those which will be migrated and hosted on AWS Cloud Services. The role works under minimal supervision with extensive latitude for the use of initiative and independent judgment. The role collaborates across teams under the direction of the Director of TIERS Operations. \n \nCANDIDATE SKILLS AND QUALIFICATIONS \n \nMinimum Requirements: \n \nCandidates that do not meet or exceed the \n \nminimum \n \nstated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity. \n \nYears \n \nRequired/Preferred \n \nExperience \n \n5 \n \nRequired \n \nInstall, deploy, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines. \n \n5 \n \nRequired \n \nExperience tuning large complex Java based web applications in a Service Oriented Architecture. \n \n5 \n \nRequired \n \nExperience troubleshooting large complex Java based web applications in a Service Oriented Architecture. \n \n5 \n \nRequired \n \nKnowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model. \n \n4 \n \nRequired \n \nExperience creating pipelines in Jenkins to automate WebSphere Application Server configurations. \n \n4 \n \nRequired \n \nExperience creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments. \n \n4 \n \nRequired \n \nExperience with different scripting methodologies - UNIX, Jython, YAML, JSON \n \n4 \n \nRequired \n \nKnowledgeable of Java and all phases of the SDLC (Systems Development Life Cycle). \n \n4 \n \nRequired \n \nUse of Application Performance Management tools such as DynaTrace and Splunk \n \n3 \n \nPreferred \n \nExperience with IBM Business Automation Workflow \n \n2 \n \nPreferred \n \nExperience with IBM Operational Decision Manager \n \n1 \n \nPreferred \n \nExperience with IBM DataPower \n \n1 \n \nPreferred \n \nExperience with Adobe Experience Manager \n \n1 \n \nPreferred \n \nExperience with AWS solution architecture and management \n",
            "dateupdated": 1723653784
        },
        {
            "id": "11533835-9abe-47f3-be24-aa8c79eb898e",
            "title": "Business Intelligence (Advanced Analytics Developer)",
            "location": "San Francisco, California, USA",
            "company": "Stellent IT LLC",
            "description": "Job Title:-IT Business Intelligence (Advanced Analytics Developer) \n \nLocation:- San Francisco, California Onsite \n \nContract \n \nJob Description: \n \nProvides development leadership and expertise for advanced BI analysis and analytics. \n \nGuides and moves forward an advanced BI/Data Mart system providing sophisticated and measurable business benefits. \n \nDrives data, ETL and system architecture and development. \n \nOwns the advanced analytics data environment to ensure that the data refresh from various sources, to facilitate research, is happening at regular intervals. \n \nSupports a group of multi-disciplinary data professionals and analysts. \n \nDrives development (coding using PL/SQL, Perl or any other scripting language, ad-hoc queries using SQL). \n \nEnsures that the data infrastructure can scale to meet defined performance, load, and functional objectives Effectively manages the execution of parallel projects of varying scope and duration. \n \nResponsible for all database objects including tables, indices, triggers, views, sequences, packages, and procedures. \n \nWorks with Systems and Database Administration for infrastructure needs related to support, storage, backups, monitoring, performance bottlenecks. \n \nParticipates with applications development and quality assurance in the management of application releases. \n \nAdvises senior management on \"best practices\" concerning web analytics, data warehousing, data architecture, and data development. \n \nWorks with business intelligence and other source system owners to build data refresh plan for research environment. \n \nOwns web click stream data collection and supports product managers to implement best practices for data definition. \n \nSupports project management and documentation needs of the group. \n \nSkill Set: \n \nExperience with Oracle 8i, 9i and 10g including PL/SQL, SQL loader, external tables, partitioning and performance tuning. \n \nStrong knowledge of Oracle data structures, data dictionary, and RDBMS structures. Experience as data architect and/or DW/BI architecture. \n \nExperience in database design and administration, strong in performance tuning, software installation, scripting, PL/SQL coding, backup & recovery process. \n \nAt least 2 medium to large scale DW/BI project implementation experience. \n \nExperience working with DW/BI environment to be able understand the concepts of STAR, data cleansing, transformation and aggregations. \n \n4+ years, current, development experience and inclination towards development. \n \n1+ years' experience with web analytics products like web trends, NetTracker, Omniture etc.. \n \nExperience working in an environment that has come across customer integration issues or has addressed it using MDM. \n \nAbility to express business and technical concepts clearly and concisely both verbally and in writing. \n \nAggressive approach to staying current with developments within the internet world, related web analytics & data management. \n \nExperience working in a team-oriented, collaborative environment. \n \nGood to Have Skills: \n \nExperience working with various business applications like campaign management, CRM, ERP. \n \nExperience with Java scripts or any other web front end scripting. \n \nExperience with column-oriented database solutions such as HBase or Infobright. \n \nExperience with Hadoop. \n \nOracle database administration experience. \n \nExperience working with various data reporting tools like Business Objects, MicroStrategy, COGNOS. \n \nExperience working with ETL tools like Data Stage, Informatica, Hummingbird. \n \nExperience working with meta data management. Experience with SAS. \n \nAdditional Skills: \n \nSenior Azure Cloud Data Engineer with a strong background in Power BI, Azure Data Factory (ADF) and SQL. The candidate will be responsible for designing, developing, and implementing data integration solutions in the Azure cloud environment. Design and implement ETL processes using Azure Data Factory to integrate data from various sources into PostgreSQL / Azure SQL Database. Develop and maintain data models in Azure SQL Database to support reporting and analytics requirements. Create interactive and visually appealing dashboards and reports using Power BI. Experience in the retail domain will be an additional advantage. Strong analytical and problem-solving skills, excellent communication and collaboration skills. Have to collaborate with cross-functional teams to deliver high-quality data solutions that drive business intelligence and analytics initiatives. \n \nTechnical Skills: \n \nPower BI, DAX \n \nAzure Cloud \n \nAzure Data Factory (ADF) \n \nAzure SQL, PostgreSQL \n \nVisual Studio \n \nTest Driven Development \n \nPython, PowerShell \n \nGitHub, Github Actions, JIRA \n \nTools : IntelliJ, Splunk, New Relic \n \nSr. IT Technical Recruiter \n \nPhone:- \n \nEmail: \n \nGtalk: \n \nLinkedin id:- \n",
            "dateupdated": 1723735898
        },
        {
            "id": "11de32c9-ed18-4b3f-88d9-0b2b918dad1e",
            "title": "Site Reliability Engineer",
            "location": "Remote or US",
            "company": "Galaxy i Technologies, Inc.",
            "description": "Hi, Everyone \n \n******W2 CONTRACT ONLY******* \n \n100% Closure & Long-term Project \n \nALL VISA TYPES ARE ACCEPTABLE \n \nJob Title: Site Reliability Engineer \n \nLocations: 100% REMOTE \n \nJob Description: \n \n3 years' experience in below technologies: \n \nNew Relic Platform with APM, Synthetic, and Browser experience \n \nNew Relic Query Language (NRQL) \n \nPython \n \nDetailed JD: \n \nSite Reliability Engineer Responsibilities \n \nWork closely with SBT team members to identify monitoring needs \n \nMonitor the technical performance of internal systems \n \nWork with Monitoring Engineer(s), Scrum Masters and Solution Architects to identify and \n \nenhance technical solutions to satisfy functional and non-functional requirements while ensuring \n \nquality and timely delivery \n \nProvide support for application deployment activities, as needed. \n \nAdheres to Sunnova release management standards and practices, including using \n \nAgile methodology and scrum teams \n \nPerform any other duties as assigned. \n \nTechnical Requirements \n \nVery Proficient in New Relic platform (APM, Synthetic, and Browser Monitors) \n \nDevelop code or scripts with Python, Node.js, PowerShell, and c#.net \n \nWell versed with Visual Studio Code IDE \n \nNew Relic NRQL proficiency is a must \n \nNew Relic NerdGrap development \n \nAWS CloudFormation, and Terraform \n \nAWS ECS, Kubernetes, and demand based Auto Scaling \n \nMinimum Requirements \n \nBachelor's degree in Computer Science, or other technical degree, or equivalent \n \nexperience (8 years) in the IT Industry. \n \nCandidate must possess 5 plus years of relevant IT experience as a Site Reliability \n \nEngineer \n \nMinimum of 3 years of experience with New Relic \n \nGood interpersonal, verbal and written communication skills. \n \n3 years of experience in cloud-based technologies like AWS (preferred), Azure, or \n \nGoogle are acceptable \n \nFirm understanding of serverless computing including AWS Lambda, ECS Clusters, and \n \nS3 \n \nExperience with Heroku, Mulesoft, and Salesforce platforms \n \nAbility to foster new ideas and concepts for observability and performance of systems in \n \nthe overall ecosystem \n \nSchedule needs to be flexible to the needs of the business and will require weekend or \n \nevening availability to facilitate software releases and critical incidents. \n \nAdditional Knowledge, Skills and Abilities \n \nNew Relic Full Stack Observability Practitioner Certification is strongly desired \n \nStrong written and verbal communication skills \n \nExcellent problem solving & critical thinking skills \n \nExperience with data analysis and setting and tracking metrics \n \nWorking Conditions \n \nOpen office environment \n \nSchedule needs to be flexible to the needs of the business and may require weekend or \n \nevening availability to support production applications \nNOTE: Please share Updated Resumes to divya at galaxyitech dot com or call me Four-Eight-Zero Four-Zero-Seven Six-Nine-One-Eight \n",
            "dateupdated": 1723648173
        },
        {
            "id": "14b08336-0376-4942-bf05-5d132227cfca",
            "title": "Business Intelligence Architect",
            "location": "Boston, Massachusetts, USA",
            "company": "Mindlance",
            "description": "Position Details: \n \nTitle: Senior BI Architect \n \nTerm: 12 Months (with possible extension) \n \nLocation: Boston, MA 02116 \n \nMode: Hybrid (2days in a week onsite) \n \nPosition Summary: \n \nClient is seeking a contract Senior BI Architect to design, develop, and implement our organization s BI strategy for a health data warehouse project for approximately fifteen (15) months. The project team, consisting of temporary and permanent staff, will rebuild an existing data warehouse using new ETL, BI, and database platforms with an eye towards cost containment and improved technical performance. This key role will work with Senior Management and our Data Analysts to identify business goals and objectives and then design and implement a BI solution that meets those goals. \n \nThe Senior BI Architect will also research and recommend an enterprise-level BI tool, work with business teams to gain consensus on that tool, and help train users on how to use it. \n \nResponsibilities: \n \nTo be considered for this position, the candidate must demonstrate specific experience in: \n \nLeading the design and implementation of semantic layers on top of Snowflake and/or Postgres, in an MS Azure environment. \n \nAnalyzing business needs and recommending an appropriate BI tool that will provide the required performance for Data Analysts. \n \nLeading a business wide BI solution implementation. \n \nAssisting clients in a consulting capacity, with implementing and using BI tools and technologies. \n \nTroubleshooting BI issues and problems and providing support to BI users. \n \nDeveloping documentation and training materials as required to support the BI users. \n \nWorking with healthcare data, preferably in the payer space. \n \nCloud technologies, preferably MS Azure and Snowflake \n \nQualifications: \n \nThe ideal candidate will have: \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years experience working in the BI space at an Architect level. \n \n5+ years experience implementing BI solutions in Azure cloud environments. \n \n2+ years experience working with Snowflake and Postgres databases. \n \nDemonstrable experience in evaluating business needs and implementing BI strategies to meet those needs. \n \nA combination of technical expertise and leadership skills to effectively navigate the complexities supporting multiple in-house business units. \n \nMindlance is an Equal Opportunity Employer and does not discriminate in employment on the basis of Minority/ Gender/ Disability/ Religion/ LGBTQI/ Age/ Veterans.\" \n",
            "dateupdated": 1723664548
        },
        {
            "id": "1547b443-f6d0-4f74-8e70-76a709e2626c",
            "title": "AWS Devops Engineer",
            "location": "Reston, Virginia, USA",
            "company": "HL Solutions LLC",
            "description": "Title: Devops Consultant \n \nLocation: \n \nReston, VA \n \nDuration: Contract \n \nSkills Needed: \n \nTerraform coding, Python coding, Gitlab, Module Development. \n \nJob Description: \n \n12 years of experience in software development and DevOps engineering \n \nExperience with architecting, designing, and automating cloud-native CI/CD workflows and tools, using Jenkins, GitLab, or similar tools. \n \nExperience in architecting modern web, microservices and cloud-native distributed systems based on containers, Kubernetes, and AWS cloud. \n \nExperience with architecting and automating cloud-native technologies, deploying applications and provisioning infrastructure. \n \nExperience with Infrastructure as Code, using Cloud Formation, Terraform or similar tools. \n \nExperience with end-to-end software development lifecycle and delivery using Agile practices. \n \nExperience with supporting technical teams implementing DevOps platform to accelerate software delivery supporting techniques such as Trunk Based Development, Feature Toggles, Blue-Green Deployment, 12 Factors and others. \n \nProgramming skills in multiple languages such as Groovy, Python, Ruby, Go, Java or similar \n \nUnderstanding of Linux, networking, and internet principles \n \nExcellent oral and written communication skills. \n",
            "dateupdated": 1723670185
        },
        {
            "id": "16208dd2-f751-48a4-9ae9-91a51084c8c8",
            "title": "Scrum Master",
            "location": "Richmond, Virginia, USA",
            "company": "Caresoft",
            "description": "Title: Scrum Master \n \nLocation: Richmond, VA (HYBRID) \n \nDuration: Long-term \n \nSkills: \n \nExperience managing cloud-based solutions for data management and analytics. \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nKnowledge of transportation data and project management with transportation data is a plus. \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nTechnical Business Analyst understanding of data integration and data project. \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nExperience in both Agile and Waterfall project management & Agile Scrum Master. \n",
            "dateupdated": 1723663176
        },
        {
            "id": "1c53ca25-a319-4ea5-9d53-5aae7bc909c8",
            "title": "Sr. Web Application Developer",
            "location": "Columbus, Ohio, USA",
            "company": "Kollasoft Inc.",
            "description": "Job Title: \n \nSr. Web Application Developer \n \nLocation: Columbus, OH(Hybrid) \n \nDuration: Long Term Position \n \nDescription: \n \nMandatory Requirements: \n \n4 years college degree or equivalent technical study or above \n \n10 years proven work experience as a Front-end developer: \n \nDesigning and developing the web applications robust and scalable web applications from concept to production using Angular and Web Forms/MVC 5.0 framework in .NET& ASP.NET environment with proficiency in C#, Java Script, CSS, and jQuery \n \nImplementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools   Entity Framework; experience in browser testing and debugging \n \n7 years Hands on experience with markup languages,Angular 8 and above, Bootstrap \n \n7 years Develop and manage SQL databases by planning,developing, and maintaining the databases using Oracle or Microsoft SQL Server \n \n3 years Azure DevOp experience \n \n5 years hands-on experience using Python2.7 & above \n \nExperience in Integrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nMust have hands-on experience in: \n \ndesigning and developing the web applications robust and scalable web applications from concept to production using Angular and MVC (5.0) framework in .NET &ASP.NET environment with proficiency in C# and Angular \n \nimplementation ofinteractive UI withAsp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8or better, and Bootstrap; Usage of ORM tools   Entity Framework \n \nconverting the ASP.NET Web Forms to Angular Component sand reuse the components in various Modules \n \nAngular CLI for creating components, Services, pipes, Directives \n \ncreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \nversion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \nbuilding process using Jenkins for Continuous Integration and version control \n \ncreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \nbuilding and maintaining server-side applications and APIs using languages such as Node.js,Python, or Ruby on Rails \n \nintegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nimplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \ndesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3,and JavaScript frameworks like React, Angular, or Vue.js \n \ndesigning,testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \n \noptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \n \nimplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nexperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nThe ideal candidate would have \n \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nfamiliarity with Micro services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nexperience with continuous integration and deployment (CI/CD) pipelines using Azure Dev Ops Experience (minimum 3 years) \n \nskills to leverage SQL database structure and optimize data storage and retrieval processes for efficient complaint management \n \nbe able to create Data Warehouse functionality by defining and capturing metadata and rules associated with ETL processes in various applications \n \nability to do the security scan the applications and fix the software vulnerabilities within the system \n \nDesired Skills: \n \nExcellent analytical skills, attention to detail, and problem-solving skills. \n \nProven ability to handle multiple tasks and projects simultaneously. \n \nGood communication skills with both technical and non-technical clients \n \nAbility to work with project team member when the requirement is not clear. \n \nMust possess excellent written and oral communication skills. \n \nStrong experience in creating good solutions w/o mature,detailed, codified business requirements. \n \nWorking experience in delivering expected results in unstructured environments. \n \nWorks productively and effectively independently without significant management oversight. \n",
            "dateupdated": 1723672652
        },
        {
            "id": "25d7aa8d-ad11-400b-b052-629adc63a696",
            "title": "AI-ML Platform Tech Lead & Architect",
            "location": "Charlotte, North Carolina, USA",
            "company": "AxiusTek",
            "description": "Role : AI-ML Platform Tech Lead & Architect \n \nLocation: Concord, CA/SFO/ Charlotte NC \n \nDuration : Long term contract \n \nKey Responsibilities: \n \nDesign and architect scalable AI platforms to develop, deploy AI solutions leveraging ML techniques and Deep Learning Techniques. \n \nDrive Joint Architecture Design to collaborating with business stakeholders, data scientists, engineering teams, product, and other key partners to gather functional, non-functional requirements for solving AI use case on the AI Platform \n \nEvaluate emerging technologies and tools in AI area and do fitment analysis to the Enterprise AI Platform and capabilities strategy. \n \nDefine and implement AI/ML architecture best practices, frameworks, and standards. \n \nLead AI/ML infrastructure setup, including cloud services selection, data pipelines, and model deployment. \n \nEnsure robustness, reliability, and scalability of AI/ML solutions in production environments. \n \nDesign and implement data governance, security, and compliance measures for AI/ML platforms. \n \nOptimize AI/ML workflows for performance, cost efficiency, and resource utilization. \n \nProvide technical leadership and mentorship to AI/ML development teams. \n \nCommunicate AI/ML architecture decisions and strategies to stakeholders and executives. \n \nKey Requirements: \n \nProven experience as an AI/ML platform architect \n \nDeep understanding of ML algorithms, Deep Learning architecture, models, and frameworks (e.g., Tensor Flow, PyTorch, Scikit-Learn). \n \nExpertise in cloud platforms (e.g., Google Cloud Platform, Azure) and their AI services. \n \nStrong knowledge of Model development life cycle, software engineering principles, data engineering principles \n \nExperience with containerization and orchestration tools on prem and cloud (e.g., AKS, GKE, Open Shift Container Platform, Docker, Kubernetes) for deploying AI/ML models. \n \nAbility to design and optimize distributed computing systems for AI/ML workloads. \n \nFamiliarity with DevOps practices, CI/CD pipelines, and automation tools in AI-ML contexts. \n \nExcellent problem-solving skills and ability to address complex technical challenges. \n \nEffective communication skills to collaborate with cross-functional teams and stakeholders. \n",
            "dateupdated": 1723648776
        },
        {
            "id": "25f00191-ee8e-4c2f-8f7e-010d0af841d8",
            "title": "AWS Application Developer",
            "location": "Atlanta, Georgia, USA",
            "company": "American Technology Consulting LLC",
            "description": "Title - SOFTWARE APPLICATION DEVELOPER (AWS cloud) \n \nLocation - Atlanta GA (Hybrid) \n \nCandidates must have experience developing software applications in an  AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nProject Overview: \n \nThe GTA CJEP project is a modernization of the Criminal Justice Exchange Program that shares data between different agencies, counties, cities, etc.  This project will take the current SoftwareAG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API s and web services will be leveraged to facilitate this modernized solution as much as possible. \n \nPosition Overview: \n \nAs an AWS Cloud Developer at GTA you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services,custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n",
            "dateupdated": 1723735469
        },
        {
            "id": "2635aeeb-28ba-46ca-996d-e492c842a17f",
            "title": "Senior Infrastructure Engineer",
            "location": "Richmond, Virginia, USA",
            "company": "Cynet Systems",
            "description": "We are looking for \n \nSenior Infrastructure Engineer \n \nfor our client in \n \nRichmond, VA \n \nJob Title: Senior Infrastructure Engineer \n \nJob Location: Richmond, VA \n \nJob Type: Contract \n \nJob Description: \n \nWe are seeking a highly skilled Senior Infrastructure Engineer with extensive experience managing Windows Server environments in both on-premises and cloud-based settings. \n \nThe ideal candidate will have a proven track record in patching, backups, migrations, and implementing Active Directory. \n \nThey should be adept at supporting a range of applications including Java, .Net, Oracle, Microsoft Dynamics, and various Warehouse technologies. \n \nThe role demands both server-level support and custom production application support expertise. \n \nThe candidate should be familiar with security tools such as Tenable and have experience with SCCM and automated patch management. \n \nProficiency in server security configurations, including end-point protection, is essential. \n \nStrong networking knowledge and in-depth understanding of OSI layer functionality and protocols are required. \n \nExperience with disaster recovery (DR) processes is crucial. \n \nPreferred qualifications include certifications as a Systems Engineer and Network Engineer. \n \nRequirements: \n \nExperience working with Windows Server in hybrid environments (on-premises and cloud). \n \nExperience providing guidance on disaster recovery/uptime management, best practices for infrastructure stability, etc. \n \nExperience performing regular patching and updates to ensure system security and stability. \n \nExperience overseeing backup operations and recovery processes in mission-critical environments. \n \nExperience planning & executing server migrations, including moving workloads from on-premises to the cloud. \n \nComfortable working in an environment that utilizes multiple. frameworks/technologies, including .NET, Java, SQL, Oracle, Microsoft Dynamics. \n \nExperience providing server-level support and troubleshooting issues for production applications. \n \nExperience working with security tools such as Tenable to manage vulnerability remediation, etc. \n \nExperience with tools like SCCM for automated patch management & deployment. \n \nExperience crafting disaster recovery (DR) plans to ensure minimal downtime and prevent data loss. \n \nStrong networking knowledge - including understanding OSI layer functionality and network protocols. \n \nAbility to work with cross-functional teams to address infrastructure needs and support application deployment. \n \nNice to Have: \n \nMicrosoft-focused certifications, such as: Azure Administrator Associate, Windows Server Hybrid Administrator Associate, etc. \n \nNetworking-focused certifications, such as: Network+, CCNA, etc. \n",
            "dateupdated": 1723647144
        },
        {
            "id": "26b5fbbc-b635-422d-a57c-1d04e25b8824",
            "title": "Senior Infrastructure Engineer",
            "location": "Richmond, Virginia, USA",
            "company": "DataStaff, Inc.",
            "description": "DataStaff, Inc. \n \nis seeking a \n \nSenior Infrastructure Engineer \n \nfor a long-term contract opportunity with one of our direct clients in \n \nRichmond, VA \n \n*This position is hybrid, 1-2 days per week will be onsite \n \nJob Description: \n \nOur client is seeking a highly skilled Senior Infrastructure Engineer with extensive experience managing Windows Server environments in both on-premises and cloud-based settings. The ideal candidate will have a proven track record in patching, backups, migrations, and implementing Active Directory. They should be adept at supporting a range of applications including Java, .Net, Oracle, Microsoft Dynamics, and various Warehouse technologies. The role demands both server-level support and custom production application support expertise. \n \nKnowledge, Skills and Abilities: \n \nComfortable working in an environment that utilizes multiple frameworks/technologies, including .NET, Java, SQL, Oracle, Microsoft Dynamics, and more. \n \nAbility to work with cross-functional teams to address infrastructure needs and support application deployment. \n \nSecurity tools such as Tenable and have experience with SCCM and automated patch management. \n \nProficiency in server security configurations, including end-point protection, is essential. \n \nStrong networking knowledge and in-depth understanding of OSI layer functionality and protocols are required. \n \nExperience with disaster recovery (DR) processes is crucial. \n \nMicrosoft-focused certifications, such as: Azure Administrator Associate, Windows Server Hybrid Administrator Associate, etc. (preferred) \n \nNetworking-focused certifications, such as: Network+, CCNA, etc. (preferred) \n \nCertifications as a Systems Engineer and Network Engineer (preferred) \n \nRequired Skills: \n \n6 Years - Experience working with Windows Server in hybrid environments (on-premises and cloud). \n \n6 Years - Experience providing guidance on disaster recovery/uptime management, best practices for infrastructure stability, etc. \n \n6 Years - Experience performing regular patching and updates to ensure system security and stability. \n \n6 Years - Experience overseeing backup operations and recovery processes in mission-critical environments. \n \n6 Years - Experience planning & executing server migrations, including moving workloads from on-premises to the cloud. \n \n6 Years - Experience providing server-level support and troubleshooting issues for production applications. \n \n6 Years - Experience working with security tools such as Tenable to manage vulnerability remediation, etc. \n \n6 Years - Experience with tools like SCCM for automated patch management & deployment. \n \n6 Years - Experience crafting disaster recovery (DR) plans to ensure minimal downtime and prevent data loss. \n \n6 Years - Experience with networking - including understanding OSI layer functionality and network protocols. \n \nThis opportunity is available on a corp-to-corp basis or as a W2 position with a \n \ncompetitive benefits package \n \n. DataStaff, Inc. offers medical, dental, and vision coverage options as well as paid vacation, sick, and holiday leave. As many of our opportunities are long-term, we also have a 401k program available for employees after 6 months. \n",
            "dateupdated": 1723665994
        },
        {
            "id": "2876808e-b585-4d28-b231-b3af40471f34",
            "title": "Cloud Application Developer",
            "location": "Remote",
            "company": "Smksoft",
            "description": "Role: Cloud Application Developer \n \n100% REMOTE \n \nW2 Role \n \nDescription \n \nTo design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies. \n \nRequired: \n \nEstablished track record with Kafka technology, with hands-on production experience and a deep understanding of the Kafka architecture and internals of how it works \n \nDesign, develop, and manage Kafka-based data pipelines \n \nRecent experience with large Event driven financial transactions to external sources (on-prem to cloud) \n \nAdvanced experience and programming knowledge in distributed Java and SpringBoot \n \nPlus: \n \nExperience with both Oracle Cloud Infrastructure and Oracle Integration Cloud \n \nExperience with Azure Cloud, Azure Kubernetes Service, Docker, and Event Hubs \n",
            "dateupdated": 1723670842
        },
        {
            "id": "2d4519ba-5c0b-4b6a-8059-7811c8887f82",
            "title": "Salesforce Developer: IV (Lead)",
            "location": "Minnetonka, Minnesota, USA",
            "company": "Stellent IT LLC",
            "description": "Lead Salesforce Developer: IV \n \nColumbus, OH or Minnetonka, MN (Hybrid Onsite) \n \nC2H on W2 only \n \nJOB DESCRIPTION \n \nThe client's Salesforce Center of Excellence (COE) team is seeking a Technical Lead to participate in development activities spanning multiple Salesforce platforms. The ideal candidate will be able to: \n1. Independently build and unit test components as well as work with Dev/QA team members to resolve code and configuration-based defects. Lead a dev team and provide guidance/mentor as needed. \n2. Provide direction to the dev team to conduct research and document results for new Salesforce capabilities or review exiting platform-related issues. \n3. Lead Proof of concepts with the architects to evaluate and document new designs, integrations, patterns, and practices. \nDuties and Responsibilities: \nProvide leadership and demonstrate proficiency in Core Salesforce capabilities such as: Apex, LWCs, flows, triggers, complex formulas, workflows, and security. \nParticipate in agile practices and ceremonies through scrum team planning sessions, user story refinement, daily status updates, code reviews and provide leadership to team members. \nParticipate in enhancements to DevOps processes (pipelines, monitoring, test automation). \nUnderstanding of enterprise cross-system integration concepts such as processing events and interacting with APIs. \nConduct product/solution evaluations     including Salesforce capabilities and third-party vendor offerings - for domain by creating prototypes/Proof of concepts as a means to elicit clarify and design towards the business goals. \nDesign, document, and develop development patterns and best practices for consumption by COE technical delivery organization. \nMentor technical delivery staff. \nBasic Qualifications: \n \nBachelor's Degree \nMin 4 years of progressively responsible technical and business work experience developing enterprise-level applications which includes Salesforce.com full-stack development experience. \nMin 2-3 years in a scrum team environment \nStrong problem-solving, interpersonal and communication skills (both verbal and written) are primary to the success of this candidate. \nSFDC Data Model knowledge across various cloud/products & strong data modeling experience. \nSubject matter expertise in branching/code merging practices in GIT (or equivalent) repository. \nPreferred Qualifications \n \n: \nSalesforce Certifications such as, but not limited to: Administrator, Platform Developer (1 and 2), Sales Cloud Consultant, Service Cloud Consultant \nSalesforce Financial Services Cloud experience highly preferred \nSalesforce managed package evaluation, deployment, and upgrade experience highly preferred \nExperience with Salesforce CI/CD(Jenkins, Copado, Gearset, etc.) \nExperience with other salesforce products like MuleSoft, Salesforce Marketing Cloud would be a plus \nRegards, \nAyush Sharma \n \nSr. US IT Recruiter \n \n|  Ext:149 \n|  G-talk: \n",
            "dateupdated": 1723648596
        },
        {
            "id": "2e5a8fb5-ae65-42c6-99e1-1237172ffee0",
            "title": "Senior Azure Cloud Data Engineer - Onsite - Locals only",
            "location": "Folsom, California, USA",
            "company": "Serenity Info Tech, Inc.",
            "description": "Hi, \n \nPlease find my direct client job requirement for your consideration. \n \nTitle: Senior Azure Cloud Data Engineer \n \nLocations: Folsom CA \n \nDuration :09 Months \n \nJob Description: \n \nSenior Azure Cloud Data Engineer with a strong background in Power BI, Azure Data Factory (ADF) and SQL. The candidate will be responsible for designing, developing, and implementing data integration solutions in the Azure cloud environment. Design and implement ETL processes using Azure Data Factory to integrate data from various sources into PostgreSQL / Azure SQL Database. Develop and maintain data models in Azure SQL Database to support reporting and analytics requirements. Create interactive and visually appealing dashboards and reports using Power BI. Experience in the retail domain will be an additional advantage. Strong analytical and problem-solving skills, excellent communication and collaboration skills. Have to collaborate with cross-functional teams to deliver high-quality data solutions that drive business intelligence and analytics initiatives. \n \nTechnical Skills: \n \nPower BI, DAX \n \nAzure Cloud \n \nAzure Data Factory (ADF) \n \nAzure SQL, PostgreSQL \n \nVisual Studio \n \nTest Driven Development \n \nPython, PowerShell \n \nGitHub, Github Actions, JIRA \n \nTools : IntelliJ, Splunk, New Relic \n",
            "dateupdated": 1723663858
        },
        {
            "id": "34f99e22-e3c1-475c-8482-e666c40da3a0",
            "title": "AI/ML Engineer (Charotte, NC)",
            "location": "Charlotte, North Carolina, USA",
            "company": "Enexus Global",
            "description": "Title: \n \nAI / ML Engineer \n \nLocation: \n \nCharotte, NC \n5+ years of Python experience \n \n5+ years of big data experience needed (Big Query, Hadoop) \n \n3 years of experience in AIML area (MLOps) \n \n2+ years of experience in developing APIs using Python/FastAPI. \n \n1+ year of Document AI, Agent Builder/Google Cloud Platform search/conversation / Dialogflow     Nice to have \n \nGood to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops) \n \nGood to have Experience in developing of API on Google Cloud Platform/Azure/API Gateways \n \nGood to have 1+year of experience in Vector Database, Model Development would be added benefit. \n",
            "dateupdated": 1723664720
        },
        {
            "id": "38db7778-6caa-4f2a-b4b9-ad775271a903",
            "title": "Data Architect_ Austin, TX (Onsite) _ Contract",
            "location": "Austin, Texas, USA",
            "company": "BURGEON IT SERVICES LLC",
            "description": "Role: Data Architect \n \nLocation: Austin, TX (Onsite) \n \nJob Type: Contract 12 Months \n \nExperience: 13+ Years \n \nPlease share the resume by mail \n \nA Java Backend Engineer who is good at Data Engineering - Probably an Architect \n \nA Data Architect who has strong experience in Rest Services \n \nLooking for a technology architect with below skills. \n \nREST APIs \n \nMonitoring \n \nAPI Automation \n \nBig Data \n \nData Engineering \n \nETL Framework \n \nLoad Testing \n \nMongoDB \n \nNode.js \n \nPython \n \nPreferred Qualifications: \n \nExperience with cloud platforms (AWS, Azure, Google Cloud Platform).Familiarity with containerization technologies (Docker, Kubernetes). \n \nKnowledge of DevOps practices and CI/CD pipelines. \n \nExperience with other databases and data storage technologies. \n \nStrong understanding of security best practices in data management \n",
            "dateupdated": 1723736945
        },
        {
            "id": "3970bc69-4a3c-4694-8c7b-5d2b22967eb5",
            "title": "Urgent-Sr. Front End Developer-Columbus, OH-Hybrid-only local",
            "location": "Remote or Columbus, Ohio, USA",
            "company": "Halcyon Solutions, Inc.",
            "description": "Hello \nGreeting !!! \nWe have an urgent requirement for the below-given role, please revert me if you are available and interested with your updated resume. \nTitle: ( Sr. Web Application Developer) (744708) \nLocation: Columbus, OH-Hybrid \nDuration: long term Contract \nAGE - Sr. Front End Developer (744705) and ( Sr. Web Application Developer) (744708) \nHybrid 2days/week \n \nODA is seeking for an experienced, skilled, motivated senior Full Stack web application developer with specialization in \n \nAPI integration for developing both front-end and back-end components \n \nof ODA web applications. \nMandatory Requirements: \n \n4 years college degree or equivalent technical study or above \n10 years proven work experience as a Front-end developer: \nDesigning and developing the web applications robust and scalable web applications from concept to production using Angular and Web Forms/MVC 5.0 framework in .NET& ASP.NET environment with proficiency in C#, Java Script, CSS, and jQuery \n \nImplementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools     Entity Framework; experience in browser testing and debugging \n \n7 years Hands on experience with markup languages,Angular 8 and above, Bootstrap \n7 years Develop and manage SQL databases by planning,developing, and maintaining the databases using Oracle or Microsoft SQL Server \n3 years Azure DevOp experience \n5 years hands-on experience using Python2.7 & above \nExperience in Integrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \nMust have hands-on experience in: \n \ndesigning and developing the web applications robust and scalable web applications from concept to production using Angular and MVC (5.0) framework in .NET &ASP.NET environment with proficiency in C# and Angular \nimplementation of   interactive UI with   Asp.Net MVC, HTML5,   CSS3, jQuery, JavaScript, Angular 8or better, and Bootstrap; Usage of ORM tools     Entity Framework \nconverting the ASP.NET Web Forms to Angular Component sand reuse the components in various Modules \nAngular CLI for creating components, Services, pipes, Directives \ncreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \nversion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \nbuilding process using Jenkins for Continuous Integration and version control \ncreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \nbuilding and maintaining server-side applications and APIs using languages such as Node.js,Python, or Ruby on Rails \nintegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \nimplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \ndesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3,and JavaScript frameworks like React, Angular, or Vue.js \ndesigning,testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \noptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \nimplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \nexperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \nNaveen Goud, \n \nSenior US IT Recruiter \n \nHalcyon Solutions Inc. \n \nDirect: \n \n+1 \n \nEmail: \n \nDelivering the very best in IT talent and consulting for private, public and federal sector clients since 1992. \n",
            "dateupdated": 1723669257
        },
        {
            "id": "39939c16-673a-4e45-a997-616796ad1f03",
            "title": "SQL DBA - Mostly Remote",
            "location": "Remote",
            "company": "MSYS Inc.",
            "description": "Title: \n \nSQL DBA - Mostly Remote \n \nLocation: \n \nDover, DE, United States \n \nLength: \n \nLong term \n \nRestriction: \n \nW2 or C2C \n \nDescription: \n \nInterview: Online **** Very Long term contract Usually the project goes for 4+ years with this customer *** 37.5 hours per week *** \n \n*** Mostly Remote *** \n \n1 inperson meeting a month in Dover, Delaware \n \n*** Prefers candidates to be in Eastern Time Zone *** \n \nJob Description: \n \nThe candidate will provide expert level guidance in data conversion, data mapping and analysis. The candidate will be responsible for extract, transformation and load (ETL) of data from multiple data sources into a new integrated data system currently being implemented. The candidate will demonstrate expert data cleaning, management and analysis skills. This hybrid remote position requires regular work hours 37.5 hours/week  8:00 am   4:30 pm with occasional flexibility for regularly scheduled meetings (no overtime). This project is expected to run until completion of the database implementation project (currently expected June 30th, 2025). Upon completion of the project and with exemplary work performance, there may be the opportunity to extend the work assignment for other data modernization activities. \n \nEssential Functions: \n \nHighly skilled at data/database conversions including data mapping, extract, transformation and load (ETL) of data following technical specifications documents and in accordance with State of Delaware policies \n \nExperience and knowledge in supporting application system development life cycle \n \nProficiency in developing and maintaining data models, data warehouses, data dictionaries/codebooks and data integration processes \n \nStrong analytical and problem solving skills to identify and resolve data related issues \n \nExpertise in iterative troubleshooting of errors and data cleaning issues \n \nHigh level of accuracy and attention to detail in all data handling activities \n \nKnowledgeable in data analysis and database management techniques \n \nAssist in coordinating software releases \n \nExecution of all responsibilities with little direct supervision of Team Lead \n \nDetermine time estimates and schedule for own work and resolve issues in a timely manner \n \nAbility to manage multiple tasks and projects simultaneously, ensuring deadlines and quality standards are met \n \nCommunicate accurate and useful status updates \n \n1Manage and report time spent on all work activities \n \nExcellent verbal and written communication skills for effective documentation and collaboration with team members \n \nAbility to communicate with both technical and non technical audiences \n \nAnticipate and resolve issues specific to the project and team \n \nJob requirements: \n \n5 or more years of experience in database administration, including at least 2 years at a Database Administrator 2 level or equivalent. \n \nStrong experience in writing and optimizing Structured Query Language (SQL) queries, and using .NET, C#, or other programming languages for data manipulation. \n \nProficiency in SQL Server Integration Services (SSIS) and other Extract, Transform, Load (ETL) tools for data conversion projects \n \nExtensive experience managing and maintaining SQL Server, MySQL, or other database management systems \n \nUnderstanding of data privacy laws and regulations, such as the Health Insurance Portability and Accountability Act (HIPAA) \n \nOne or more of the following: \n \nRelevant certifications such as Microsoft Certified: Azure Data Engineer Associate, Certified Data Management Professional (CDMP), or certifications in specific ETL tools \n \nExperience with cloud data platforms (e.g., Amazon Web Services (AWS), Azure, Google Cloud) \n \nExperience with Agile methodologies or other project management frameworks \n \nKnowledge of the essential functions of public health \n \nKnowledge of public health informatics in including methods of collecting, compiling and presenting health data \n \nKnowledge of public health surveillance including collecting, analyzing and interpreting heath data \n \nKnowledge of public health data modernization including enhancing or replacing legacy data systems \n",
            "dateupdated": 1723655356
        },
        {
            "id": "3c38c4f4-0450-4f58-a00e-29698a5c34be",
            "title": "BI Architect",
            "location": "Boston, Massachusetts, USA",
            "company": "CogniSoft Technologies",
            "description": "Role: BI Architect \n \nLocation: Boston MA-- 2 days onsite in Boston \n \nTop Skills' Details \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years  experience working in the BI space at an Architect level. \n \n5+ years  experience implementing BI solutions in Azure cloud environments. \n \n2+ years  experience working with Snowflake and Postgres databases. \n \nPosition Summary \n \n: \n \nCHIA is seeking a contract Senior BI Architect to design, develop, and implement our organization s BI strategy for a health data warehouse project for approximately fifteen (15) months. The project team, consisting of temporary and permanent staff, will rebuild an existing data warehouse using new ETL, BI, and database platforms with an eye towards cost containment and improved technical performance. This key role will work with Senior Management and our Data Analysts to identify business goals and objectives and then design and implement a BI solution that meets those goals. \n \nThe Senior BI Architect will also research and recommend an enterprise-level BI tool, work with business teams to gain consensus on that tool, and help train users on how to use it. \n \nResponsibilities: \n \nTo be considered for this position, the candidate must demonstrate specific experience in: \n \nLeading the design and implementation of semantic layers on top of Snowflake and/or Postgres, in an MS Azure environment. \n \nAnalyzing business needs and recommending an appropriate BI tool that will provide the required performance for Data Analysts. \n \nLeading a business wide BI solution implementation. \n \nAssisting clients in a consulting capacity, with implementing and using BI tools and technologies. \n \nTroubleshooting BI issues and problems and providing support to BI users. \n \nDeveloping documentation and training materials as required to support the BI users. \n \nWorking with healthcare data, preferably in the payer space. \n \nCloud technologies, preferably MS Azure and Snowflake. \n \nQualifications: \n \nThe ideal candidate will have: \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years  experience working in the BI space at an Architect level. \n \n5+ years  experience implementing BI solutions in Azure cloud environments. \n \n2+ years  experience working with Snowflake and Postgres databases. \n \nDemonstrable experience in evaluating business needs and implementing BI strategies to meet those needs. \n \nA combination of technical expertise and leadership skills to effectively navigate the complexities supporting multiple in-house business units. \n \nAdditional Skills & Qualifications \n \nPlease include answers to Sample Questions in submittals!! \n \nInclude answers to these questions on the Candidate Bid Sheet. \n \nHow many years of direct experience does the candidate have designing and implementing Business Intelligence (BI) strategies? \n \nHow many years of experience does the candidate have managing within an IT environment? \n \nPlease list any relevant professional certifications the candidate has. \n",
            "dateupdated": 1723644828
        },
        {
            "id": "3cf0dba2-482b-4972-897c-2577efedd7e6",
            "title": "Azure Cloud Architect",
            "location": "Pittsburgh, Pennsylvania, USA",
            "company": "SUNRAY INFORMATICS",
            "description": "Hi Professionals, \n \nWe have an immediate openings for the below role, If intrerested please apply. \n \nJob Title: Azure Cloud Architect \n \nType :  C2C and Onsite Hybrid Model \n \nInterview: Telephonic & Skype \n \nJOB RESPONSIBILITIES \n \nOVERALL EXPERIENCE 10YRS+ \n \nMajor Duties \n \n: \n \nOversee architecture, management, configuration, and layout of Azure infrastructures. \n \nProvide expert-level architecture design for Azure environments \n \nDemonstrate knowledge of DevOps tool chains and processes \n \nDevelop solutions architecture and evaluate architectural alternatives for private, public and hybrid cloud models, including IaaS, PaaS, and other cloud services \n \nAct as a Subject Matter Expert to the organization for cloud end-to-end architecture, including networking, provisioning, and management \n \nOffer in-depth analysis of Azure environment and recommend best practices in Compute, Storage, Backup, Recovery, and Archiving. \n \nEnsure delivered solutions meet/perform to technical and functional/non-functional requirements \n \nUse prior knowledge and creativity to troubleshoot and solve technical issues as they arise. \n \nKeep up to date with developments on current cloud computing solutions and processes. \n \nProvide guidance to cross-functional teams on using and accessing data on the cloud, especially during major transfer, updates, or changes. \n \nParticipate in Root Cause Analysis reviews to improve Azure system performance. \n \nRecommend operational improvements and changes to align with best practices and policies. \n \nKnowledge, Skills, and Abilities \n \n: \n \nMINIMUM QUALIFICATIONS The successful candidate must have minimally achieved the following level of experience \n \n: \n \nDeep understanding of cloud computing technologies, applications, and trends. \n \nKnowledge of cloud infrastructure, software application, and design. \n \nExperience using Microsoft Azure, Amazon Web Services (AWS), Google Cloud, or other major cloud computing services. \n \nStrong cloud migration and data management skills with an emphasis on data privacy and security. \n \nExcellent problem-solving capabilities and can thrive in a fast-paced work environment. \n \nStrong communication skills with the willingness to collaborate with cross-functional departments and teams. \n \n5 \n \n+ years of experience in planning, designing, and managing Azure infrastructures. \n \n5+ \n \nyears of experience in implementing backup and disaster recovery solutions for Azure, following industry best practices and change management policies \n \n. \n \n5+ \n \nyears of experience in analyzing Azure environments and recommending best practices in Compute, Storage, Backup Recovery, and Archiving specific to Azure. \n \nBest Wishes, \n \nDany|Recruiter|Sunray Informatics Inc \n \n(Direct)  | (E) \n \nDesk: EXT 253 \n \nSunray Informatics Inc | 77 Milltown Road Suite C1, East Brunswick, NJ 08816  Web: \n",
            "dateupdated": 1723647306
        },
        {
            "id": "3d5b7004-9f14-4dbd-82cc-92a9e90b85fc",
            "title": "AWS Cloud Native Developer Hybrid Atlanta, GA",
            "location": "Atlanta, Georgia, USA",
            "company": "Paramount Software Solutions, Inc",
            "description": "Position Overview: \n \nAs an AWS Cloud Developer at Client you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services,custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nSkill \n \nRequired / Desired \n \nAmount \n \nof Experience \n \nProven experience developing cloud application software \n \nRequired \n \n8 \n \nYears \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nRequired \n \n5 \n \nYears \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nRequired \n \n5 \n \nYears \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nRequired \n \n5 \n \nYears \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nRequired \n \n5 \n \nYears \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nRequired \n \n5 \n \nYears \n \nAgile methodologies and SCRUM framework \n \nRequired \n \n3 \n \nYears \n \nExperience with CI/CD pipelines and DevOps practices \n \nHighly desired \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n \nHighly desired \n \nAWS certifications (e.g., AWS Certified Developer) \n \nHighly desired \n",
            "dateupdated": 1723735132
        },
        {
            "id": "3dc727f5-c664-4b90-b524-525b1f7fae36",
            "title": "Jama Connect Administrator",
            "location": "Remote",
            "company": "Kyyba Inc",
            "description": "Job Title: \n \nJama Connect Administrator \n \nDuration: Long Term Contract \n \nLocation: : DEARBORN,MI - Remote \n \nAdditional Information : \n \n***POSITION IS HYBRID BUT CUSTOMER WILL CONSIDER FULLY REMOTE FOR THE RIGHT CANDIDATE*** \n \nPosition Description: \n \nManages user accounts, roles, and permissions within Jama Connect. Configures and maintains Jama Connect workflows, including custom fields, forms, and integrations. Implements and maintains security policies and access controls. Monitor system performance and identify potential issues. Designs and implements solutions to improve data management, reporting, and automation within Jama Connect. Identifies opportunities to improve Jama Connect workflows and processes through automation and custom development. Collaborates with teams to understand their requirements and translate them into technical solutions. Creates and maintains documentation for custom developments in the form of confluence pages. Provides technical support to users on all aspects of Jama Connect, including custom applications and integrations. Troubleshoots user issues and provides timely solutions. Develops training materials and workshops for new and existing users. \n \nSkills Required: \n \nFamiliarity with Jama Connect as an administrator or a similar role. Strong understanding of requirements management principles and best practices. Excellent knowledge of Jama Connect features and functionalities. Experience with configuring workflows, custom fields, and integrations. Experience developing custom solutions for Jama Connect using the Jama Connect API. Strong problem-solving and analytical skills. Excellent communication and interpersonal skills. Ability to work independently and as part of a team. Ability to construct Confluence pages and integrate JIRA projects with Confluence pages. Ability to communicate well both verbally and in writing to technical and non-technical audiences of various levels. \n \nExperience Required: \n \n2-5 years \n \nExperience Preferred: \n \nExperience with Agile development methodologies. Experience with Jira or other project management tools. Experience with scripting or automation tools. Basic python development experience and some experience using REST APIs. Knowledge on configuring or maintaining cloud and container platforms (i.e. AWS, Azure, Google Cloud Platform, Docker) would be an asset. \n \nEducation Required: \n \nBachelor's Degree in Computer Science, Computer Information Systems or Computer Engineering \n \nEducation Preferred: \n \nMasters \n",
            "dateupdated": 1723728414
        },
        {
            "id": "3f11de3d-fd14-48ef-b169-68ecea6fca76",
            "title": "Full Stack Developer",
            "location": "Plano, Texas, USA",
            "company": "V2Soft",
            "description": "V2Soft ( ) is a global company, headquartered out of Bloomfield Hills, Michigan, with locations in Mexico, India, Canada, France. At V2Soft, our mission is to provide high performance technology solutions to solve real business problems. We become our customer's true partner, enabling both parties to enjoy success. We are committed to promoting diversity in the workplace, and believe it has a positive effect on our company and the customers we serve. \n \nTechnical Skills: \n \nCloud Platforms: AWS (EC2, S3, RDS, Lambda, CloudFormation, VPC, IAM, Redshift) \n \nData Engineering: ETL, Data Warehousing, Data Modeling, SQL, NoSQL \n \nBig Data Technologies: Hadoop, Spark, Athena, materialized views \n \nDevOps Tools: Docker, Kubernetes, Jenkins, Terraform, Git, Big query, Firebase \n \nWorkflow Orchestration: Apache Airflow \n \nProgramming Languages: Python, SQL, Java, Go, Bash \n \nData Visualization: Tableau, Looker, Power BI, Quicksight \n \nMonitoring & Logging: CloudWatch, Prometheus, Grafana, ELK Stack \n \nOther Tools: GitLab CI/CD \n \nSecurity: Forerock, Keycloak, SSO solutions for data platforms \n \nRequirements: \n \nWe are looking for a Full stack developer who is has strong Java & python (Some Golang exposure) experience plus working exposure with data and analytics platforms. We are are Data platform and analytics team. \n \nLooking for some one who is familiar with technologies like Glue, Pyspark, and java. Someone who is able to understand the workings of functions that make a performant data platform. Need someone with strong hands working on experience. \n \nYou will be writing python functions, java functions and sometimes supporting existing Golang functions to help with the data platform day to day activities \n \nPython, Java, Golang. Plus if you have worked in a data or analytics platform prior and have a data infrastructure, data warehouse experience. \n \n10 Years of overall experience is required. \n \nSomebody who is strong in java and python - Golang \n \nData Centric candidate - Data pipeline. Redshift / Puyspark. Data Connector of their own. \n \nAWS experience. \n \nV2Soft is an Equal Opportunity Employer ( EOE). \n \n- to view all of our open opportunities and to learn more about our benefits. \n",
            "dateupdated": 1723730695
        },
        {
            "id": "40218835-40f7-41c1-8c2b-8c1220003222",
            "title": "PMP Certified Project Manager",
            "location": "Richmond, Virginia, USA",
            "company": "Stellar Professionals LLC",
            "description": "We have an opening for the \n \nPMP Certified Project Manager role \n \nin \n \nRichmond, VA \n \nMode of Interview: Both Web Cam and In-Person Interview \n \nWork Location: \n \nRichmond, VA \n \nWork Arrangement: Hybrid \n \nShift: EST \n \nApplicant must have 10 Years of experience with the following: \n \nLarge Project Management \n \nPortfolio Management \n \nProject Management Tools \n \nPMP or Qualified under Commonwealth of Virginia Qualification Standards for IT Project Managers for Category 4 Projects. \n \nComprehensive knowledge of vendor contracting, and vendor management methodologies related to information technology projects. \n \nFinancial Literacy \n \nHands-on working experience with Microsoft Project. \n \nMust possess an active PMP from PMI OR a PM certification from VITA (no other certifications are accepted) \n \nVITA CTP \n \nProposal Development/Business Writing \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience managing cloud-based solutions for data management and analytics. \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n",
            "dateupdated": 1723732269
        },
        {
            "id": "41355ac3-90d2-44cc-bb89-45afdc6fe148",
            "title": "Sr .Net Front-End Developer with Angular, Python - Hybrid - Long-term Contract- Columbus, Ohio. - B3750B",
            "location": "Columbus, Ohio, USA",
            "company": "Technovision, Inc.",
            "description": "Our direct client is looking for a Sr .Net Front-End Developer with Angular, Python for a Hybrid Long-term contract position in Columbus, Ohio. \n \nNote: \n \n- Hybrid : 2 weeks/week \n \nJOB DESCRIPTION: \n \n- Client is seeking for an experienced, skilled, and motivated senior Front-End web application Developer with responsibility for developing and maintaining both front-end components of client web applications. \n \nMandatory Requirements \n \n- 4 years college degree or equivalent technical study or above \n \nProven work experience as a Front-end developer: \n \n- Designing and developing the web applications robust and scalable web applications from concept to production using Angular and Web Forms/MVC 5.0 framework in .NET & ASP.NET environment with proficiency in C#, Java Script, CSS, and jQuery \n \n- Implementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools   Entity Framework; experience in browser testing and debugging \n \n- Understanding of layout aesthetics; Knowledge of SEO principles & Familiarity with software like Adobe Suite, Photoshop, and content management systems \n \nRequired Hands-on Experience: \n \n- Converting the ASP.NET Web Forms to Angular Components and reuse the components in various Modules \n \n- Angular CLI for creating components, Services, pipes, Directives \n \n- Creating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \n- Version control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \n- Building process using Jenkins for Continuous Integration and version control \n \n- Creating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \n- In building and maintaining server-side applications and APIs using languages such as Node.js, Python, or Ruby on Rails \n \n- Integrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \n- Implementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \n- Designing and implementing user interfaces using modern web technologies such as HTML5,CSS3, and JavaScript frameworks like React, Angular, or Vue.js \n \n- In designing, testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \n \n- Optimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \n \n- Implementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \n- Experience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \n- Experience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nResponsibilities: \n \n- Use markup languages like HTML to create user-friendly web pages \n \n- Maintain and improve website \n \n- Optimize applications for maximum speed \n \nDesign mobile-based features \n \n- Collaborate with back-end developers and web designers to improve usability \n \n- Get feedback from, and build solutions for, users and customers \n \n- Write functional requirement documents and guides \n \nCreate quality mock-ups and prototypes \n \n- Help back-end developers with coding and troubleshooting \n \n- Ensure high quality graphic standards and brand consistency \n \nStay up to date on emerging technologies \n \n- Illustrate design ideas using storyboards, process flows and sitemaps \n \nDesired Skills: \n \n- Excellent analytical skills, attention to detail, and problem-solving skills. \n \n- Proven ability to handle multiple tasks and projects simultaneously. \n \n- Good communication skills with both technical and non-technical clients \n \n- Ability to work with project team member when the requirement is not clear. \n \n- Must possess excellent written and oral communication skills. \n \n- Strong experience in creating good solutions w/o mature, detailed, codified business requirements. \n \n- Working experience in delivering expected results in unstructured environments. \n \n- Works productively and effectively independently without significant management oversight. \n \nSKILL MATRIX: \n \n- Development experience using Angular and Web Forms/MVC 5.0 Framework in .NET & ASP.NET environment with proficiency in #, Java Script, CSS, and jQuery - Required \n \n- Designing & Implementing user interfaces using modern web technologies such as HTML5, CSS3, and Java Script framework like React, Angular, or Vue.js - Required \n \n- Hands on experience with mark-up languages, Angular 8 and above, Bootstrap - Required \n \n- Hands on Experience using Python 2.7 & above - Required \n \n- Azure DevOps Experience - Strong plus to have \n \n- Technical Documentation skills; Communication skills with both non-technical and technical clients - Required \n \nQuestion 1: Are you willing to report to the office located in downtown Columbus, Ohio twice a week (minimum)? \n \nLocation: Hybrid (2days/week Onsite), Downtown Columbus, Ohio. \n \nType: Long-term contract \n \nPlease send resume to \"jobs at etechnovision dot com\" with B3750B in Subject for immediate consideration. \n",
            "dateupdated": 1723671517
        },
        {
            "id": "4555d544-e68f-4afb-8fc5-d60c58c0d22b",
            "title": "AWS CLOUD NATIIVE SOFTWARE APPLICATION DEVELOPER",
            "location": "Atlanta, Georgia, USA",
            "company": "Sunrise Systems, Inc.",
            "description": "Job Title: AWS CLOUD NATIIVE SOFTWARE APPLICATION DEVELOPER \n \nLocation: Atlanta, GA(Hybrid) \n \nDuration: 09 months of Contract. \n \nAs an AWS Cloud Developer at Client, you will play a crucial role in designing, developing, and maintaining scalable native cloud software applications on the AWS platform. \n \nCandidates must have experience developing software applications in an AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nProject Overview: \n \nThe Client CJEP project is a modernization of the Criminal Justice Exchange Program that shares data between different agencies, counties, cities, etc.  This project will take the current SoftwareAG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API's and web services will be leveraged to facilitate this modernized solution as much as possible. \n \nPosition Overview: \n \nAs an AWS Cloud Developer at Client, you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services,custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nSkill Matrix: \n \nSkill \n \nRequired / Desired \n \nAmount \n \nof Experience \n \nProven experience developing cloud application software \n \nRequired \n \n8 \n \nYears \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nRequired \n \n5 \n \nYears \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nRequired \n \n5 \n \nYears \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nRequired \n \n5 \n \nYears \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nRequired \n \n5 \n \nYears \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nRequired \n \n5 \n \nYears \n \nAgile methodologies and SCRUM framework \n \nRequired \n \n3 \n \nYears \n \nExperience with CI/CD pipelines and DevOps practices \n \nHighly desired \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n \nHighly desired \n \nAWS certifications (e.g., AWS Certified Developer) \n \nHighly desired \n",
            "dateupdated": 1723732144
        },
        {
            "id": "4588b91e-621b-4b12-88a1-9a35168c7ad3",
            "title": "D365 Developer \\ X++ developer for Dynamics 365",
            "location": "Remote",
            "company": "Svam International, Inc.",
            "description": "The role is for a strong X++ developer for Dynamics 365. \n \nCustom SSRS reporting skills \n \nCore data service experience \n \nLogic Apps desirable \n \nPower Apps desirable \n \nSkills & Experience \n \nAt least six years of ERP development experience and four years of experience specifically in Microsoft Dynamics AX 2012 to D365 \n \nAt least two years of development experience in the current version of Dynamics 365 Finance & Supply Chain Management \n \nMust have a Bachelor s degree, preferably in Computer Science, Management Information Systems or Information Technology \n \nHas a proven track record of providing technical consultancy and delivering complex, full life-cycle implementation, upgrade, extensibility, performance optimization, integration, data migration, security, and support of D365 in a consultancy role. \n \nDeep technical knowledge of Dynamics 365 and AX application stack and server architecture, web services, security, cloud, and infrastructure \n \nExperience with Visual Studio, X++ programming language, .NET, C#, Application Lifecycle Model (ALM), XML, Azure, AIF, and MDX \n \nStrong knowledge of coding standards and methodologies \n \nDesire to learn and implement Microsoft Azure solutions. \n \nExperience in business intelligence and reporting using Power BI, Power App, Flow, and Common Data Services (CDS) \n \nExperience in two or more functional areas in Finance, Supply Chain (T&L),  Professional Services, Service Management,  Analytics, Sales, Marketing, and others \n \nCurrent Microsoft Dynamics 365 development and Azure certifications or the ability to obtain after joining within 90 days of employment. \n \nStrong advisory and presentation skills \n \nAbility to communicate effectively to client stakeholders and all levels within the organization. \n \nPassion for learning and developing technical and functional skills. \n",
            "dateupdated": 1723647942
        },
        {
            "id": "45ac679f-524d-43c7-9d42-d5d3fe81bbb4",
            "title": "Solution Architect",
            "location": "Remote or Redmond, Washington, USA",
            "company": "Wallero",
            "description": "Role : \n \nSolution Architect \n \nLocation : \n \nRedmond, WA (Remote) \n \nJob type: \n \nContract \n \nJob Description: \n \nSummary: \n \nSeeking a seasoned Solutions Architect experience to lead application development projects. \n \nResponsibilities include analyzing project requirements, migrating data using Azure Data Factory, integrating systems and delivering strong applications. Experience with Azure, Snowflake, ServiceNow, and SharePoint preferred. \n \nActivity: \n \nThe solution architect needs to assess the existing system and evaluate solutions to eliminate the manual processes and improve the efficiency, accuracy, and maintainability of the financial system. \n \nSkills: \n \nEnterprise scale Solutions Architecture experience \n \nSQL databases \n \nETL experience \n \nPower BI \n \nADF \n \nAzure Cloud \n \nStrong problem-solving skills. \n",
            "dateupdated": 1723657982
        },
        {
            "id": "466f5d54-f2b9-48fd-842a-1fffe3b86a3f",
            "title": "Business Intelligence (Advanced Analytics Developer)",
            "location": "San Francisco, California, USA",
            "company": "Stellent IT LLC",
            "description": "Job Title:- Oracle BI Developer \n \nLocation:- San Francisco, California Onsite \n \nContract \n \nJob Description: \n \nProvides development leadership and expertise for advanced BI analysis and analytics. \n \nGuides and moves forward an advanced BI/Data Mart system providing sophisticated and measurable business benefits. \n \nDrives data, ETL and system architecture and development. \n \nOwns the advanced analytics data environment to ensure that the data refresh from various sources, to facilitate research, is happening at regular intervals. \n \nSupports a group of multi-disciplinary data professionals and analysts. \n \nDrives development (coding using PL/SQL, Perl or any other scripting language, ad-hoc queries using SQL). \n \nEnsures that the data infrastructure can scale to meet defined performance, load, and functional objectives Effectively manages the execution of parallel projects of varying scope and duration. \n \nResponsible for all database objects including tables, indices, triggers, views, sequences, packages, and procedures. \n \nWorks with Systems and Database Administration for infrastructure needs related to support, storage, backups, monitoring, performance bottlenecks. \n \nParticipates with applications development and quality assurance in the management of application releases. \n \nAdvises senior management on \"best practices\" concerning web analytics, data warehousing, data architecture, and data development. \n \nWorks with business intelligence and other source system owners to build data refresh plan for research environment. \n \nOwns web click stream data collection and supports product managers to implement best practices for data definition. \n \nSupports project management and documentation needs of the group. \n \nSkill Set: \n \nExperience with Oracle 8i, 9i and 10g including PL/SQL, SQL loader, external tables, partitioning and performance tuning. \n \nStrong knowledge of Oracle data structures, data dictionary, and RDBMS structures. Experience as data architect and/or DW/BI architecture. \n \nExperience in database design and administration, strong in performance tuning, software installation, scripting, PL/SQL coding, backup & recovery process. \n \nAt least 2 medium to large scale DW/BI project implementation experience. \n \nExperience working with DW/BI environment to be able understand the concepts of STAR, data cleansing, transformation and aggregations. \n \n4+ years, current, development experience and inclination towards development. \n \n1+ years' experience with web analytics products like web trends, NetTracker, Omniture etc.. \n \nExperience working in an environment that has come across customer integration issues or has addressed it using MDM. \n \nAbility to express business and technical concepts clearly and concisely both verbally and in writing. \n \nAggressive approach to staying current with developments within the internet world, related web analytics & data management. \n \nExperience working in a team-oriented, collaborative environment. \n \nGood to Have Skills: \n \nExperience working with various business applications like campaign management, CRM, ERP. \n \nExperience with Java scripts or any other web front end scripting. \n \nExperience with column-oriented database solutions such as HBase or Infobright. \n \nExperience with Hadoop. \n \nOracle database administration experience. \n \nExperience working with various data reporting tools like Business Objects, MicroStrategy, COGNOS. \n \nExperience working with ETL tools like Data Stage, Informatica, Hummingbird. \n \nExperience working with meta data management. Experience with SAS. \n \nAdditional Skills: \n \nSenior Azure Cloud Data Engineer with a strong background in Power BI, Azure Data Factory (ADF) and SQL. The candidate will be responsible for designing, developing, and implementing data integration solutions in the Azure cloud environment. Design and implement ETL processes using Azure Data Factory to integrate data from various sources into PostgreSQL / Azure SQL Database. Develop and maintain data models in Azure SQL Database to support reporting and analytics requirements. Create interactive and visually appealing dashboards and reports using Power BI. Experience in the retail domain will be an additional advantage. Strong analytical and problem-solving skills, excellent communication and collaboration skills. Have to collaborate with cross-functional teams to deliver high-quality data solutions that drive business intelligence and analytics initiatives. \n \nTechnical Skills: \n \nPower BI, DAX \n \nAzure Cloud \n \nAzure Data Factory (ADF) \n \nAzure SQL, PostgreSQL \n \nVisual Studio \n \nTest Driven Development \n \nPython, PowerShell \n \nGitHub, Github Actions, JIRA \n \nTools : IntelliJ, Splunk, New Relic \n \nSr. IT Technical Recruiter \n \nPhone:- \n \nEmail: \n \nGtalk: \n \nLinkedin id:- \n",
            "dateupdated": 1723738577
        },
        {
            "id": "489f1ae8-ccd0-488f-aa59-6e243efeee72",
            "title": "Cloud Network Developer",
            "location": "Mount Laurel Township, New Jersey, USA",
            "company": "Indus Valley",
            "description": "Work Location (City/State) \n \nMt Laurel, NJ or Toronto, ON (2 days/week onsite) \n \nRequired: \n \n7+ years of automation and IT experience. 3+ years in DevOps and cloud experience. \n \nStrong programming skill with experience in API and Webhook development using Python, Ruby, PowerShell, and Shell Scripting languages. \n \nExperience with automating and integrating Serverless cloud provided PaaS solutions. \n \nAbility to troubleshoot code and logic errors for cloud-based network services. \n \nUnderstanding of deployment platforms and databases via CI/CD pipeline. \n \nDevelop APIs and Webhook for multi-directional integration of cloud orchestration platform with system management systems, DevOps tools, and Cloud platforms. \n \nUnderstanding of agile JIRA tools to manage a backlog of enhancements and bug-fixes, managing source code in Stash and binaries in Nexus. \n \nProficiency in cloud automation using cloud native CLI/API. \n \nDemonstrable experience deploying enterprise workloads to Azure/AWS/Google Cloud Platform. \n \nMust have working experience with Cloud Native Networking technologies. \n \nMust have experience using PowerShell to configure Cloud Networking components. \n \nKnowledgeable of cloud and hybrid-cloud implementations including IaaS, PaaS, and SaaS. \n \nAbility to participate in fast-paced DevOps Engineering teams within Scrum agile processes. \n \nA critical thinker with strong research and analytics skills \n \nSelf-motivated with a positive attitude and an ability to work independently and or in a team. \n \nAble to work under tight timeline and deliver on complex problems. \n \nEducation/Certifications: \n \nBachelor's degree in computer science, engineering or a related field, or equivalent work experience \n \nCISSP, CCSP, Microsoft MCSE Azure   400 or 500 \n \nBest Regards, \n \nRasmita Lima \n \n(Office) \n",
            "dateupdated": 1723736335
        },
        {
            "id": "48c27e2e-584f-48cc-840a-be7ea0813186",
            "title": "SRE",
            "location": "Plano, Texas, USA",
            "company": "Tekfortune Inc.",
            "description": "Job Tittle: \n \nSRE \n \nLocation: \n \nContract to hire \n \nDuration: \n \nHybrid; McLean VA or Plano TX \n \nJob Description: \n \nPosition Scope: \n \n- Identifying opportunities to improve the resiliency and reliability of the organization's infrastructure across multiple teams \n \n- Troubleshooting issues that arise in production environments \n \n- Determining where incoming architectural and infrastructure requirements can be met, such as those mandated by the organization \n \n- Working with core engineering teams to resolve mobile app issues in production \n \nCandidates Experience: \n \n- Experience with AWS for building and managing infrastructure \n \n- Proficiency in Python for scripting automation tasks \n \n- Understanding of infrastructure-as-code tools like Terraform and Jenkins for provisioning and deploying changes \n \n- Experience monitoring applications and infrastructure using tools like New Relic, Splunk, and Observe \n \n- Knowledge of network observability tools and deep packet inspection for troubleshooting network-related issues \n \n- DevOps skills like configuration management, release management, and monitoring \n \n- Understanding of software engineering best practices for reviewing code/PRs and debugging bugs \n \n- Strong learning abilities to adapt to new technologies as requirements change \n \nCurrent Tech Stack: \n \n- AWS as their primary cloud provider \n \n- Python for automation scripts \n \n- Terraform for infrastructure provisioning \n \n- Jenkins for continuous integration/delivery \n \n- New Relic for application metrics \n \n- Splunk for centralized logging \n \n- Observe for aggregating metrics from other tools \n \n- Network observability tools like those that provide deep packet inspection \n",
            "dateupdated": 1723658483
        },
        {
            "id": "4aac9a62-7334-44f0-b2e4-a044e3158209",
            "title": "Sr. Security Engineer - Atlanta, GA (Hybrid)",
            "location": "Atlanta, Georgia, USA",
            "company": "Stellent IT LLC",
            "description": "Sr. Security Engineer \n \nAtlanta, GA (Hybrid) \n \nPhone+Skype \nJob Description: \n \nBuilding and growing a next-generation vulnerability management program \n \nProviding remediation guidance and recommendations and coordinate with the Technology organization, IT and other teams as needed to provide oversight to the remediation and/or mitigation of enterprise vulnerabilities. \n \nEvaluate and deploy vulnerability reporting solution to aggregate and centralize all infrastructure, application, and container vulnerabilities. \n \nExtensive Windows, Mac, and Linux experience and common configuration deficiencies \n \nThorough understanding of desktop, server, application, database, and network security hardening principles and practices for threat prevention \n \nDevelop vulnerability reports and scorecards that define the current state of the corporate network security risk posture. \n \nPerform research and analysis of scheduled and on demand vulnerability assessments and post results. \n \nResearch exploit techniques and mitigation strategies. \n \nPerform analysis of asset and vulnerability information to identify risks that were not discovered via automated scanning \n \nTroubleshoot issues that may occur during automated network scanning, and or agent scans. \n \nReview public and private vulnerability notifications/disclosures, consume research findings and prioritize remediation efforts. \n \nIntegrate vulnerability management tools with other systems, such as CMDB, SIEM, and Archer, PowerBI. \n \nAssist with implementing policy compliance tools to monitor compliance against CIS and other industry related benchmarks. \n \nAssist with implementation of IoT and OT security solution to Client and secure unmanaged assets. \n \nDevelop rules to identify non-compliant resources in our cloud environments and create automations to remediate the non-compliant resources. \nTop skills required: \n1. SME on Qualys Vulnerability Management solution \n \n2. Experience with centralized vulnerability reporting solution (Kenna Security, Vulcan, or similar) \n \n3. Experience with risk-based vulnerability management program \n \n4. Experience with Qualys Policy Compliance \n \n5. Experience with IoT/OT solutions (Armis, Nozomi, or similar) \n5+ years of experience in Qualys (VMDR), Policy Compliance and Vulnerability Management. \n \n2+ years of experience in Kenna Security, Vulcan, or equivalent solution. \n \nScripting experience with PowerShell, python, rest API. \n \nExperience developing reports in MS PowerBI. \n \nExperience working with IoT/OT technology. \n \nWorking knowledge of cloud environments such as AWS, Google Cloud Platform, and Azure. \n \nBachelor's degree in Information Security, Information Technology or Computer Science. \n \nKnowledge of vulnerability management, policy compliance, and web application scanning solutions. \n \nBasic understanding of regulatory structures such as PCI, PII, and GDPR. \n \nCreative and adaptive work ethic, with a strong customer-oriented attitude. \n \nAbility to clearly communicate and present to various levels of the organization \n \nStrong organizational and analytical skills with attention to detail \n \nIndependent and self-motivated and very thorough work ethic \n \nAbility to identify gaps in process and develop solutions \n \nExperience crafting tools to improve efficiency performing routine tasks \n \nExperience with Excel functions and extracting data using multiple criteria \n \nUnderstanding of Vulnerability Management holistically as a program \nBINU TRIPATHI \n \nIT TECHNICAL RECRUITER \n \nContact No: \n \nEmail: binu \n \n@ \n \nGtalk  : binu \n \n@ \n",
            "dateupdated": 1723733211
        },
        {
            "id": "4d192376-adba-4935-9d33-9b71c9762a2d",
            "title": "DevOps Engineer",
            "location": "US",
            "company": "Abidi Solutions",
            "description": "Job Title: \n \nDevOps Engineer \n \nDuration: \n \nLong Term \nQualifications / Requirements \n \nHands on experience in one or more public clouds and/or experience with web applications, virtualization technologies, operating systems, databases, networking, security, or software development. \n \nIntellectual curiosity with an innate ability to learn and new technologies. \n \n5+ years of hands-on progressive IT experience. \n \nExperience with Configuration Management technologies (Ansible, Chef, Puppet, etc.) \n \nInfrastructure-as-Code experience using Ansible, Terraform, Pulumi, CloudFormation, ARM Templates, etc. \n \nExperience collaborating across cross-functional technical teams to deliver a project. \n \nExperience with version control software, including Git (GitHub, Bitbucket, Azure DevOps, etc.) \n \nExperience with programming languages (Python, BASH, Java, Ruby, Go, Javascript, Typescript, etc.) \n \nExperience with logging solutions (ELK, Aria Logs, Splunk, Sumo Logic, Datadog, etc.) \n \nExperience with monitoring and visualization systems and tools (ScienceLogic, Grafana, Tableau, PowerBI, etc.) \n \nHands-on experience collecting performance data, analyzing, troubleshooting, and tuning. \n \nAn understanding of ITIL best practices in a service provider setting. \n \nPassion for working in an internal and external customer facing setting. \n \nAdequate professional experience and knowledge to perform Job Responsibilities \n \nExcellent verbal, written, and interpersonal skills. \n \nAbility to prioritize and organize effectively. \n \nAbility to work on multiple projects simultaneously. \n \nAbility to work both independently and with others. \n \nAbility to operate in a fast moving, team-oriented, collaborative environment with specific deadlines. \n \nProficiency in using MS Office Suite and Windows-based computer applications. \n \nPreferred Experience \n \nPrior experience particularly in the managed services data center industry. \n \nResponsibilities \n \nLeverage our depth of experience with infrastructure engineering to provide full lifecycle managed services, driving value for our clients. \n \nMaintain responsibility for the design, deployment, and maintenance of production-scale systems across multiple application and infrastructure vendors. \n \nDesign, build, test, and deploy highly scalable and resilient applications within various internal and public clouds. \n \nSupport multiple infrastructure services before they go live through activities such as system design consulting, developing software platforms and frameworks, lifecycle management, capacity management, testing, quality assurance, and release management. \n \nUse automation to streamline the provisioning, management, and monitoring of applications and services using multiple scripting languages, and infrastructure-as-code. \n \nCoordinate with Service Delivery, Development, and Infrastructure Engineering teams to design and implement zero-downtime deployment approaches, real-time logging, alerting, monitoring solutions, and code instrumentation. \n \nMonitor application performance and maintain observability over key metrics for various infrastructure workloads and services. \n \nBuild reusable automation following vendor best practices and guides. \n \nCreate and maintain client design documentation (diagrams, runbooks, etc.) \n \nRelentlessly work as a team to automate the undifferentiated heavy lifting associated with incident, configuration, change, and problem management. \n \nHave familiarity with one or more data center infrastructure platforms and APIs such as Storage (NetApp, Pure, etc), Network (Cisco, Arista, Juniper, etc), Recovery (Commvault, Veeam, Zerto, etc), Cloud/Virtualization (VMware, KVM, Proxmox, Nutanix, Azure, AWS, etc). \n \nProvide recommendations on workload optimization, cost reduction opportunities, architecture, and design changes. \n \nProvides quality internal and external customer service surrounding company values. \n \nOther duties as assigned. \n",
            "dateupdated": 1723653944
        },
        {
            "id": "4eca40ab-e084-40b9-9445-e1cc338de167",
            "title": "Microsoft Infrastructure Engineer/Microsoft Systems Engineer- Need VA locals",
            "location": "Glen Allen, Virginia, USA",
            "company": "InfoPeople Corp",
            "description": "DUTIES AND RESPONSIBILITIES \n \nInfrastructure Enterprise Engineer with a strong focus on Microsoft Environment (On-Prem and Azure cloud) \n \nStrong hands-on experience with Server management, Storage, Windows Infrastructure, and Networking \n \nRegular support of Microsoft Windows environment, by identifying and implementing solutions to operational issues \n \n5+ years of experience in a systems administration role is required \n \nIn-depth knowledge of Microsoft products to support VDI and desktop users such as Windows 10, Active Directory/Entra, Microsoft 365, ADFS, Azure-AD, GPO Policies, etc. \n \nIn-depth knowledge of Windows servers, including OS upgrades and system maintenance & support. \n \nConfigures, Administers, Troubleshoots, and Manages Companywide issues \n \nStrong Documentation and Visio Diagram experience is preferred \n \nAbility to support On-Premise environment as well as remote users \n \nContribute to upskilling level 1 and level 2 systems operations support teams \n \nProvide documentation and training for additions or changes to our environment. \n \nAssist as escalation level support. \n \nSupport Team Initiatives \n \nMaintain current knowledge of current and emerging technologies, regularly analyzing and evaluating their impact and benefit to the Firm. \n \nProvide lead as well as backup support for other members of the infrastructure team (we partner with a vendor MSP) \n \nAssist in other infrastructure-related administrative tasks within IT related to such things as, security incidence response or application backend architecture. \n \nManage AD/Messaging/server-related trouble tickets utilizing the Service Now platform. \n \nCommunicate proactively, openly, and clearly. \n \nPerform other departmental duties, as necessary. \n \nSupport initiatives and special projects with other teams, as required. \n \nJOB SPECIFICATIONS \n \nOn-Call Escalation availability off-hours and weekends when required \n \nAfter-hours work required when business needs \n \nKNOWLEDGE AND SKILL REQUIREMENTS \n \nAbility to translate non-technical user requirements and descriptions into system designs. \n \nAbility to communicate effectively with technical and non-technical individuals. \n \nAbility to multitask and switch focus among multiple different efforts quickly. \n \nExcellent organizational and self-management skills. \n \nAbility to work well in a team (team player) and individually (self-starter). \n \nApplicable certification (Azure, Exchange, etc.) preferred. \n",
            "dateupdated": 1723727450
        },
        {
            "id": "523612f8-d214-4952-b52e-0e17e6fb3881",
            "title": "Middleware Engineer",
            "location": "Remote or Austin, Texas, USA",
            "company": "Bansar Technologies Inc.",
            "description": "DirectClient: Texas Health and Human Services Commission(HHSC) \n \nSolicitation#529401093 \n \nTitle: Middleware Engineer \n \nLocation: 701 W 51st Street, Austin, TX 78751 \n \nDuration: Until 8/31/2025 with possible extension \n \nLast date for submission: August 20, 2024 (2.00 PM-CST) \n \nImportant Note: The working position is remote. Candidates must relocate to Texas before the start date. \n \nDESCRIPTION OF SERVICES: \n \nThe role includes being a member of the team that is the focal point for all Middleware activities between TIERS Operations management and Social Services Applications. The role also provides the coordination for all TIERS Releases and Maintenance schedules with respect to Middleware servers and the applications that those server host. When issues arise within the TIERS operational ecosystem, the role asses  problems, communicates up to management, and leads the effort of all required fixes. From an architecture standpoint, the role will advise on any technical implementation, schedules, automation, and division of labor within the Middleware Team. The role performs work related to supporting the core TIERS applications on-premise and those which will be migrated and hosted on AWS Cloud Services. The role works under minimal supervision with extensive latitude for the use of initiative and independent judgment. The role collaborates across teams under the direction of the Director of TIERS Operations. \n \nCANDIDATE SKILLS AND QUALIFICATIONS \n \nMinimum Requirements: \n \nYears Required/Preferred Experience \n \n5 Required Install, deploy, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines. \n \n5 Required Experience tuning large complex Java based web applications in a Service Oriented Architecture. \n \n5 Required Experience troubleshooting large complex Java based web applications in a Service Oriented Architecture. \n \n5 Required Knowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model. \n \n4 Required Experience creating pipelines in Jenkins to automate WebSphere Application Server configurations. \n \n4 Required Experience creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments. \n \n4 Required Experience with different scripting methodologies - UNIX, Jython, YAML, JSON \n \n4 Required Knowledgeable of Java and all phases of the SDLC (Systems Development Life Cycle). \n \n4 Required Use of Application Performance Management tools such as DynaTrace and Splunk \n \n3 Preferred Experience with IBM Business Automation Workflow \n \n2 Preferred Experience with IBM Operational Decision Manager \n \n1 Preferred Experience with IBM DataPower \n \n1 Preferred Experience with Adobe Experience Manager \n \n1 Preferred Experience with AWS solution architecture and management \n",
            "dateupdated": 1723648531
        },
        {
            "id": "551be1c5-44c5-413f-9094-d0537d31a132",
            "title": "Infrastructure/Devops Engineer",
            "location": "Remote",
            "company": "Beacon Hill",
            "description": "Overview: \n \nWe are seeking a Infrastructrue Engineer to join our clients growing Team. Their team is looking to ensure the security of their environment. They are looking for someone with diverse skill sets within AWS infrastructure, including expertise in Terraform, cloud networking, containerization, and more. \nResponsibilities: \n \nInfrastructure as Code (IAC): \n \nDevelop and maintain unified IAC solutions to streamline our stack and make it easily understandable. \n \nCloud Networking: \n \nSolve networking accessibility challenges using VPCs and security groups, all implemented through IAC. \n \nCollaboration: \n \nWork closely with the security team to diagnose issues and implement solutions. Partner with development teams to ensure their systems are production-ready. \n \nObservability: \n \nBuild and advocate for observability solutions, guiding development teams in adopting these practices. \n \nSystem Inventory: \n \nContribute to their service and infrastructure inventory system to ensure a comprehensive understanding of our stack and dependencies. \n \nDeployment: \n \nAssist development teams in deploying their application code, ensuring proper setup of pager alerts for both application and infrastructure issues. \n \nContinuous Improvement: \n \nIdentify gaps in capabilities, workflows, and operations. Propose and implement improvements to enhance efficiency and excellence. \n \nSkills and Qualifications: \n \nEducational Background: \n \nBS or MS in Software Engineering, Computer Science, or equivalent experience. \n \nExperience: \n \n5+ years in writing, deploying, and operating cloud systems and infrastructure. \n \n3+ years with IAC and deployment automation tools such as Terraform (preferred), CloudFormation, CDK, Helm, Ansible, etc. \n \nProficiency in cloud networking and security practices. \n \nExperience with CI/CD tools like CircleCI, GitHub Actions, or GitLab. \n \nTechnical Proficiency: \n \nStrong knowledge of AWS and its ecosystem. \n \nExpertise in Kubernetes (k8s), VPCs, and cloud segmentation. \n \nProgramming skills in Python, JavaScript, Go, or Java. \n \nPassion for Automation: \n \nA genuine enthusiasm for automation and maximizing the value of code. \n \nObservability and Monitoring: \n \nProven experience in implementing robust observability and monitoring solutions. \n \nIf you are passionate about infrastructure, security, and cloud systems, and you thrive in a dynamic and innovative environment, we would love to hear from you. Apply today to join our clients mission-driven team and make a significant impact in their ongoing project. \nBeacon Hill is an Equal Opportunity Employer that values the strength diversity brings to the workplace. Individuals with Disabilities and Protected Veterans are encouraged to apply. \nIf you would like to complete our voluntary self-identification form, please or copy and paste the following link into an open window in your browser: ;/p> \n \nCompletion of this form is voluntary and will not affect your opportunity for employment, or the terms or conditions of your employment. This form will be used for reporting purposes only and will be kept separate from all other records. \n \nCompany Profile: \n \nBeacon Hill Technologies, a premier National Information Technology Staffing Group, provides world class technology talent across all industries utilizing a complete suite of staffing services.  Beacon Hill Technologies' dedicated team of recruiting and staffing experts consistently delivers quality IT professionals to solve our customers' technical and business needs. \n \nBeacon Hill Technologies covers a broad spectrum of IT positions, including Project Management and Business Analysis, Programming/Development, Database, Infrastructure, Quality Assurance, Production/Support and ERP roles. \n \nLearn more about Beacon Hill Staffing Group and our specialty divisions, Beacon Hill Associates, Beacon Hill Financial, Beacon Hill HR, Beacon Hill Legal, Beacon Hill Life Sciences and Beacon Hill Technologies by visiting . \n \nWe look forward to working with you. \n \nBeacon Hill. Employing the Future \n",
            "dateupdated": 1723738260
        },
        {
            "id": "5b126ba0-bf58-42fb-83c8-a1157f86b884",
            "title": "DevOps/iOS Consultant",
            "location": "Boston, Massachusetts, USA",
            "company": "Dexian DISYS",
            "description": "Position Details: \n \nTitle: \n \nDevOps/iOS Consultant \n \nLocation: 2 weeks onsite , 2 weeks remote ( Boston , MA ) \n \nLong term role with possible extensions \n \nLocation Options - \n \nBoston , MA \n \nThe Expertise and Skills You Bring \nYou have a proven record building and maintaining pipelines at scale. Experience navigating a highly regulated industry is a definite bonus. \n \nYou know that reliable and performant pipelines are the secret to our success, and you have the passion and skill to deliver them. You possess strong communication and collaboration skills and wield the ability to influence an organization to constantly improve their products and processes. \n \nIdeal candidates will have a forward-thinking approach to work, anticipating inflection points (like Xcode or Swift upgrades) to have the pipelines ready in advance. This role is inclusive of related tasks such as handling security scans, generating build health reports, and assisting teams with test automation. \n \nDesired experience includes: \n \nSix to nine years of building and maintaining mobile CI/CD pipelines using Jenkins or other cloud-based build systems \n \nAdept at writing code in Swift and one or more scripting languages, such as bash, Groovy, or Python \n \nExperience with iOS test automation using XCTest and XCUITest \n \nDexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian's platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals. \nDexian's brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit  to learn more. \nDexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",
            "dateupdated": 1723738305
        },
        {
            "id": "5c4dfabe-91e8-4a08-82cf-1d79381f451f",
            "title": "DevOps Engineer **100% REMOTE**",
            "location": "Remote",
            "company": "Artech Information Systems",
            "description": "Job Summary \n \nWe are seeking a highly skilled Senior DevOps Engineer to join our engineering team. You will play a critical role in designing, building, and maintaining our cloud infrastructure. This position requires a deep understanding of infrastructure as a service (IaaS), Linux systems, virtualization, and Java application management. You will be responsible for automating infrastructure provisioning, ensuring system reliability, and optimizing application performance. \n \nResponsibilities \n \nDesign and implement IaaS solutions using tools such as OpenStack and CloudStack. \n \nAdminister and maintain Linux systems, ensuring optimal performance and security. \n \nManage and scale Java applications, troubleshooting issues as they arise. \n \nDevelop and implement advanced telemetry and observability solutions. \n \nCollaborate with development and operations teams to streamline processes and improve efficiency. \n \nStay up to date with the latest industry trends and technologies. \n \nQualifications \n \nBachelor s degree in computer science, Engineering, or a related field, or equivalent experience. \n \nProven experience with IaaS orchestration tools (OpenStack, CloudStack, etc.). \n \nStrong Linux system administration skills. \n \nExpertise in Linux system virtualization technologies (Libvirt, QEMU, KVM, etc.) and their associated APIs and programming languages. \n \nIn-depth knowledge of Java application management, scaling, and troubleshooting. \n \nUnderstanding of authentication schemes, certificates, and secure secret management. \n \nAbility to develop and implement advanced telemetry and observability solutions. \n \nStrong problem-solving and analytical skills. \n \nExcellent communication and collaboration skills. \n \nPreferred Qualifications \n \nExperience with containerization technologies (Docker, Kubernetes). \n \nKnowledge of scripting languages (Python, Bash). \n \nExperience with CI/CD pipelines. \n",
            "dateupdated": 1723676635
        },
        {
            "id": "6032f285-2bf6-43b3-9589-120b39dbde7d",
            "title": "Cloud Security Engineers",
            "location": "Frisco, Texas, USA",
            "company": "VDart, Inc.",
            "description": "Cloud Security Engineer \n \nFrisco, TX \n \nKey Responsibilities \n \nDevelop and implement secure onboarding processes for new cloud accounts, users, and resources across AWS, Azure, and other cloud platforms in compliance with federal regulations and security standards. \n \nProvision and configure cloud security services like Identity and Access Management (IAM), logging, config management, threat detection, and security monitoring for continuous protection. \n \nImplement and enforce security controls to protect sensitive data and systems. \n \nCollaborate with cross-functional teams to ensure secure integration of applications and services into the cloud environments. \n \nRespond to security incidents, investigate root causes, and implement remediation measures to prevent future occurrences. \n \nDocument and maintain comprehensive security policies, procedures, and configurations for cloud environments. \n \nQualifications \n \nExperience with onboarding and provisioning in cloud environments. \n \nProven experience as a Cloud Security Engineer or similar role, with a strong focus on secure cloud deployments across multiple platforms. \n \nIn-depth knowledge of cloud security services, tools, and best practices for AWS, Azure, and other major cloud providers. \n \nFamiliarity with security regulations, standards (e.g., FedRAMP, NIST), and compliance requirements for cloud environments. \n \nHands-on experience with cloud security services like IAM, CloudTrail, Config, GuardDuty and Security Hub for threat detection and security monitoring. \n \nStrong problem-solving and analytical skills for identifying and mitigating security risks proactively. \n \nCloud security certifications like AWS Certified Security - Specialty, Azure Security Engineer Associate, or similar are highly preferred. \n \nProficiency in scripting and automation tools (e.g., Python, Terraform). \n \nunderstands onboarding and will be doing onboarding provisioning work on AWS and Azure \n \nStrong communication and documentation skills for collaborating with cross-functional teams. \n \nVDart Group, a global leader in technology, product, and talent management, empowers businesses with comprehensive solutions through our four distinct, industry-leading business units. With a diverse team of over 4,000 professionals across 13 countries, we deliver strong results across various industries, including Fortune 500 companies. \nLeveraging our deep expertise as a global provider of resources and solutions, we serve a wide range of industry verticals, including BFSI, Automotive, Healthcare, Mobility, Energy, Life Sciences, Manufacturing, Consumer Industries, and Technology. \nWith over 16 years of experience, VDart has evolved to meet the needs of leading technology brands, placing and training more than 20,000 professionals and shaping the industry's future. \nOur continuous reinvention, providing resources for IT solutions and unique digital solutions, has positioned us as a top growth leader in digital talent management and technology consulting. \nCommitted to \" \n \nPeople, Purpose, Planet \n \n,\" we prioritize social responsibility and sustainability, as evidenced by our EcoVadis Bronze Medal Certification and participation in the UN Global Compact. \nOur dedication to delivering strong results has earned us recognition as a trusted advisor for businesses seeking to drive innovation and growth, including many Fortune 500 companies. \nJoin our network! Partner with VDart Group to leverage our global network, industry expertise, and proven track record with a diverse clientele.",
            "dateupdated": 1723729553
        },
        {
            "id": "664f21f4-d17d-4ff9-baf2-dbf656ffb442",
            "title": "Business Process Automation/DMS Analyst with Liquid office",
            "location": "Chicago, Illinois, USA",
            "company": "UNICOM TECHNOLOGIES INC",
            "description": "Job Title: \n \nDigital Solutions Engineer (Consultant) \nLocation: \n \nUS-IL-Chicago \nOverview: \n \nAs a Digital Solutions Engineer, you will be part of our CTS department, providing essential support for our software and systems. Your role will focus on ensuring the smooth functioning of our applications, assisting users, and contributing to the overall maintenance and enhancement of our technological infrastructure. \nResponsibilities: \n \nProvide first and second-level support for OpenText Liquid Office System. \n \nTroubleshoot, diagnose, and resolve technical problems related to operating systems, hardware, and software that run these systems. \n \nLiaise with internal users to gather detailed information to understand the nature of their technical issues. \n \nDocument all technical inquiries, issues, and solutions in ServiceNow for future reference. \n \nProvide support for other critical enterprise applications that typically do not require full-time support from CTS. \n \nWork with the Security team to apply security policies required to move changed code to production. \n \nCreate system documentation that will be utilized to support the tools and applications that are supported. Some tools or applications could be transitioned to other CTS departments for steady-state support. \n \nAssist the Application Development and Enterprise Architecture teams by studying emerging technologies and sharing this information with other teams. \n \nParticipate in periodic meetings with the management team to plan, review and monitor operations. \n \nAssure projects are deployable upon completion and meet the CTS Operational Readiness criteria. \n \nMaintain effective communication with management regarding developments within areas of assigned responsibilities and perform special projects as required or requested. \n \nBe self-directed and show ability to manage and prioritize their own work. Be able to manage multiple projects at the same time, with appropriate prioritization given to each project. \n \nProvide technical mentorship to others. \n \nQualifications: \n \nExpert knowledge of JavaScript, C#, Microsoft SQL Server, with 5+ years' experience. \n \nProven experience in application support, help desk, or a similar role. \n \nWorking knowledge and utilization of SSRS and SSIS tools. \n \nAbility to diagnose and resolve basic technical issues. \n \nExcellent problem-solving and communication skills. \n \nAbility to work independently and as part of a team. \n \nAbility to work with the Business Analysts and the Business to document and implement the processes that will meet the Business's needs. \n \nExperience working with internal and external API's, to get the most efficiency out of our processes. \n \nExperience with Azure Dev Ops (ADO) boards, git repos, and pipelines. \n \nOutstanding troubleshooting experience with applications and tools \n \nAbility to work under pressure and maintain composure in order to get systems functioning. \n \nComfortable in dealing with individuals above and below position \n \nExtensive knowledge of project management processes and project execution best practices \n \nExpectation to support critical systems as required \n \nExcellent written and verbal communication skills \n \nAbility to learn new applications quickly \n \nAbility to be an individual contributor \n \nAbility to work effectively on a project team \n \nExcellent proficiency in Word, Excel, PowerPoint products \n \nWork Experience using Liquid Office or other process automation tools preferred. \n",
            "dateupdated": 1723648695
        },
        {
            "id": "673ac36a-83fa-4c0c-8cfd-11ed4545a2d6",
            "title": "OpenShift Engineer (SME, L3)",
            "location": "Frisco, Texas, USA",
            "company": "K-Tek Resourcing LLC",
            "description": "OpenShift Engineer \n \nLocations: Frisco, TX or Bothell, WA (onsite) \n \nMust-Have: \n \nRedHat OpenShift build experience on \n \nBaremetal infrastructure. \n \nGood understanding of \n \nRedHat ACM for provisioning and managing clusters \n \n, OpenShift Virtualization, \n \nGitOps \n \nprinciples. \nNice to have: \n \nOpenShift Data Foundation for Storage, \n \nRedHat Advanced Cluster Security. \nUnderstanding of Baremetal infrastructure (Dell PowerEdge Server). \nExperience building Container as a Service Self Service model. \nResponsible to Design and implement enterprise PaaS solutions, based on RedHat OpenShift on \n \nBaremetal infrastructure \n \nand variety of IaaS platforms like AWS, Azure, VMware, OpenStack etc. \nGood understanding of \n \nRedHat ACM for provisioning and managing clusters \n \n, OpenShift Virtualization, GitOps principles. \nGood exposure to DevOps principles, CI/CD, Continuous Deployment Pipelines with a proper well tested failover & recover plans on any infrastructure. \nDeep understanding of cloud storage and integrations with k8s platforms. \n \nOpenShift Data Foundation for Storage, \n \nRedHat Advanced Cluster Security. \nBroad understanding of competitive landscape, IT strategic topics and solutions like automation, hybrid cloud, IT modernization, DevOps, and advanced application development concepts. \nExperience building Container as a Service Self Service model. \nUnderstanding of Baremetal infrastructure (Dell PowerEdge Server). \nBroad understanding and ability to effectively communicate the value technology brings to a business, industry, or vertical \nAbility to design high available, multi cloud and split cluster based OpenShift environment. \nSkilled to assess the client's technology architecture, identify gaps and prescribe the right set of tools and technologies cutting various layers of architecture for the target state designs/ architectures. \nAbility to define roadmap for non-functional requirements for the production and guide the implementation. \nProvide technical leadership in daily system support and operation for critical and complex production systems \nCreate and update maintain and deliver technical documentations \nAn active listener with excellent communications and interpersonal skills, with an ability to utilizes different styles of questioning techniques and manage conflict and objection handling.",
            "dateupdated": 1723644972
        },
        {
            "id": "67d38af2-0bac-447f-8c36-f5671660e2e2",
            "title": "Cloud Platform Engineer",
            "location": "Paramus, New Jersey, USA",
            "company": "SOHO Square Solutions",
            "description": "Note* Only candidates \n \nthat are local to NJ and can commute to the Paramus will be considered. \n \nSummary \n \nThe Cloud Platform Engineer will be primarily responsible for the design, implementation, and maintenance of the infrastructure to support the Customer Application team's infrastructure and other applications installed in Oracle Cloud Infrastructure and/or AWS tenancies. The candidate will work closely with development teams, architects, and other stakeholders to ensure the reliable and efficient operation of our key applications in various environments. The candidate is expected to work in a hybrid model. \nDuties and Responsibilities: \n \nDesign, configure, and maintain the infrastructure components of the Customer Applications team. \n \nCollaborate with the architects and development team to understand the infrastructure requirements of the team and ensure it is aligned with architectural principles and best practices. \n \nImplement high availability, backup strategies, and disaster recovery for supported applications ensuring business continuity and data protection. \n \nMonitor and optimize the team's infrastructure components, identifying and resolving bottlenecks, and implementing performance tuning measures. \n \nAutomate infrastructure provisioning, deployment, and configuration management processes using tools and scripts to improve efficiency and consistency. \n \nCollaborate with the security team to ensure the implementation of appropriate security controls and compliance with organizational policies and industry standards. \n \nProvide technical support and troubleshooting for infrastructure-related issues, working closely with the development team and vendors as needed. \n \nStay up-to-date with the latest application releases, infrastructure technologies, and industry best practices, and evaluate their potential impact on existing and future solutions. \n \nRequirements: \n \nHybrid role in Paramus, NJ \nPlease submit candidates that are local to NJ and can commute to the Paramus office \nEducation / Experience / Background: \n \nKnowledge / Skills / Abilities: \n \nMinimum Bachelor Degree in Computer Science, Information Technology, or related field and equivalent experience. \n \nMinimum 5 years of designing, implementing, and maintaining the infrastructure services or similar role. \n \nKnowledge in managing, configuring, and troubleshooting the Linux operating system, storage, and networking. \n \nKnowledge of the database management systems. Be able to install patches and upgrades specific to the database. \n \nExperience with CI/CD tools and version control systems (eg. Gitlab). \n \nKnowledge of agile methodologies, DevOps practices, and continuous integration/continuous deployment (CI/CD) pipelines. \n \nProficiency in scripting languages for automation and management of the infrastructure (eg Python, Shell, Ansible). \n \nFamiliarity with cloud computing platforms (OCI, AWS, etc) and their integration with each other. \n \nStrong understanding of high availability, disaster recovery, and backup strategies for mission-critical systems. \n \nExcellent problem-solving, troubleshooting, and analytical skills. \n \nStrong communication and collaboration skills. Ability to effectively communicate technical concepts to technical and non-technical stakeholders. \n \nDevelop and maintain technical documentation, including design documents and technical specifications. \n \nKeep up to date with the latest technologies and recommend improvements to existing systems and processes. \n \nKnowledge of the Oracle Utilities technology stack (Oracle Utilities Application Framework, Customer Care and Billing, and Weblogic) is a big plus. \n \nExperience in working in a mixed onshore/offshore team environment \n",
            "dateupdated": 1723644957
        },
        {
            "id": "6885983f-1449-4e6d-a39c-f1d55934398a",
            "title": "Senior IT Project Manager-Microsoft Infrastructure",
            "location": "Remote",
            "company": "Arraya Solutions",
            "description": "Arraya Solutions, a leading technology consulting firm, is looking for a Remote Senior IT Project Manager to join our customer's team! \n \nWe are a culture that embraces change, values family and are actively involved with the community. Our team consists of people with positive attitudes who are interested in growing their knowledge around technology and leaders that are heavily involved in day-to-day activities. \n \nThe Technical IT Project Manager is responsible for planning and executing project work in support of organization s Security Infrastructure projects. This position works with IT Leadership on project initiatives and planning, discussion, and communication to ensure the project team s efficiency. \n \nResponsibilities \n \nAccountable for every aspect of the project, including leading a team capable of meeting or exceeding client expectations for their vision \n \nProvide expert guidance on implementing Microsoft Azure/M365 solutions. \n \nProject manage Microsoft 365, including Microsoft Defender, Azure Sentinel, and other related tools. \n \nCollaborate with customers to understand their security needs and develop tailored solutions. \n \nIn-depth experience in managing projects in Autopilot, Co-management, Conditional Access, device policies, MAM for IOS and Android), in-depth understanding of Azure Active Directory and Office 365, Security (LAPS, Bit locker, Windows Hello for Business, Certificate 802.1X) \n \nProject Management experience in Microsoft Cloud/Hybrid Cloud Management. Onboarding and configuring and transitioning to the cloud \n \nStay up-to-date with the latest Microsoft security certifications and best practices. \n \nWork with internal stakeholders and external clients to define project outcomes, deliverables, benefits, costs, and schedule \n \nSet and manage stakeholder expectations, develop a detailed project plan, define the scope of the project, understand project risks, and assign team members to specific tasks \n \nDevelop and maintain open communication, form working relationships and motivate stakeholders and team members \n \nMonitor project progress and set deadlines \n \nAnticipate delays that may occur on the client side and apprise the team of any changes in the client s needs \n \nAdapt and problem solve based on changing circumstances in order to achieve updated project objectives \n \nEstimate costs and manage within cost authorizations \n \nCommunicate accurate cost information including burn rate, cost to completion and cost under or over runs \n \nDevelop and maintain comprehensive stakeholder communication that addresses scope, cost, schedule, and risks to the project \n \nIdentify, evaluate, and mitigate risks that could impact the project's outcomes \n \nOversee all project documentation, including contract and process documentation \n \nEnsure deliverables meet quality standards \n \nDrive continuous project execution improvement \n \nRequirements \n \nBachelor s in Business, Information Technology, Engineering, or Computer Science and 7+ years of experience performing relevant IT project management in midsize or large organizations \n \nExperience in business analysis, requirements gathering, documentation, and stakeholder management \n \nSolid technical background in Microsoft Security related tools, such as Azure Active Directory, Microsoft 365 Defender, and Microsoft Information Protection, Intune \n \nAbility to design and implement security solutions using Microsoft technologies and best practices \n \nDemonstrate experience managing IT projects that deliver IT platforms that are scalable, performant and secure and cost effective \n \nDemonstrated experience defining and maintaining project documentation standards and artifacts including budgets, schedules, specifications, and contracts \n \nAbility to lead and facilitate meetings including project planning, sprint planning, and sprint and scrum meetings. \n \nAbility to define product rollout strategy and communications \n \nStrong verbal and written communication skills \n \nCandidates with meeting the following criteria will be preferred: \n \nProfessional certifications demonstrating Project Management competencies (e.g., PMP, ITIL, MCITP, Scrum/Agile) \n \nJob Types: Full-time, Contract \n \nBenefits: \n \n401(k) \n \nDental insurance \n \nHealth insurance \n \nSchedule: \n \n8 hour shift \n \nExperience: \n \nM365 Project Management: 5 years (Preferred) \n \nMicrosoft Azure Project Management: 5 years (Preferred) \n \nCloud Technology Project Management: 5 years (Preferred) \n \nLicense/Certification: \n \nPMP (Preferred) \n \nWork Location: Remote \n",
            "dateupdated": 1723644818
        },
        {
            "id": "6b129714-cd8e-497f-8391-3332c953f87d",
            "title": "Senior Front-End Developer",
            "location": "Columbus, Ohio, USA",
            "company": "Hanker Systems Inc",
            "description": "Hello,I trust you're doing great!My name is Raj, and I work as a Recruiter at Hanker Systems. I wanted to get in touch because we have a fantastic job opening with one of our clients that I believe would pique your interest. Job Title: Senior Front-End Developer Location: Columbus, OH In Person interview Job Description: Mandatory Requirements \n4 years college degree or equivalent technical study or above \n10 years proven work experience as a Front-end developer: \nDesigning and developing the web applications robust and scalable web applications from concept to production using Angular and Web Forms/MVC 5.0 framework in .NET &  environment with proficiency in C#, Java Script, CSS, and jQuery \nImplementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools   Entity Framework; experience in browser testing and debugging \n7 years Hands on experience with markup languages, Angular 8 and above, Bootstrap \n3 years Azure DevOp experience \n5 years hands experience using Python 2.7 & above \nUnderstanding of layout aesthetics; Knowledge of SEO principles & Familiarity with software like Adobe Suite, Photoshop, and content management systems \nRequired Hands-on Experience: \nconverting the  Web Forms to Angular Components and reuse the components in various Modules \nAngular CLI for creating components, Services, pipes, Directives \ncreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \nversion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \nbuilding process using Jenkins for Continuous Integration and version control \ncreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \nin building and maintaining server-side applications and APIs using languages such as Node.js, Python, or Ruby on Rails \nintegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \nimplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \ndesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3, and JavaScript frameworks like React, Angular, or Vue.js \nin designing, testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \noptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \nimplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \nexperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \nResponsibilities: \nUse markup languages like HTML to create user-friendly web pages \nMaintain and improve website \nOptimize applications for maximum speed \nDesign mobile-based features \nCollaborate with back-end developers and web designers to improve usability \nGet feedback from, and build solutions for, users and customers \nWrite functional requirement documents and guides \nCreate quality mock-ups and prototypes \nHelp back-end developers with coding and troubleshooting \nEnsure high quality graphic standards and brand consistency \nStay up to date on emerging technologies \nIllustrate design ideas using storyboards, process flows and sitemaps \nIf this role aligns with your career goals and interests, I d love to discuss it further. Please feel free to reach out to me with any questions or to express your interest.Looking forward to hearing from you!Best regards,Raj KumarTechnical RecruiterPhone:+1 E-Mail:   Hanker Systems Inc. #5401, Tampa, Florida, USA",
            "dateupdated": 1723675472
        },
        {
            "id": "6f317464-5bc0-4df7-a0db-62b9200d0158",
            "title": "Senior Infrastructure Engineer",
            "location": "Richmond, Virginia, USA",
            "company": "Bluefish Technologies",
            "description": "Role: \n \nSr. Infrastructure Engineer \n \nLocation: \n \nRichmond, VA (looking for nearby candidates) \n \nInterview Type: \n \nIn Person Only \n \nWork Arrangement: \n \nHybrid (3 days onsite 2 days remote) \n \nYears of exp required: \n \n6+ years of exp \n \nMust have skills: \n \nWindows Server environments ,  exp with patching, backups, migrations, and implementing Active Directory and exp with tools like SCCM for automated patch management \n \nComplete Description: \n \nWe are seeking a highly skilled Senior Infrastructure Engineer with extensive experience managing Windows Server environments in both on-premises and cloud-based settings. The ideal candidate will have a proven track record in patching, backups, migrations, and implementing Active Directory. They should be adept at supporting a range of applications including Java, .NET, Oracle, Microsoft Dynamics, and various Warehouse technologies. The role demands both server-level support and custom production application support expertise. \n \nThe candidate should be familiar with security tools such as Tenable and have experience with SCCM and automated patch management. Proficiency in server security configurations, including end-point protection, is essential. Strong networking knowledge and in-depth understanding of OSI layer functionality and protocols are required. Experience with disaster recovery (DR) processes is crucial. Preferred qualifications include certifications as a Systems Engineer and Network Engineer. \n \nRequirements: \n \nExperience working with Windows Server in hybrid environments (on-premises and cloud). \n \nExperience providing guidance on disaster recovery/uptime management, best practices for infrastructure stability, etc. \n \nExperience performing regular patching and updates to ensure system security and stability. \n \nExperience overseeing backup operations and recovery processes in mission-critical environments. \n \nExperience planning & executing server migrations, including moving workloads from on-premises to the cloud. \n \nComfortable working in an environment that utilizes multiple frameworks/technologies, including .NET, Java, SQL, Oracle, Microsoft Dynamics, and more. \n \nExperience providing server-level support and troubleshooting issues for production applications. \n \nExperience working with security tools such as Tenable to manage vulnerability remediation, etc. \n \nExperience with tools like SCCM for automated patch management & deployment. \n \nExperience crafting disaster recovery (DR) plans to ensure minimal downtime and prevent data loss. \n \nStrong networking knowledge - including understanding OSI layer functionality and network protocols. \n \nAbility to work with cross-functional teams to address infrastructure needs and support application deployment. \n \nNice-to-haves: \n \nMicrosoft-focused certifications, such as: Azure Administrator Associate, Windows Server Hybrid Administrator Associate, etc. \n \nNetworking-focused certifications, such as: Network+, CCNA, etc. \n \nRequire/Desire Skills: \n \nExperience working with Windows Server in hybrid environments (on-premises and cloud). \n \nExperience providing guidance on disaster recovery/uptime management, best practices for infrastructure stability, etc. \n \nExperience performing regular patching and updates to ensure system security and stability. \n \nExperience overseeing backup operations and recovery processes in mission-critical environments. \n \nExperience planning & executing server migrations, including moving workloads from on-premises to the cloud. \n \nExperience providing server-level support and troubleshooting issues for production applications. \n \nExperience working with security tools such as Tenable to manage vulnerability remediation, etc.     Experience with tools like SCCM for automated patch management & deployment. \n \nExperience crafting disaster recovery (DR) plans to ensure minimal downtime and prevent data loss. \n \nExperience with networking - including understanding OSI layer functionality and network protocols. \n",
            "dateupdated": 1723647806
        },
        {
            "id": "75844d67-f838-4e31-8b89-d6022ee96fae",
            "title": "Cloud Security Engineers",
            "location": "Frisco, Texas, USA",
            "company": "VDart, Inc.",
            "description": "Cloud Security Engineer \n \nFrisco, TX \n \nKey Responsibilities \n \nDevelop and implement secure onboarding processes for new cloud accounts, users, and resources across AWS, Azure, and other cloud platforms in compliance with federal regulations and security standards. \n \nProvision and configure cloud security services like Identity and Access Management (IAM), logging, config management, threat detection, and security monitoring for continuous protection. \n \nImplement and enforce security controls to protect sensitive data and systems. \n \nCollaborate with cross-functional teams to ensure secure integration of applications and services into the cloud environments. \n \nRespond to security incidents, investigate root causes, and implement remediation measures to prevent future occurrences. \n \nDocument and maintain comprehensive security policies, procedures, and configurations for cloud environments. \n \nQualifications \n \nExperience with onboarding and provisioning in cloud environments. \n \nProven experience as a Cloud Security Engineer or similar role, with a strong focus on secure cloud deployments across multiple platforms. \n \nIn-depth knowledge of cloud security services, tools, and best practices for AWS, Azure, and other major cloud providers. \n \nFamiliarity with security regulations, standards (e.g., FedRAMP, NIST), and compliance requirements for cloud environments. \n \nHands-on experience with cloud security services like IAM, CloudTrail, Config, GuardDuty and Security Hub for threat detection and security monitoring. \n \nStrong problem-solving and analytical skills for identifying and mitigating security risks proactively. \n \nCloud security certifications like AWS Certified Security - Specialty, Azure Security Engineer Associate, or similar are highly preferred. \n \nProficiency in scripting and automation tools (e.g., Python, Terraform). \n \nunderstands onboarding and will be doing onboarding provisioning work on AWS and Azure \n \nStrong communication and documentation skills for collaborating with cross-functional teams. \n \nVDart Group, a global leader in technology, product, and talent management, empowers businesses with comprehensive solutions through our four distinct, industry-leading business units. With a diverse team of over 4,000 professionals across 13 countries, we deliver strong results across various industries, including Fortune 500 companies. \nLeveraging our deep expertise as a global provider of resources and solutions, we serve a wide range of industry verticals, including BFSI, Automotive, Healthcare, Mobility, Energy, Life Sciences, Manufacturing, Consumer Industries, and Technology. \nWith over 16 years of experience, VDart has evolved to meet the needs of leading technology brands, placing and training more than 20,000 professionals and shaping the industry's future. \nOur continuous reinvention, providing resources for IT solutions and unique digital solutions, has positioned us as a top growth leader in digital talent management and technology consulting. \nCommitted to \" \n \nPeople, Purpose, Planet \n \n,\" we prioritize social responsibility and sustainability, as evidenced by our EcoVadis Bronze Medal Certification and participation in the UN Global Compact. \nOur dedication to delivering strong results has earned us recognition as a trusted advisor for businesses seeking to drive innovation and growth, including many Fortune 500 companies. \nJoin our network! Partner with VDart Group to leverage our global network, industry expertise, and proven track record with a diverse clientele.",
            "dateupdated": 1723645865
        },
        {
            "id": "763ee0d8-1116-481b-9a1d-2417c84c9921",
            "title": "Looking for DevOps Engineer --- HYBRID at Michigan",
            "location": "Dearborn, Michigan, USA",
            "company": "4-Serv Solutions Inc.",
            "description": "Senior DevOps Engineer \n \n***POSITION IS HYBRID*** \n \nMICHIGAN \n \nJob Description: \n \nWe are seeking a Senior DevOps Engineer to join our growing software development team. \n \nThe individual in this role will play a crucial part in optimizing and scaling our development processes, ensuring that our applications and infrastructure are scalable, resilient, and efficient. \n \nThe ideal candidate will work closely with our software development and IT operations teams to design, implement, and maintain robust automation and continuous integrations/continuous deployment (CI/CD) pipelines. \n \nThe DevOps Engineer will also drive DevOps strategy, streamline workflows, and foster a culture of continuous improvement. \n \nSkills Required: \n \nStrong experience with SQL database administration, scripting, performance tuning, and troubleshooting. \n \nSolid experience with containerization and orchestration technologies like Terraform. You should also have experience scripting in PowerShell, Bash, or similar languages. \n \nStrong understanding in implementation of CI/CD systems (rolling, stage, etc), infrastructure as code (IaC), and automated observability and alerts. \n \nSolid knowledge/understanding of cloud operations, applications, cybersecurity concepts, and industry best practices. \n \nExcellent analytical, diagnostic, and problem-solving skills. \n \nStrong written and verbal communication skills. \n \nDetailed and goal-orientated \n \nExperience Required: \n \nMinimum of 5 years of experience in a DevOps role, with extensive knowledge in managing AWS/Google Cloud Platform environments and deploying Go applications. \n \n5+ years of experience with programming languages such as C#, Golang, Python, etc. \n \nEducation Required: \n \nBachelor's degree in Computer Science, Information Technology, Engineering, or a related field. \n",
            "dateupdated": 1723646385
        },
        {
            "id": "76e342ba-ca83-4763-85ff-29340e823f16",
            "title": "Senior Software Developer",
            "location": "Toronto, Ontario, Canada",
            "company": "Cynet Systems",
            "description": "We are looking for \n \nSenior Software Developer \n \nfor our client in \n \nToronto, ON \n \nJob Title: Senior Software Developer \n \nJob Location: Toronto, ON \n \nJob Type: Contract \n \nJob Description: \n \nResponsibilities: \n \nRequired to translate technical systems specifications into working, tested applications. \n \nDeveloping detailed programming specifications, writing and generating code, compiling data. \n \nDriven programs, maintaining, and conducting unit tests. \n \nResolves and troubleshoots technical problems which arise during the use and operation of software packages, including technical assistance in implementation, conversion and migrations. \n \nExperience in programming and analysis; specialized software package support at the specified experience level. \n \nAbility to collaborate with IT Professionals throughout the Software Development Life Cycle. \n \nExperience in structured methodologies for the development, design, implementation and maintenance of applications. \n \nExperience in design, code, test, debug and document applications. \n \nExperience in the use of object and/or third generation language development tools. \n \nExperience in one or more programming languages. \n \nExperience in application design, latest design patters, deployment and troubleshooting. \n \nExperience with relational and hierarchical database technologies. \n \nExperience in the use of information retrieval packages using query languages. \n \nExperience with one or more communications protocols. \n \nExperience in structured methodologies for the design, development, implementation and maintenance of applications. \n \nExperience eliciting and documenting information from diverse business area stakeholders and subject matter experts. \n \nExcellent analytical, problem solving and decision making skills; verbal and written communication skills; interpersonal and negotiation skills. \n \nA team player with a track record for meeting deadlines. \n \nDesirable Skills: \n \nKnowledge and experience with programming Internet Ready applications. \n \nKnowledge and experience in rapid application development (RAD) methodologies. \n \nKnowledge and understanding of Information Management principles, concepts, policies and practices. \n \nExperience with middleware and gateways. \n \nExperience reviewing, analyzing, and modifying product installation scripts including encoding, testing, debugging Ability to provide post implementation support and resolve any post implementation technical issues. \n \nExperience conducting design walkthrough sessions with project team. \n \nKnowledge and understanding of Accessibility for Ontarians with Disability Act (AODA) and related regulations and standards. \n \nAbility to provide user and system documentation as required. \n \nExperience and Skill Set Requirements: \n \nCandidate have ability to design, build and maintain stable, secure, and scalable web applications. \n \nCandidate have senior application development experience in cloud technologies using Microsoft Azure, .NET. With demonstrated experience in C#/MVC, Entity Framework, ReactJS, HTMLS/CS/JavaScript. \n \nCandidate have knowledge of Domino AIX Server & Lotus Notes Database Developer Script, \n \nDemonstrated experience with Lotus Notes R6.5.1, JavaScript and client server/PC application environments Lotus Script and JavaScript skills, as well as strong knowledge and experience with Lotus Notes architecture and Domino administration, and Quest Migrator from Notes to SharePoint. \n \nCandidate have experience working on application development platforms such as OutSystems. \n \nCandidate have senior level experience in designing, building, modelling and configuring database management systems using Azure SQL Database (Paas). \n \nCandidate have experience in Agile Software Development. \n \nCandidate have experience applying industry web, accessibility, and security standards and best practices to Candidate work that can be adopted by others. \n \nAnalyzing and Assessing Skills: \n \nCandidate can ensure that ongoing application development, technical work, operations and services are planned, scheduled, executed, monitored and evaluated. \n \nCandidate have demonstrated experience analyzing complex system problems and resolving them with minimal impact to the business. \n \nCandidate have demonstrated experience assessing clients' information/systems needs and leading the development of information technology solutions which are cost effective and improve clients' program/service delivery. \n \nResearch Skills: \n \nCandidate can maintain current knowledge of trends and advances in IT across various computing platforms, including configuration and/or new development, analysis and design techniques. \n \nCandidate can work with a high- impact team, on Cloud or new technologies and techniques, supporting research, experimentation with Candidate colleagues. \n \nCode and Scripting - 15%: \n \n5+ years of experience in writing high quality code using cloud technologies Microsoft Azure, .NET. C#/MVC, Entity Framework, ReactJS, HTMLS/CS/JavaScript, Azure DevOps; Azure Web Apps; Azure Functions; Azure Logic Apps. \n \n5+ years of experience designing, building, modelling and configuring database management systems (using Azure SQL Database (Pass), SQL Server). \n \n5+ years of demonstrated experience with testing code to ensure it is developed to meet clients' requirements, and perform as expected. \n \nUI & Frameworks - 20%: \n \n5+ years of demonstrated experience in using markup (HTML5, CSS3, XML). \n \nDemonstrated experience in using frontend Java script frameworks (such as Angular, Vue JS, React, etc.). \n \nExperience in prototyping. \n \nExperience in Agile Framework. \n \nExperience in applying industry web, accessibility and security standards and best practices. \n \nCommunication, Research and Technical Skills - 10%: \n \n5+ years of experience in working with a high- impact Agile team. \n \n5+ years of experience with applying industry web, architectural and security standards and best practices to Candidate work. \n \nAbility to learn new technologies and techniques through research, experimentation and from Candidate colleagues. \n \nStrong communicator with demonstrated interpersonal skills to work within a team environment. \n",
            "dateupdated": 1723655574
        },
        {
            "id": "7711adb3-7a48-48d2-b325-f1d2386b2884",
            "title": "Java Developer",
            "location": "Santa Clara, California, USA",
            "company": "Rackera Inc",
            "description": "Role: Java Developer \n \nLocation: Santa Clara, CA. \n \nNeed people with 15 plus years of experience. who can work from office in Santa Carla, CA In this role you would, \n \nDesign, develop and deploy applications using JAVA/J2EE   Design and develop containerized Spring boot, kafka, applications/Microservices APIs/Design pattern and standards \n \nResponsibilities   Understand the business process requirement   Code and guide the team   Create and maintain documentation regarding configuration, processes & security   Building   Design and integrate RESTful and message-based APIs (KAFKA)   Develop applications using API standards, patterns, and best-practices especially Open API/Swagger, REST, SOAP, Graph QL, Async APIs, JDBC, JSON etc Qualifications we seek in you! Minimum Qualifications   BE in Computer Science, Information Systems Management, Computer Engineering, or an equivalent combination of education and/or experience   Hands on experience with agile methodologies   Knowledge of other programming languages, such as Node, Python and GO   Nice to have hands on experience on cloud Kubernetes services such as AKS, EKS, GKE etc   Knowledge and experience with DevOps, CI/CD tools including Jenkins, Maven, ServiceNow, GitHub, Release Management etc Preferred Qualifications/ Skills   Team leading capabilities   Strong analytical skills and problem solving skills   Excellent communication skills (written and oral) and problem-solving ability   Write unit tests with Junit, Mockito etc \n",
            "dateupdated": 1723674347
        },
        {
            "id": "7bef9f46-9eb8-44d6-8465-b370fa0c84d5",
            "title": "Scrum Master- Need local candidates",
            "location": "US",
            "company": "Alrek Business Solutions, Inc",
            "description": "Required/Desired Skills \nSkill \n \nRequired /Desired \n \nAmount \n \nof Experience \n \nExperience managing cloud-based solutions for data management and analytics. \n \nRequired \n \n8 \n \nYears \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nRequired \n \n8 \n \nYears \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nRequired \n \n8 \n \nYears \n \nKnowledge of transportation data and project management with transportation data is a plus \n \nRequired \n \n8 \n \nYears \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nRequired \n \n8 \n \nYears \n \nTechnical Business Analyst understanding of data integration and data project \n \nRequired \n \n8 \n \nYears \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nRequired \n \n8 \n \nYears \n \nExperience in both Agile and Waterfall project management. & Agile Scrum Maste \n \nRequired \n \n8 \n \nYears \n",
            "dateupdated": 1723647640
        },
        {
            "id": "7bf49866-8db7-4fa4-ad4d-eddf611ce8a0",
            "title": "DevOps engineer",
            "location": "Texas City, Texas, USA",
            "company": "Sagatianz Inc",
            "description": "JD: DevOps engineer: \n \nWrite automation code for provisioning and operating infrastructure at scale. \n \nIdentify and drive opportunities to improve automation for code deployment, management, and \n \nvisibility of application services. \n \nDevelop tools and frameworks to automate operational tasks and deploy machines, services, and \n \napplications. \n \nEstablish end-to-end monitoring and alerting on all critical components of the application \n \nAudit existing services for problems in infrastructure with security, configuration or other possible \n \nissues \n \nProviding support to the infrastructure hosting Critical DevOps tools and Applications. \n \nSupport engineering Linux systems. \n \nAbility to keep up with software development trends and innovation Skill/Job Requirements: \n \n4+ Years` Experience in DevOps Engineering, team management, and collaboration. \n \nExperience with IaaS (Terraform) implementing scalable cloud / On-prem based environments and systems; service-oriented architectures and microservices; deploying resilient, scalable, high-throughput systems. \n \nExperience in developing and maintaining CI/CD processes for enterprise SaaS and on-prem applications using tools like GitHub, Jenkins, GitLab, Bitbucket, Confluence, Jira, packer, etc. \n \n3+ years of administering Linux versions of RHEL, Ubuntu, and CentOS. \n \nSupport, to include Linux subsystems, patching, packaging (rpm), performance tuning, networking, user management, and security. \n \nExperience with configuration management tools like Ansible, Chef, Puppet \n \nGood knowledge of programming languages such as Python and Java and writing code and scripts. \n \nExperience working with virtualization Platforms as VMWare, AWS, Nutanix AHV. \n \nHands-on experience in building and administering VMs using automation tools like terraform \n \nHands-on experience in building and administering Containers using tools such as Docker / Kubernetes and Helm. \n \nFamiliarity with logging and monitoring technologies such as ElasticSerach, Prometheus, Grafana etc. \n \nAbility to install and configure software, gather test-stage data, and perform de-bugging. \n \nProficiency in documenting processes and monitoring performance metrics. \n \nAdvanced knowledge of best practices related to data encryption and cybersecurity. \n \nExceptional interpersonal and communication skills. \n \nStrong hardware/software troubleshooting skills \n \nStrong networking knowledge and experience is highly desired. \n \nDevelop / Maintain Documentation on operational, configuration, or other procedures. \n \n4-year college degree in Information Technology or Engineering strongly desired \n \nMust have excellent verbal and written communication skills. \n \nAbility to oversee and mentor junior software developers, as well as report to management \n \nMust be able to work independently and self-directed, as well as within a team. \n \nSuccessful candidates should be flexible and able to complete projects outside \n \nnormal daily duties as needed \n",
            "dateupdated": 1723671940
        },
        {
            "id": "7c609ed3-8f51-4382-aec3-9efe00fc8efd",
            "title": "IaC Terraform Engineer with Google Cloud Platform",
            "location": "Charlotte, North Carolina, USA",
            "company": "APN Consulting Inc",
            "description": "APN Consulting has an immediate need for a direct client requirement: \nJob Role : IaC Terraform Engineer with Google Cloud Platform \n \nLocation: Concord, CA & Charlotte, NC (Day1 Onsite) \n \nDuration: Contract \n \nNumber of Position:6 \n \nJOB DESCRIPTION \n \nIn this role, you will: \n \nLead complex technology Cloud initiatives, including those that are companywide, with broad impact \n \nAct as a key contributor in automating the provisioning of Cloud Infrastructure using Infrastructure as Code (IaC) \n \nMake decisions in developing standards and best practices for engineering and large-scale technology solutions \n \nDesign, optimize, and document the engineering aspects of the Cloud platform \n \nLead and share understanding of industry best practices and how new technologies influence the Cloud technology team to meet deliverables and drive new initiatives \n \nReview and analyze complex, large-scale technology solutions in Cloud for strategic business objectives and solving technical challenges that require in-depth evaluation of multiple parameters, including intangibles or unprecedented technical factors \n \nCollaborate and consult with key technical experts, senior technology team, and external industry groups to resolve complex technical issues and achieve goals \n \nBuild and enable Cloud infrastructure, automate the orchestration for Google Cloud Platform for Wells Fargo Enterprise \n \nWork in a globally distributed team and provide innovative and robust Cloud centric solutions \n \nClosely work with Product Team and vendors to develop and deploy Cloud services to meet customer expectations \n \nCollaborate with architects, developers, and operations teams to ensure seamless integration and delivery of cloud-based systems \n \nGather and analyze data to diagnose the root cause of Cloud issues, recommend and implement solutions to resolve issues in timely manner \n \nRequired Qualifications: \n \n5+ years of Software Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education \n \n3+ years working with Google Cloud Platform (Google Cloud Platform) and a proven track record of building complex infrastructure programmatically with Infrastructure as Code (IaC) tools \n \n2+ years of hands-on experience with IaC tools Terraform and GitHub \n \nStrong understanding of Google Cloud Platform networking services, such as Virtual Private Cloud (VPC), Cloud Virtual Private Network (VPN), Cloud Interconnect, Virtual Network (Vnet) and Cloud Load Balancing \n \nKnowledge and understanding of Cloud service offerings such as Data, Analytics, AI/Client on Google Cloud Platform \n \nDemonstrated experience on at least three of the following key services: Big Query, Composer, Vertex AI, Document AI, Agent Builder, DataProc, Data Catalog, Notebook \n \nIn-depth knowledge of network protocols, security, and compliance standards \n \nExperience with scripting and automation tools for network provisioning and configuration \n \nKnowledge and understanding of Cloud service offerings on Security, Data Protection and Security policy implementations \n \nBasic understanding of Cloud computing concepts like landing zone and Blueprints \n \nDesired Qualifications: \n \nCloud certification on Google Cloud Platform \n \nExposure to Cloud governance and logging/monitoring tools \n \nExperience with Agile, CI/CD, DevOps concepts and Site Reliability Engineer (SRE) principles \n \nProficient on container-based solution services, have handled 2-3 large scale Kubernetes based infrastructure build out, provisioning of services in Azure or Google Cloud Platform \n \nExperience in scripting (Shell, Python) \n \nGood understanding of networking, firewalls, load balancing concepts (IP, DNS, Guardrails, Vnets) and exposure to database, cloud security, AD, authentication methods, RBAC \n \nExcellent verbal, written, and interpersonal communication skills \n \nAbility to articulate technical solutions to both technical and business audiences \n \nAbility to deliver & engage with partners effectively in a multi-cultural environment by demonstrating co-ownership & accountability in a matrix structure \n \nDelivery focus and willingness to work in a fast-paced, enterprise environment \n",
            "dateupdated": 1723658457
        },
        {
            "id": "8026a3fc-75b3-4529-8b0f-3f7f1e752425",
            "title": "Cloud Security Engineer",
            "location": "Remote",
            "company": "Allwyn Corporation",
            "description": "Job Title: Cloud Security Engineer \n \nLocation: Vienna, Virginia (Remote) \n \nDescription: \n \nThe successful candidate will be a subject matter expert with hands-on experience with cloud technologies, tools and \n \nmethodologies with a particular focus on Microsoft Azure. The role is suited for an experienced Cloud Engineer with proven \n \nunderstanding in enterprise security and will focus on building tool sets and processes to support Client Cloud program. \n \nClient Cloud Organization fosters a collaborative environment and is building a best-in-class Cloud program that protects \n \nClient information and cloud compute environments. \n \nResponsibilities: \n \nContribute to the vision, strategy, and drive execution for integrated security controls across Software-as-a-Service \n \n(SaaS), Platform-as-a-Service (PaaS), Infrastructure-as-a-Service (IaaS) for Client Azure environment. \n \nAble to demonstrate clear understanding of current risks and threats to Cloud infrastructure and/or IT infrastructures \n \nat technical and manager audiences. \n \nDrive Identity and Access Management (IAM), configuration management, and monitoring strategy for Azure. \n \nProvide security consultancy and engineering support for cloud security solutions including analysis and development \n \nof Azure and other security solutions. \n \nProvide architecture assurance on Cloud security initiatives and compliance of existing security standards interfacing \n \nwith infrastructure and development teams. \n \nMaintain the security infrastructure tools that are built on the Cloud platform, providing stability and policies and \n \nprocedures. \n \nSupport the development and delivery of a comprehensive ISP for the entire organization. \n \nDevelop and maintain documentation of all Security products including specific tools, technologies and processes. \n \nParticipate in Information Security Incident Response activities for the Client environment. \n \nRespond to security vulnerabilities identified through periodic and on-demand system audits and vulnerability \n \nassessments of Cloud services. \n \nMonitor compliance with the organization's information security policies and procedures among employees, \n \ncontractors and third parties. \n \nManage remediation efforts for any gaps reported in audits or recommended process improvements. \n \nActively monitor new and emerging cloud security technologies, trends, issues, and solutions and assess their \n \napplicability to Client cloud strategy. \n \nQUALIFICATIONS \n \nHands-on experience with Access control technologies such as Azure AD B2C; SAML SSO, oAuth 2.0 configuration, \n \nset-up and operations management; \n \nExperience with certificate management for IaaS and PaaS elements \n \nExperience with Azure AD, Azure Resource Management Templates and Azure policies \n \nExperience with Azure Key Vault integration and key management \n \nExperience with VSTS release management for Azure Key Vault and other IaaS and PaaS elements. \n \nHands-on development and scripting skills in PowerShell 5 \n \n7+ years  experience working in a technical role with a minimum of 3 years  experience focused on information \n \nsecurity and access control.. \n \nStrong knowledge of information security and access controls. \n \nIndustry certification (CISSP, CISA, CISM, CEH) of high interest \n \nFinancial industry experience preferred \n \nExperience with CheckPoint Next Generation Firewall and Threat Prevention Suite (nice to have) \n",
            "dateupdated": 1723670008
        },
        {
            "id": "8257ab5a-f583-411b-8f34-5a04d93f7b6d",
            "title": "W2 project - IT Program Manager",
            "location": "Chicago, Illinois, USA",
            "company": "Donato Technologies Inc",
            "description": "Job Title: \n \nProgram Manager (IT) \n \nLocation: \n \nChicago, IL (Local Candidates Only   Must be within 1-hour driving distance) \n \nJob Overview: \n \nThe Program Manager (IT) will be responsible for overseeing and coordinating multiple IT projects within a program, ensuring that they align with the organization s strategic goals. The ideal candidate will have a strong background in IT project management, excellent leadership skills, and the ability to manage cross-functional teams to deliver high-quality results on time and within budget. \n \nKey Responsibilities: \n \nLead and manage multiple IT projects within a program, ensuring alignment with organizational goals and objectives. \n \nDevelop and maintain program schedules, budgets, and resource plans. \n \nCoordinate and communicate with cross-functional teams, including developers, business analysts, and stakeholders, to ensure successful project delivery. \n \nMonitor project progress, identify risks, and implement mitigation strategies to ensure project success. \n \nProvide regular updates to senior management and stakeholders on program status, risks, and issues. \n \nFacilitate program meetings, including status updates, steering committee meetings, and issue resolution sessions. \n \nEnsure compliance with organizational policies, procedures, and standards throughout the program lifecycle. \n \nDrive continuous improvement initiatives within the program to enhance efficiency and effectiveness. \n \nRequired Qualifications: \n \nBachelor s degree in Information Technology, Computer Science, Business Administration, or a related field. \n \n7+ years of experience in IT project management, with at least 3 years in a program management role. \n \nProven experience managing large-scale IT programs involving multiple projects. \n \nStrong understanding of project management methodologies, including Agile, Scrum, and Waterfall. \n \nExcellent leadership and team management skills, with the ability to motivate and guide cross-functional teams. \n \nStrong communication and interpersonal skills, with the ability to interact effectively with all levels of the organization. \n \nSolid problem-solving and decision-making abilities. \n \nProficiency in project management tools such as Microsoft Project, Jira, or similar. \n \nAbility to work onsite in Chicago, IL, and reside within an hour's driving distance. \n \nPreferred Qualifications: \n \nMaster s degree in a related field or an MBA. \n \nPMP, PgMP, or other relevant certifications. \n \nExperience with IT infrastructure, software development, and cloud-based technologies. \n \nKnowledge of change management principles and practices. \n",
            "dateupdated": 1723676194
        },
        {
            "id": "831e5b7c-93eb-436a-aa3f-287acd576464",
            "title": "Software Engineer (C/C++) - ADAS",
            "location": "Remote or San Jose, California, USA",
            "company": "Abidi Solutions",
            "description": "Job Title: \n \nSoftware Engineer (C/C++) - ADAS \n \nLocation:  San Jose, CA \n \nEmployment Type:  Contractor \n \nHybrid Onsite - some flexibility for hybrid WFH; core work days Tue-Thu in office \n \n- Seasoned Python developer \n \n- Solid understanding of C/C++ and build systems (like cmake, etc.) \n \n- Solid understanding of version control systems (like git, etc.) \n \n- practical CI / CD know-how from previous positions / jobs (like in GitLab, Jenkins, etc.) \n \n- Experience with Azure services \n \n- Experienced in shell programming (like bash) \n \n- Advanced knowledge with Linux is a plus \n \n- Practical experience with tools like JIRA, CodeBeamer, etc. is a plus \n \n- Knowledge with ROS 1 or 2, ADTF and streaming frameworks are a plus \n \n- Experience with embedded systems is a plus \n \nBased on the current tasks in the DevOps and Tools team, would rather prefer to hire a software developer with 'practical experience' in DevOps than a DevOps guru / certified DevOps person. \n \nThey need a developer/automation engineer for the \"DevOps\" role in the automotive industries in CA - any of the OEMs, etc; coming from the auto domain would be super helpful for their ramp up at Audi. Also person doesn't have to be super skilled at cloud platform integration as they have their own local servers. Its a smaller office and team so this will be a ops person who can set up new users on the fly, grant permissions, able to code in Linux for server configurations, automate repetitive tasks in the pipeline on the server, etc. \n \nRole Summary: \n \nThe role is to support with DevOps tools, targeting automated testing and continuous integration of software products. The tasks will include automation of variated development processes: supporting data collection from test fleet, automation of Labelling, SIL and HIL processes, integration of different Project Management tools (e.g Jira, Codebeamer), linking automated tests to PM tools, implementing build and test servers for multiple platforms, work on deployment infrastructure. Software will be developed for multiple platforms, from embedded SW supporting data collection in the test fleet, up to modules running in the cloud. As side task, the candidate will be required to assist on the development of concept products in vehicle or cloud. The candidate is required to have very good programming skills, especially in C++ and Python languages, and to be able to design solutions for complex problems. The candidate is expected to work on multiple projects simultaneously, so teamwork, good planning, organization and time management skills are required. \n \nRole Responsibilities: \n \nDevelopment of Tools for Process Automation (65%) \n \nDocumentation and Project Management (25%) \n \nDevelopment of Concept Products in vehicle or cloud (10%) \n \nRequired: \n \n+3 years of experience with software development \n \nBachelors Degree in Engineering (computer science or comparable) \n \nDesired: \n \nMasters or PhD in in Engineering (computer science or comparable) \n \nRequired Skills: \n \nProven programming experience (C/C++, Python, Java Script) \n \nExpertise in Continuous Integration and automated tests environments \n \nExperience using REST/Swagger APIs \n \nKnowledge on industry development processes like A-SPICE, ISO9001. \n \nExperience using GitLab/GitHub, Artifactory, Conan, Jenkins/Bamboo \n \nExperience with Linux and Windows OS \n \nDesired Skills: \n \nExperience developing for ARM / Linux environments \n \nExperience with Azure or AWS APIs \n \nExperience with CMake and cross-compilation \n \nExperience with Docker and VMWare \n \nExperience with CodeBeamer, Zephyr \n \nExperience with Unit Tests, SIL, HIL and Simulation \n \nWork Flexibility: \n \nFlexibility to travel (domestic and international) \n \nFull time position \n \nHybrid On-Site position \n",
            "dateupdated": 1723736753
        },
        {
            "id": "84b9b794-a1d2-4711-bc37-a1ab43ccd368",
            "title": "Scrum Master",
            "location": "Richmond, Virginia, USA",
            "company": "Tri-Force Consulting Services Inc",
            "description": "Title: Scrum Master \n \nDuration: 9 Months \n \nLocation: Richmond, VA \n \nNote: Hybrid Role \n \n\"Candidate must be local\" \n \nJob Description: \n \nDrives consistent project delivery through the entire project lifecycle, including: project plans, release plans, resource allocation, and management of project risks, scope, schedule, and delivery of value. \n \nCoordinates Agile Ceremonies such as Sprint Planning, Daily Standups, Retrospectives, Sprint Demos, Story Refinement, and Release Planning. \n \nTracks and communicates project's progress from a schedule, cost, and risk perspective to the project team, stakeholders, and management. \n \nEstablishes an environment where the teams can be effective and helps removing obstacles. \n \nProtects the team from outside interruptions and distractions. \n \nEnsures a good relationship between the team and product owner as well as others outside the team. \n \nTracks and reports team velocity and other project metrics. \n \nPromotes continuous improvement and helps teams to increase productivity. \n \nHelps Product Owner and team with Product backlog management. \n \nAdheres to VDOT and VITA project management practices as defined. \n \nAdditional responsibilities as assigned. \n \nCommunicate timelines and expectations to technical and business staff. \n \nCollaborate with stakeholders to understand project requirements and support data management needs. \n \nEnsure data is collected, stored, and processed securely and in compliance with all applicable regulations. \n \nAnalyze data and provide insights to support decision-making by project management teams. \n \nProvide training and support for end-users to ensure the platform is used effectively. \n \nDemonstrable capability and experience in planning, implementing and maintenance of local master data systems and processes across business units and functions. \n \nUnderstanding of data and leveraging it to deliver business value. Ability to discuss requirements with data teams \n \nExperience in data governance concepts, and data governance implementations. \n \nAbility to use agile approach and methodology to drive master data governance processes. \n \nEnsure documentation of requirements and uses cases, facilitate design workshops for assigned project. \n \nEnsure definition of test objectives, designed test plans and test cases for assigned project. \n \nProvide the management of project milestones and deliverables for on-time and on-budget delivery. \n \nDefine, measure, and clearly communicate progress with metrics. \n \nQualifications: \n \nSolid understanding of software development life cycle models as well as expert knowledge of Agile project management principles and practices. \n \nExperience managing cloud-based solutions for data management and analytics. \n \nAbility to work with customers, understand their business practices and manage their expectations. \n \nAbility to set clear performance standards and hold team members accountable, while keeping team engaged and on track. \n \nAbility to help Product Owners to create and prioritize Product Backlog. \n \nStrong interpersonal skills including mentoring, coaching, collaborating, and team building. \n \nStrong analytical, organizational and decision-making skills. \n \nAbility to analyze and document business and system processes. \n \nAbility to balance the competing demands for quality, scope, schedule, and cost. \n \nWell-versed with Scrum and Kanban Agile methodologies. \n \nPMP and CSM Certifications required. \n \nSAFe Certification preferred. \n \nExperience with SAFe framework is a plus. \n \nPreferred: \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nExcellent analytical, problem-solving, and communication skills. \n \nKnowledge of transportation data and project management with transportation data is a plus. \n \nExperience in IT Infrastructure delivery(networking, physical plant, vendor management, site provisioning) is preferred. \n \nExperience managing large, multi-stream projects. \n \nMicrosoft Office products (Word, Excel, Access, Outlook, Visio, PowerPoint, Project Server) \n \nRequired Skills: \n \nExperience managing cloud-based solutions for data management and analytics. \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nKnowledge of transportation data and project management with transportation data is a plus \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nTechnical Business Analyst understanding of data integration and data project \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nExperience in both Agile and Waterfall project management. & Agile Scrum Master \n",
            "dateupdated": 1723716998
        },
        {
            "id": "850b96f7-a2f9-47df-a7f2-71828614b05c",
            "title": "AWS CLOUD NATIIVE SOFTWARE APPLICATION DEVELOPER",
            "location": "Atlanta, Georgia, USA",
            "company": "Datasoft Technologies, Inc.",
            "description": "AWS Cloud Native Software Application Developer \nHybrid \n \nAbout the Job: \n \nDuration: 10 month Contract w. possibility of extension \n \nLocation: Atlanta, GA \n \nPay rate: Hourly \n \nJob ID: 744937 \n \nOverview: \n \nDataSoft Technologies, Inc. is seeking an AWS Cloud Native Software Application Developer to join our client in Atlanta, GA. This project will take the current SoftwareAG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API s and web services will be leveraged to facilitate this modernized solution as much as possible. \nResponsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nAbout our Company \n \nDataSoft Technologies is a highly recognized provider of professional IT Consulting services in the US. Founded in 1994, DataSoft Technologies, Inc. provides staff augmentation services for Information Technology and Automotive Services. Our team member benefits include: \nPaid Holidays/Paid Time Off (PTO) \n \nMedical/Dental Insurance \n \nVision Insurance \n \nShort Term/Long Term Disability \n \nLife Insurance \n \n401 (K) \n",
            "dateupdated": 1723737875
        },
        {
            "id": "85e395b9-a1b3-4a99-9691-c7daccf51509",
            "title": "AWS Solution Arhcitect",
            "location": "Remote",
            "company": "Proventus Metrics",
            "description": "Hi \n \nPosition: AWS Solution Architect \n \nLocation : Texas \n \nDuration: Long term \n \nInstall, deploy, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines. \n \nExperience tuning large complex Java based web applications in a Service Oriented Architecture. \n \nExperience troubleshooting large complex Java based web applications in a Service Oriented Architecture. \n \nKnowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model. \n \nExperience creating pipelines in Jenkins to automate WebSphere Application Server configurations. \n \nExperience creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments. \n \nExperience with different scripting methodologies - UNIX, Jython, YAML, JSON \n \nKnowledgeable of Java and all phases of the SDLC (Systems Development Life Cycle). \n \nUse of Application Performance Management tools such as DynaTrace and Splunk \n \nExperience with IBM Business Automation Workflow \n \nExperience with IBM Operational Decision Manager \n \nExperience with IBM DataPower \n \nExperience with Adobe Experience Manager \n \nExperience with AWS solution architecture and management \n \nThanks & Regards \n \nSagar \n \nDesk: +1 \n",
            "dateupdated": 1723735430
        },
        {
            "id": "89dd0347-8f5a-4938-b6d2-c66a50dde944",
            "title": "Data Modeler / Architect with Azure",
            "location": "Minneapolis, Minnesota, USA",
            "company": "Synechron",
            "description": "Job Title: \n \nData Modeler/Architect with Azure \n \nLocation: Minneapolis, MN \n \nFull Time/ Permanent / W2 Contract \n \nHybrid Role \n \nOur Challenge: \n \nWe are looking for a talented and experienced Data Architect to join our dynamic team and help us design and implement complex data models, lead our data analytics initiatives, and provide data architecture support to our clients. The ideal candidate will have a strong understanding of data modeling principles and techniques, create and maintain complex data models, including conceptual, logical, and physical data models, to support various business processes and applications, extensive experience in designing and implementing data models that support our large-scale, complex datawarehouses and data lakes . You will work closely with data engineers, analysts, and stakeholders to ensure that our data architecture is robust, scalable, and aligned with our business needs. A strong SQL skill with Azure knowledge is a definite plus and experience in Banking KYC is advantageous but not essential. \n \nResponsibilities: \n \nData Model Design: Design, develop, and maintain complex data models for large data warehouses and data lakes, ensuring they meet business needs and support data-driven decision-making. \n \nData Architecture: Develop and document data architecture, including data flow diagrams, entity-relationship diagrams, and data dictionaries, to support comprehensive and efficient data management. \n \nSQL Development: Write, optimize, and troubleshoot SQL queries and scripts to support data extraction, transformation, and loading (ETL) processes. \n \nCollaboration: Work closely with data engineers, analysts, and business stakeholders to understand requirements and translate them into effective data models and solutions. \n \nPerformance Tuning: Analyze and optimize data model performance, addressing any issues related to data processing, retrieval, and query execution. \n \nQuality Assurance: Conduct data quality assessments and ensure data models adhere to data governance and quality standards. \n \nTechnology Integration: Utilize Azure technologies and services (such as Azure Data Factory, Azure Synapse, or Azure SQL) where applicable to enhance data integration and processing. \n \nKYC Domain Knowledge: Apply knowledge of Banking KYC requirements to ensure data models support compliance and regulatory needs (preferred but not required). \n \nBest Practices: Stay current with industry best practices, emerging technologies, and methodologies in data modeling and apply them to improve data architecture and practices. \n \nBachelor s degree in Computer Science, Information Systems, or related field. \n \nProven experience as a Data Modeler/Architect with strong proficiency in SQL and database design. \n \nProven experience as a Data Modeler with expertise in data modeling and database design. \n \nProficiency in data modeling tools such as ERwin, ER/Studio, or similar. \n \nStrong understanding of relational databases, SQL, and database management systems. \n \nProficiency in data modeling tools and techniques. \n \nStrong understanding of data governance, data quality, and data security principles. \n \nExperience with Azure technologies (e.g., Azure Data Factory, Azure Synapse, Azure SQL) is preferred. \n \nExperience or familiarity with the Banking KYC domain is preferred but not required. \n \nStrong analytical and problem-solving skills, with the ability to translate complex business requirements into effective data models. \n \nExcellent communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders. \n \nRelevant certifications in SQL and Azure are a plus. \n",
            "dateupdated": 1723733148
        },
        {
            "id": "8a1176d0-2f08-4f2f-a14f-78831cd985df",
            "title": "Technical Architect",
            "location": "Santa Clara, California, USA",
            "company": "Dizer Corp",
            "description": "Job Title: Technical Architect \n \nLocation: Santa Clara, CA (Onsite) \n \nNeed people with 15-plus years of experience from the CA location \n \nDescription: \n \nIn this role you would, \n \nDesign, develop and deploy applications using JAVA/J2EE \n \nDesign and develop containerized Spring boot, Kafka, applications/Microservices APIs/Design pattern and standards \n \nResponsibilities \n \nUnderstand the business process requirement \n \nCode and guide the team \n \nCreate and maintain documentation regarding configuration, processes & security \n \nBuilding \n \nDesign and integrate RESTful and message-based APIs (KAFKA) \n \nDevelop applications using API standards, patterns, and best-practices especially Open API/Swagger, REST, SOAP, Graph QL, Async APIs, JDBC, JSON etc \n \nQualifications we seek in you! \n \nMinimum Qualifications \n \nBE in Computer Science, Information Systems Management, Computer Engineering, or an equivalent combination of education and/or experience \n \nHands-experience with agile methodologies \n \nKnowledge of other programming languages, such as Node, Python and GO \n \nNice to have hands on experience on cloud Kubernetes services such as AKS, EKS, GKE etc \n \nKnowledge and experience with DevOps, CI/CD tools including Jenkins, Maven, ServiceNow, GitHub, Release Management etc \n \nPreferred Qualifications/ Skills \n \nTeam leading capabilities \n \nStrong analytical skills and problem solving skills \n \nExcellent communication skills (written and oral) and problem-solving ability \n \nWrite unit tests with Junit, Mockito etc \n \nThanks, \n \nSaranya Chandrasekaran \n \nTechnical Recruiter | Dizer Corp \n",
            "dateupdated": 1723665598
        },
        {
            "id": "8f0236e5-89e0-4b22-a921-7e5c5df13bae",
            "title": "Devops Engineer",
            "location": "Bentonville, Arkansas, USA",
            "company": "CA-One Tech Cloud Inc.",
            "description": "DevOps person should have hands-on experience on the below: \n \nCreation of CICD pipelines \n \nAutomation of jobs \n \nExperience with Ansible \n \nDashboard creation based on Splunk \n \nCreation of alerts on failures/deployment issues \n \nSplunk/Grafana experience \n \nWorking experience with Windows Server/Linux server \n",
            "dateupdated": 1723738298
        },
        {
            "id": "93ed6afe-8196-4b3d-ad98-16ae0ea8a080",
            "title": "Salesforce B2B commerce cloud developer",
            "location": "Remote",
            "company": "SRI Tech Solutions",
            "description": "Experience in Salesforce B2B commerce Cloud with APEX and LWC knowledge. \n \nDevelop end to end ecommerce experience using B2B commerce cloud, APEX class, triggers and Lightining and Aura components. \n \nIn depth knowledge in B2B architecture, data models and customization. \n \nExperience with RestFul, GraphQL API service architecture. \n \nKnowledge of Ecommerce architecture and understand the flow. \n \nPerform independent code reviews, unit testing and build using Jenkin. \n \nSalesforce B2B Commerce Administration certificate is plus. \n \nDesign and implementation between salesforce and other third party/legacy systems. \n \nExperience in DevOps Copado is a plus. \n",
            "dateupdated": 1723732991
        },
        {
            "id": "94076ec2-1940-40ae-9637-9799cb390b7e",
            "title": "Azure B2X Security",
            "location": "Chicago, Illinois, USA",
            "company": "Nityo Infotech Corporation",
            "description": "Proven experience in implementing security solutions on Azure, with a focus on IAM, MFA, and \n \nSSO \n \n. \n \nIn-depth knowledge of Azure AD, Azure AD B2C \n \n, related authentication/authorization components and security protocols which including SAML, OAuth, and OpenID \n \nStrong scripting and automation skills (PowerShell, Azure CLI) \n \nExcellent understanding of cloud security principles \n \nMicrosoft Certified: Azure Security Engineer Associate certification is a plus. \n \nExperience with Azure Sentinel for monitoring, alerting, and automation. \n \nStrong troubleshooting skills for identifying and resolving IAM-related issues. \n \nAbility to work in a dynamic environment and adapt to evolving security challenges. \n \nExcellent communication and collaboration skills for working with cross-functional teams. \n \nCommitment to maintaining a secure, compliant, and scalable IAM solution. \n",
            "dateupdated": 1723731283
        },
        {
            "id": "941b373d-6223-4196-b683-f6ac188eb8ad",
            "title": "Sr. Web Application Developer",
            "location": "Columbus, Ohio, USA",
            "company": "SR International Inc.",
            "description": "Position Description: \n \nMandatory Requirements: \n \n4 years college degree or equivalent technical study or above \n \n10 years proven work experience as a \n \nFront-end developer \n \n: \n \nDesigning and developing the \n \nweb applications \n \nrobust and scalable web applications from concept to production using \n \nAngular and Web Forms/MVC 5.0 framework in .NET& ASP.NET environment with proficiency in C#, Java Script, CSS, and jQuery \n \nImplementation of interactive \n \nUI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap \n \n; Usage of ORM tools \n \nEntity Framework; \n \nexperience in browser testing and debugging \n \n7 years Hands on experience with \n \nmarkup languages, Angular 8 and above, Bootstrap \n \n7 years Develop and manage \n \nSQL databases by planning, developing, and maintaining the databases using Oracle or Microsoft SQL Server \n \n3 years \n \nAzure DevOps \n \nexperience \n \n5 years hands-on experience using \n \nPython2.7 & above \n \nExperience in Integrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nMust have hands-on experience in: \n \nDesigning and developing the web applications robust and scalable web applications from concept to production using Angular and MVC (5.0) framework in .NET &ASP.NET environment with proficiency in C# and Angular \n \nImplementation ofinteractive UI withAsp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8or better, and Bootstrap; Usage of ORM tools Entity Framework \n \nConverting the ASP.NET Web Forms to Angular Component sand reuse the components in various Modules \n \nAngular CLI for creating components, Services, pipes, Directives \n \nCreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \nVersion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \nBuilding process using Jenkins for Continuous Integration and version control \n \nCreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \nBuilding and maintaining server-side applications and APIs using languages such as Node.js, Python, or Ruby on Rails \n \nIntegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nImplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \nDesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3,and JavaScript frameworks like React, Angular, or Vue.js \n \nDesigning, testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \n \nOptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \n \nImplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \nExperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nExperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nThe ideal candidate would have \n \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nfamiliarity with Micro services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nexperience with continuous integration and deployment (CI/CD) pipelines using Azure Dev Ops Experience (minimum 3 years) \n \nskills to leverage SQL database structure and optimize data storage and retrieval processes for efficient complaint management \n \nbe able to create Data Warehouse functionality by defining and capturing metadata and rules associated with ETL processes in various applications \n \nability to do the security scan the applications and fix the software vulnerabilities within the system \n \nDesired Skills: \n \nExcellent analytical skills, attention to detail, and problem-solving skills. \n \nProven ability to handle multiple tasks and projects simultaneously. \n \nGood communication skills with both technical and non-technical clients \n \nAbility to work with project team member when the requirement is not clear. \n \nMust possess excellent written and oral communication skills. \n \nStrong experience in creating good solutions w/o mature, detailed, codified business requirements. \n \nWorking experience in delivering expected results in unstructured environments. \n \nWorks productively and effectively independently without significant management oversight. \n",
            "dateupdated": 1723671036
        },
        {
            "id": "943093ec-11f4-45c0-a296-63ac98b8525f",
            "title": "Java Full Stack Developer",
            "location": "Remote",
            "company": "Raas Infotek LLC",
            "description": "Position: Java Full Stack Developer \n \nContract: W2 Only \n \nJob Description: \n \nWe are seeking a talented Java Full Stack Developer to join our dynamic team. As a Java Full Stack Developer, you will be responsible for the design, development, and implementation of software solutions using Java technologies. You will work closely with cross-functional teams to deliver high-quality applications. \n \nResponsibilities: \n \nDevelop, test, and implement new software programs using Java technologies. \n \nBuild efficient, reusable, and reliable Java code. \n \nDesign and develop user interfaces using Angular, React, or other JavaScript frameworks. \n \nIntegrate backend services with front-end components using RESTful APIs. \n \nCollaborate with team members and stakeholders to gather and refine specifications and requirements. \n \nTroubleshoot, debug, and resolve issues in production and non-production environments. \n \nParticipate in code reviews and provide constructive feedback. \n \nStay updated on emerging technologies and suggest improvements wherever necessary. \n \nContribute to the overall architecture and design of the software. \n \nRequirements: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent work experience). \n \nProven experience as a Java Full Stack Developer or similar role. \n \nStrong proficiency in Java programming and Spring Framework. \n \nExperience with front-end development using HTML, CSS, JavaScript, and modern JavaScript frameworks (Angular, React, etc.). \n \nFamiliarity with databases (SQL, NoSQL) and ORM frameworks (Hibernate, JPA). \n \nKnowledge of RESTful web services and API development. \n \nExperience with Agile methodologies and DevOps practices. \n \nExcellent problem-solving skills and attention to detail. \n \nGood verbal and written communication skills. \n \nAbility to work effectively in a team environment. \n \nPreferred: \n \nExperience with cloud platforms (AWS, Azure, Google Cloud Platform). \n \nKnowledge of containerization and orchestration technologies (Docker, Kubernetes). \n \nFamiliarity with CI/CD pipelines and automated testing frameworks. \n \nUnderstanding of microservices architecture. \n \nExperience in using version control systems (Git). \n",
            "dateupdated": 1723645393
        },
        {
            "id": "9527b15b-adbd-47ee-8be5-2c9862ecac4e",
            "title": "Sr. Front End Developer@Hybrid--Columbus,OH--Locals",
            "location": "Columbus, Ohio, USA",
            "company": "HUMAC INC.",
            "description": "Sr. Front End Developer \n \nColumbus,Ohio \n \nJob Category \n \nIT \n \nTechnical Skills \n \nSkills \n \nRequired / Desired \n \nAmount Of Experience \n \nDevelopment experience using Angular and Web Forms/MVC 5.0 Framework in .NET & environment with proficiency in #, Java Script, CSS, and jQuery \n \nRequired \n \n10 \n \nDesigning & Implementing user interfaces using modern web technologies such as HTML5, CSS3, and Java Script framework like React, Angular, or Vue.js \n \nRequired \n \n10 \n \nHands on experience with mark-up languages, Angular 8 and above, Bootstrap \n \nRequired \n \n7 \n \nHands on Experience using Python 2.7 & above \n \nRequired \n \n5 \n \nAzure DevOps Experience \n \nHighly Desired \n \n3 \n \nTechnical Documentation skills; Communication skills with both non-technical and technical clients \n \nRequired \n \n5 \n \nJob Description \n \nHybrid : 2 weeks/week \n \nODA is seeking for an experienced, skilled, and motivated senior Front-End web application Developer with responsibility for developing and maintaining both front-end components of ODA web applications. \n \nMandatory Requirements \n \n4 years college degree or equivalent technical study or above \n \n10 years proven work experience as a Front-end developer: \n \nDesigning and developing the web applications robust and scalable web applications from concept to production using Angular and Web Forms/MVC 5.0 framework in .NET & environment with proficiency in C#, Java Script, CSS, and jQuery \n \nImplementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools   Entity Framework; experience in browser testing and debugging \n \n7 years Hands on experience with markup languages, Angular 8 and above, Bootstrap \n \n3 years Azure DevOp experience \n \n5 years hands experience using Python 2.7 & above \n \nUnderstanding of layout aesthetics; Knowledge of SEO principles & Familiarity with software like Adobe Suite, Photoshop, and content management systems \n \nRequired Hands-on Experience: \n \nconverting the  Web Forms to Angular Components and reuse the components in various Modules \n \nAngular CLI for creating components, Services, pipes, Directives \n \ncreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \nversion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \nbuilding process using Jenkins for Continuous Integration and version control \n \ncreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \nin building and maintaining server-side applications and APIs using languages such as Node.js, Python, or Ruby on Rails \n \nintegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nimplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \ndesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3, and JavaScript frameworks like React, Angular, or Vue.js \n \nin designing, testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \n \noptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \n \nimplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nexperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nResponsibilities: \n \nUse markup languages like HTML to create user-friendly web pages \n \nMaintain and improve website \n \nOptimize applications for maximum speed \n \nDesign mobile-based features \n \nCollaborate with back-end developers and web designers to improve usability \n \nGet feedback from, and build solutions for, users and customers \n \nWrite functional requirement documents and guides \n \nCreate quality mock-ups and prototypes \n \nHelp back-end developers with coding and troubleshooting \n \nEnsure high quality graphic standards and brand consistency \n \nStay up to date on emerging technologies \n \nIllustrate design ideas using storyboards, process flows and sitemaps \n \nDesired Skills: \n \nExcellent analytical skills, attention to detail, and problem-solving skills. \n \nProven ability to handle multiple tasks and projects simultaneously. \n \nGood communication skills with both technical and non-technical clients \n \nAbility to work with project team member when the requirement is not clear. \n \nMust possess excellent written and oral communication skills. \n \nStrong experience in creating good solutions w/o mature, detailed, codified business requirements. \n \nWorking experience in delivering expected results in unstructured environments. \n \nWorks productively and effectively independently without significant management oversight. \n \nSkill \n \nRequired / Desired \n \nAmount \n \nof Experience \n \nDevelopment experience using Angular and Web Forms/MVC 5.0 Framework in .NET & environment with proficiency in #, Java Script, CSS, and jQuery \n \nRequired \n \n10 \n \nYears \n \nDesigning & Implementing user interfaces using modern web technologies such as HTML5, CSS3, and Java Script framework like React, Angular, or Vue.js \n \nRequired \n \n10 \n \nYears \n \nHands on experience with mark-up languages, Angular 8 and above, Bootstrap \n \nRequired \n \n7 \n \nYears \n \nHands on Experience using Python 2.7 & above \n \nRequired \n \n5 \n \nYears \n \nAzure DevOps Experience \n \nHighly desired \n \n3 \n \nYears \n \nTechnical Documentation skills; Communication skills with both non-technical and technical clients \n \nRequ \n",
            "dateupdated": 1723667137
        },
        {
            "id": "952c89fd-18a7-4edd-b94b-230353f48474",
            "title": "AI Developer",
            "location": "Remote or Plainsboro Township, New Jersey, USA",
            "company": "Pronix Inc",
            "description": "Job Title: AI Developer /Kore.AI Lead Developer \n \nLocation: Plainsboro, NJ \n \nOverview: \n \nStep into a pioneering role as a AI/Kore.AI Lead Developer, where you'll spearhead a team of innovators to craft state-of-the-art conversational AI solutions. This position offers the chance to blend your technical prowess with leadership skills to create unparalleled conversational experiences. If you are driven by a passion for AI and innovation, this role is your gateway to making a significant impact. \n \nKey Responsibilities: \n \nInnovative Design & Development: Lead the design, development, and maintenance of advanced conversational AI solutions on the Kore.AI platform. \n \nCollaborative Synergy: Work closely with cross-functional teams including product managers, UX designers, and quality assurance to transform requirements into technical blueprints. \n \nArchitectural Excellence: Develop scalable and robust AI architectures that align with strategic goals and project requirements. \n \nAI Craftsmanship: Create sophisticated chatbots and virtual assistants, leveraging programming languages, scripting, and Kore.AI APIs and tools. \n \nIntelligent Conversations: Implement cutting-edge NLP and NLU capabilities to enable smart, context-aware interactions. \n \nQuality Assurance: Uphold code quality through best practices, comprehensive code reviews, and by mentoring junior developers. \n \nDevOps Integration: Collaborate with DevOps teams to streamline continuous integration and deployment pipelines for seamless software releases. \n \nProblem Solving: Proactively troubleshoot and resolve technical issues to ensure uninterrupted operation of AI solutions. \n \nContinuous Learning: Stay abreast of the latest advancements in conversational AI and NLP, applying new insights to enhance development processes. \n \nLeadership & Mentoring: Provide visionary technical leadership and foster a culture of collaboration and innovation within the development team. \n",
            "dateupdated": 1723644665
        },
        {
            "id": "95e77b13-dccf-44ec-9422-18d1a40610ff",
            "title": "Senior DevOps",
            "location": "Kansas City, Kansas, USA",
            "company": "Cynet Systems",
            "description": "We are looking for \n \nSenior DevOps \n \nfor our client in \n \nKansas City, KS \n \nJob Title: Senior DevOps \n \nJob Location: Kansas City, KS \n \nJob Type: Contract \n \nJob Description: \n \nExperience in Continuous Integration Continuous Delivery tools, such as, Jenkins, Cloud bees, etc., and other automation tools. \n \nPreferred Gitlab CICD Experience with APM tool, like, AppDynamics, logging tool, like Splunk Helm charts/Conducktor Docker Kubernetes. \n \nExpertise in one plus of scripting such as Shell, Python and Perl. \n \nExperience working in a cloud environment (public/private)such as AWS/Google Cloud Platform/Azure. \n \nExperience working in an Agile and DevOps environment. \n",
            "dateupdated": 1723658938
        },
        {
            "id": "96897644-35fd-4ab4-aa12-428c5f42f06c",
            "title": "Data Architect",
            "location": "Remote",
            "company": "Tekcel8",
            "description": "Title: \n \nSenior Data Architect \n \nLocation: \n \nRemote \n \nDescription: \n \nMust hold Public Trust \n \nWe offer remote work opportunities for those residing in the following states ONLY: \n \nAZ, AK, AR, CO, FL, HI, IA, ID, IL, KS, LA, MD, MN, MO, MT, NE, NV, NM, NC, ND, OK, OR, SC, SD, TN, TX, UT, VA/DC, WA, WI, WY \n \nKey Skills: \n \nAzure \n \nDatabricks, Data Factory \n \nSnowflake is preferred \n \nJob Summary: \n \nThe Sr Data Architect will be responsible for design and implementations of data strategy as it relates to data lakes, data warehouse, and data marts.  The primary responsibility will be a focus on data sourcing, data integration, and data modelling to ensure systems meet the analytical needs of business users.  The role will work closely with the project development teams and project support teams to ensure the right architecture is implemented across multiple work streams.  The role will also develop standards (data definition, tools, and platforms) as related to information management, data warehouse, data governance, and business intelligence. \n \nKey Responsibilities: \n \nArchitect data lake, data warehouse and data marts to meet online efficiency requirements. \n \nAct as an advisor to Director of Data Services on data strategy. \n \nRepresent data services in Data Governance efforts. \n \nResearch, Review and Recommend new technologies. \n \nWork closely with Enterprise Data Architect to ensure strategies align and mentor and collaborate with other data architects to ensure consistency across the enterprise. \n \nCreate conceptual, logical, and physical data models for online application transactions. \n \nTranslate enterprise or business requirements into long-term online information and data architecture solutions. \n \nCollaborate with users, business analysts, developers, database administrators, and project managers. \n \nPerform data profiling and data quality validation processes. \n \nDevelop and implement metadata management, data dictionary, data quality, data profiling, data security, shared data usage, and data cleansing standards. \n \nEnsures compliance with TriWest HIPAA, privacy, and government security policies \n \nRequired: \n \nBachelor s degree in computer science, Information Systems, or related experience \n \nMinimum of 5 years of experience in Data Warehousing \n \nMinimum of 5 years of experience as a Data Architect \n \nMinimum of 10 years in a data driven environment with relation to migration and conversions \n \nMinimum of 5 Years ETL experience preferably in Azure (Datafactory / Databricks) \n \nStrong knowledge of Azure Cloud Architecture \n \nMinimum of 5 Year ETL development preferably SSIS \n \nProficient with SQL Server (On Prem and Azure Cloud) \n \nKnowledge or change data capture tools (CDC) \n \nStrong knowledge of data warehouse design and architecture (Kimball / Inmon) \n \nExperience with ERwin, ER/Studio, or other data modeling tool \n \nStrong knowledge of data protection tools and use cases (Encryption / Masking / De-Identification) \n \nPreferred: \n \nExperience with data related to health care \n \nExperience with Snowflake \n \nExperience with Tableau / PowerBI \n \nExperience with Oracle Databases \n \nExperience with Salesforce Healthcloud \n \nTechnical Skills: \n \nStrong knowledge of online data stores design; advanced data modeling skills; proficiency with SQL; some experience with data extraction, transformation, and loading (ETL); working knowledge of SQL Server databases; working knowledge of Oracle databases; familiarity with Kimball and Inmon design paradigms. \n",
            "dateupdated": 1723737964
        },
        {
            "id": "976a2bfd-6c13-4770-9100-61b3b4532c48",
            "title": "Enterprise Architect",
            "location": "Plano, Texas, USA",
            "company": "VDart, Inc.",
            "description": "Job Title: \n \nEnterprise Architect \n \nLocation: \n \nPlano, TX \n \nDuration /Term: \n \nContract \n \nRoles & Responsibilities Include: \n \nContribute to an overall Enterprise Architecture strategic plan. Establish, develop, and promote standard architecture, frameworks and guidelines. \n \nAnalyze complex business and technical problems related to the implementation of new technology and/or the customization of existing technologies. \n \nPartner with other technology teams to work with business executives and end users to conceptualize new application projects, recommend technologies and implementation strategies. Then architect/design for requirements of the project within financial and timeline guidelines. \n \nUnderstand the changing business needs of the organization/projects and recommend viable strategies for the future. \n \nAuthor and/or Review architecture/design and other technical documents ensuring high quality deliverables and systems development across tech stacks and applications teams. \n \nReview code and technical approaches for problem solving to ensure functional and non-functional requirements are met in an effective and high-quality manner. \n \nProvide guidance and mentor technical teams across multiple architecture styles and technologies to ensure high quality design/implementation, re-use of enterprise/common patterns, improve code quality and testability/maintainability. \n \nScrutinize project effort estimations from vendors driving down costs by ensuring standard design practices and removing duplication of effort. \n \nHands-on development creating proof of concepts and maintaining small development projects. \n \nHelp ensure high quality software delivery by providing guidance on testing strategy, providing technical consultation to plan/design performance testing and profiling of application, and providing feedback/guidance for tuning performance and other non-functional elements of the application. \n \nExperience & Qualifications Include: \n \nDeep expertise on Kubernetes, Dockers, Containerization and Virtualization \n \nMinimum 10 years of experience in Solution, Design and Development of applications using J2EE, Spring Boot, RESTful services and Angular \n \nExperience in designing and Implementing cloud-based solutions using AWS \n \nExperience In design and development of Microservice using Spring boot and REST API \n \nExperience in DevOps tool chain (Jenkins, Artifactory, Ansible/Chef/Puppet/Spinnaker, Maven/Gradle, Atlassian Tool suite) \n \nGood knowledge of database concepts and integration with business application development \n \nHands on AWS Cloud Architecture experience including migration of on premise legacy applications to AWS. \n \nPublic/Customer facing high volume transactional web applications custom app or ASP/SaaS implementations \n \nHands-on architecture/design for web sites that are highly scalable and built in enterprise environments. \n \nJava EE and Spring frameworks, JavaScript Frameworks: AngularJS and JQuery. \n \nCode Quality systems: SonarQube, Sauce Labs, JFrog XRay \n \nWeb Services/ESB/Integration technologies including REST and SOAP based services. \n \nApplication Servers such as JBoss, Tomcat, Weblogic. \n \nExperience with scripting languages using Unix \n \nDegree in Computer Science, Engineering or equivalent. \n \nVDart Group, a global leader in technology, product, and talent management, empowers businesses with comprehensive solutions through our four distinct, industry-leading business units. With a diverse team of over 4,000 professionals across 13 countries, we deliver strong results across various industries, including Fortune 500 companies. \n \nLeveraging our deep expertise as a global provider of resources and solutions, we serve a wide range of industry verticals, including BFSI, Automotive, Healthcare, Mobility, Energy, Life Sciences, Manufacturing, Consumer Industries, and Technology. With over 16 years of experience, VDart has evolved to meet the needs of leading technology brands, placing and training more than 20,000 professionals and shaping the industry's future. \n \nOur continuous reinvention, providing resources for IT solutions and unique digital solutions, has positioned us as a top growth leader in digital talent management and technology consulting. \n \nCommitted to \"People, Purpose, Planet,\" we prioritize social responsibility and sustainability, as evidenced by our EcoVadis Bronze Medal Certification and participation in the UN Global Compact. \n \nOur dedication to delivering strong results has earned us recognition as a trusted advisor for businesses seeking to drive innovation and growth, including many Fortune 500 companies. \n \nJoin our network! Partner with VDart Group to leverage our global network, industry expertise, and proven track record with a diverse clientele. \n",
            "dateupdated": 1723675743
        },
        {
            "id": "97ae714d-e932-443f-9127-0c0e485f8ec2",
            "title": "Azure ML Architect with Data Bricks",
            "location": "Santa Clara, California, USA",
            "company": "SBS Corp.",
            "description": "4 days a week onsite at Santa Clara, CA \nExperience in designing and implementing scalable and secure Azure cloud solutions using Data Bricks ML platform. \n \nModel development , deployment and job scheduling using unstructured data. \n \nCertification in databricks ML \n \nExpert level in Designing and Architect solutions in Azure Data factory, Azure Databricks, Azure Datalake, Delta Lake and Azure synapse analytics implementation. \n \nExperience in Azure cloud technologies like PySpark, Synapse, ADF, Databricks, Python, Scala and SQL. \n \nHave good experience configuring Microservices using Docker, Kubernetes on Azure Data Bricks \n \nExtensive Experience on working on Azure AI services including Data Bricks and Azure cognitive services \n \nHighly preferred experience on working with Azure OpenAI services \n \nHands-on experience on design, and optimizing LLM, natural language processing (NLP) systems, frameworks, and tools.",
            "dateupdated": 1723659324
        },
        {
            "id": "982fc869-a0e6-418a-a32e-134a9828d8f1",
            "title": "Java Microservices Developer",
            "location": "Englewood Cliffs, New Jersey, USA",
            "company": "Marlabs LLC",
            "description": "Roles and Responsibilities: \n \nDesign, develop, test, deploy and maintain scalable Java-based microservices using Spring Boot. \n \nCollaborate with cross-functional teams to identify requirements and implement solutions that meet business needs. \n \nEnsure high availability, scalability, security, and performance of cloud-based applications on AWS platform. \n \nImplement DevOps practices such as continuous integration/continuous deployment (CI/CD) pipelines using tools like Jenkins or similar technologies. \n \nParticipate in code reviews to ensure adherence to coding standards and best practices. \n \nDesign, develop, test, deploy, and maintain Java-based microservices using Spring Boot framework. \n \nCollaborate with cross-functional teams to identify requirements and implement solutions that meet business needs. \n \nEnsure high availability, scalability, security, and performance of the system by following best practices in software engineering. \n \nParticipate in code reviews to ensure adherence to coding standards and quality guidelines. \n \nTroubleshoot issues related to application deployment on cloud platforms like AWS or Azure. \n \nJob Requirements: \n \nStrong understanding of Microservices architecture principles and design patterns. \n \nProficiency in writing clean, modularized code using Spring Boot framework. \n \nDeveloping RESTFUL Microservices using spring boot. \n \nExperience working with CI/CD pipelines using Maven/Jenkins/Azure DevOps. \n",
            "dateupdated": 1723647393
        },
        {
            "id": "98ddeb4a-dbef-4c0f-bbb0-9edb58064734",
            "title": "Sr Power Platform Developer -Hybrid -Richmond, VA-Need locals",
            "location": "Richmond, Virginia, USA",
            "company": "Cerebra Consulting Inc",
            "description": "Cerebra Consulting Inc is a System Integrator and IT Services Solution provider with a focus on Big Data, Business Analytics, Cloud Solutions, Amazon Web Services, Salesforce, Oracle EBS, Peoplesoft, Hyperion, Oracle Configurator, Oracle CPQ, Oracle PLM and Custom Application Development. Utilizing solid business experience, industry-specific expertise, and proven methodologies, we consistently deliver measurable results for our customers. Cerebra has partnered with leading enterprise software companies and cloud providers such as Oracle, Salesforce, Amazon and able to leverage these partner relationships to deliver high-quality, end-to-end customer solutions that are targeted to the needs of each customer. \nHello, \nJob Title: Sr Power Platform Developer \n \nLocation: Hybrid -Richmond, VA-Need locals \n \nContract: 24 months \n \nJob Description \n \nLooking for an experienced hands-on senior SharePoint and Power Platform developer. The Senior Microsoft Power Platform Developer will be responsible for developing applications using Microsoft Power Platform components like Power Apps including both canvas apps model-driven apps Power Automate among others by following the best practices and methodologies. \nThe successful candidate should have strong communication skills to be effective in both technical and business requirement discussions. Primary responsibilities include: \nConfigure Dataverse \nCreate and configure Power Apps\\\\Power Automation both Canvas and Model-driven Apps \nConfigure business process automation \nLead functionality discovery workshops and requirements gathering sessions \nProgramming experience using .NET SQL Azure and C# \nUnderstand the business and its challenges functionally map a solution to the identified use cases and then develop an APP using Power Platform \nExperience with API or rest services integrations with an understanding of how to implement solutions with multiple data sources \nCertifications in PowerApps Professional or PowerApps Developer \nParticipate in code reviews \nEnforce standards and best practices \nTroubleshoot Power Platform issues document solutions and work with system administrators and other IT resources to implement fixes. \nCreate design solutions and document for common use case scenarios \nPreferred Experience with Devops in Power Platform Power Pipelines/ALM Accelerator \nDevelop and disseminate documentation requirements recommendations technical analysis etc. on platform usage. \nPrepare mockups/prototypes based on requirements and use knowledge of Power Platform features/tools to offer solutions that meet business needs. \nAdhere to best practices when implementing business solutions and define/refine a governance approach for the platform's use. \nParticipate in Agile SDLC \nThanks \n \nSai Revanth \n \nEmail \n \n- \n \nLinkedIn | \n",
            "dateupdated": 1723736758
        },
        {
            "id": "9a7313d3-2053-4a6c-9e4b-eee99ae3a689",
            "title": "Data Governance Analyst (Azure Data lake, Databricks, SQL)",
            "location": "St. Louis, Missouri, USA",
            "company": "Denken Solutions",
            "description": "Currently, we are looking for talented resources for one of our listed clients. If interested please reply to me with your updated resume or feel free to reach out to me for more details at \n \nTitle: Data Governance Analyst \n \nLocation: St. Louis, MO \n \nDuration: 12 months \n \nSummary: \n \nAs a Data Governance Data Engineer at Client, this position will be responsible for implementing and integrating data management applications, including Master Data Management (MDM), Data Catalog, and Data Quality. \n \nYour primary focus will be on automating and administering these technologies to ensure the smooth operation of data governance solutions for stakeholders. \n \nThe successful candidate will excel in application configuration, data integration, pipeline development, resource monitoring, and translating and executing use cases to enable effective data stewardship. \n \nThis role requires strong collaboration with various teams to ensure data governance processes align with business needs and objectives. \n \nPrimary Responsibilities: \n \nDesign, construct, deploy, test, and support solutions and applications using the MDM platform and related technologies, including Python, Azure Data Factory, Databricks, and APIs. \n \nServe as the technical subject matter expert (SME) for the MDM platform, overseeing its integrations and data flows to ensure optimal performance and reliability. \n \nDevelop and maintain data pipelines in a cloud environment, preferably Azure, utilizing cloud-based data environments like Azure Data Lake for storage and management. \n \nDesign, construct, deploy, test, and support data storage in big data constructs, relational databases, and other database technologies to meet data governance needs. \n \nAssess and evaluate system designs to ensure adherence to architecture and design best practices, optimizing for efficiency and scalability. \n \nTranslate and execute use cases into effective data stewardship models, ensuring compliance with all applicable Client standards and regulatory requirements. \n \nMonitor resources and troubleshoot technical and data-related issues, providing timely resolution to ensure uninterrupted data management operations. \n \nCommunicate issues, risks, concerns, and status to management promptly, ensuring transparency and effective risk management. \n \nCollaborate with various teams to align data governance processes with business needs and objectives, contributing to team goals through iterative and agile development practices. \n \nDevelop and interact with APIs, performing data mapping of incoming data sources and configuring MDM and Data Catalog tools accordingly. \n \nConnect and integrate data sources with MDM and data catalog tools, ensuring accurate and reliable data integration and management. \n \nBasic Qualifications (Minimum): \n \nEducation: \n \nA.S. Degree or equivalent experience in a related field \n \nRequired Skills: \n \nExperience with cloud-based data environments, such as Azure Data Lake \n \nExperience in building, deploying, and maintaining data pipelines in a cloud environment, preferably Azure. \n \nExperience with Databricks for enhancing capabilities in data processing, analysis, and automation tasks. \n \nDesired Skills: \n \nExtensive experience in data modeling, architecture, analysis, and management. \n \nModerate to expert-level SQL skills. \n \nShe has demonstrated the ability to troubleshoot and resolve technical and data-related issues. \n \nExcellent interpersonal and communication skills, both verbal and written. \n \nAbility to create and convey detailed and accurate requirements to stakeholders, partners, and management. \n \nExperience with master data management and solution configuration, preferably Profisee. \n \nExperience with related technologies such as Alation, Collibra, and Purview is a plus. \n \nProficiency in developing and interacting with APIs. \n \nFamiliarity with data quality concepts and tools to ensure accurate and reliable data integration and management. \n \nAbout us: \n \nAt our organization, we take our mission and values to heart! We are on a mission to offer more and better jobs all over the world! Our goal is to care for you while you care for our clients and get you paid the highest pay possible. All our associates working with us are expected to embrace our RACE values: R - Results Matter, A- Approachable, C - Care, and E - Emergency i.e. work with a sense of urgency. \n \nFor more relevant job opportunities please visit our website: \n",
            "dateupdated": 1723648185
        },
        {
            "id": "9f7f7c12-2611-4a41-be22-b4c4acb71557",
            "title": "Java Technical Architect",
            "location": "Santa Clara, California, USA",
            "company": "Dizer Corp",
            "description": "Java Technical Architect \n \nLocation - Santa Clara, CA \n \nOnsite \n \nOnly Local candidates are considered. Relocation candidates will not be considered. \n \nNeed people with 15 plus years of experience. who can work from office in Santa Carla, CA \n \nDesign, develop and deploy applications using JAVA/J2EE \n \nDesign and develop containerized Spring boot, Kafka, applications/Microservices APIs/Design pattern and standards \n \nResponsibilities \n \nUnderstand the business process requirement \n \nCode and guide the team \n \nCreate and maintain documentation regarding configuration, processes & security \n \nBuilding \n \nDesign and integrate RESTful and message-based APIs (KAFKA) \n \nDevelop applications using API standards, patterns, and best-practices especially Open API/Swagger, REST, SOAP, Graph QL, Async APIs, JDBC, JSON etc \n \nQualifications we seek in you! \n \nMinimum Qualifications \n \nBE in Computer Science, Information Systems Management, Computer Engineering, or an equivalent combination of education and/or experience \n \nHands on experience with agile methodologies \n \nKnowledge of other programming languages, such as Node, Python and GO \n \nNice to have hands on experience on cloud Kubernetes services such as AKS, EKS, GKE etc \n \nKnowledge and experience with DevOps, CI/CD tools including Jenkins, Maven, ServiceNow, GitHub, Release Management etc \n \nPreferred Qualifications/ Skills \n \nTeam leading capabilities \n \nStrong analytical skills and problem solving skills \n \nExcellent communication skills (written and oral) and problem-solving ability \n \nWrite unit tests with Junit, Mockito etc \n \nThanks & Regards \n \nShobana Prabhakar |Technical Recruiter |Dizer Corp. \n \n| \n",
            "dateupdated": 1723733053
        },
        {
            "id": "a493a6e0-23a8-4c6b-ab04-08500fce7b8f",
            "title": "Lead Azure Data Engineer(15 + Years Required)",
            "location": "Fremont, California, USA",
            "company": "GSPANN Technologies",
            "description": "About GSPANN \n \nHeadquartered in Milpitas, California (U.S.A.), GSPANN provides consulting and IT services to global clients, ranging from mid-size to Fortune 500 companies. With our experience in retail, high-technology, and manufacturing, we help our clients to transform and deliver business value by optimizing their IT capabilities, practices, and operations. Counting on our ten offices, including four global delivery centers, and approximately 1400 employees globally, we offer the intimacy of a boutique consultancy with capabilities of a large IT services firm. \n \nAzure Data Engineer \n \nLocation-Fremont, CA / Remote \n \nJob Type-Long Term \n \nMust have Skills : \n \nMin 5 years of experience in modern data engineering/data warehousing/data lakes technologies on cloud platforms like \n \nAzure, AWS, Google Cloud Platform, Data Bricks etc. Azure experience is preferred over other cloud platforms. \n \n10 + years of proven experience with \n \nSQL, schema design and dimensional data modelling. Hands on experience in SQL is a MUST. \n \nSolid knowledge of data warehouse best practices, development standards and methodologies \n \nHands on experience with \n \nETL/ELT tools like ADF, Informatica , Talend etc., and data warehousing technologies like Azure Synapse, Azure SQL, Amazon redshift , Snowflake , Google Big Query etc.. \n \nStrong experience with \n \nbig data tools(Databricks , Spark etc..) and programming skills in PySpark and Spark SQL. \n \nBe an independent self-learner with let s get this done approach and ability to work in Fast paced and Dynamic environment. \n \nExcellent communication and teamwork abilities. \n \nNice-to-Have Skills: \n \nEvent Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, Cosmo DB knowledge. \n \nSAP ECC /S/4 and Hana knowledge. \n \nIntermediate knowledge on Power BI \n \nAzure DevOps and CI/CD deployments, Cloud migration methodologies and processe \n \nWorking at GSPANN \n \nGSPANN is a diverse, prosperous, and rewarding place to work. We provide competitive benefits, educational assistance, and career growth opportunities to our employees. Every employee is valued for their talent and contribution. Working with us will give you an opportunity to work globally with some of the best brands in the industry. The company does and will take an affirmative action to employ and advance in the employment of individuals with disabilities and protected veterans, and to treat qualified individuals without discrimination based on their physical or mental disability status. GSPANN is an equal opportunity employer for minorities/females/veterans/disability. \n",
            "dateupdated": 1723735614
        },
        {
            "id": "a6563acf-5c50-4830-8929-366130e3a025",
            "title": "Cybersecurity Engineer (Azure / MS Defender) (414654)",
            "location": "Dallas, Texas, USA",
            "company": "Vaco Technology",
            "description": "Cybersecurity Engineer | 414654 \n \nDETAILS \n \nLocation \n \n: Dallas, TX 75254 (3-days per week onsite [T / W / TH]) \nPosition Type \n \n: 6M C2H \nHourly / Salary \n \n: BOE! \nJOB SUMMARY \n \nVaco Technology is currently seeking a Cybersecurity Engineer for a 6M C2H opportunity located in Dallas, TX 75254 (3-days per week onsite [T / W / TH]).  The Cybersecurity Engineer will execute the Cybersecurity / IAM Strategy, to identify and mitigate cyber threats.  The Cybersecurity Engineer will design, document, implement, and maintain cybersecurity processes and systems.  The Cybersecurity Engineer will ensure the appropriate levels of security across users, devices, cloud resources, and applications.  The Cybersecurity Engineer will assist in M&A related activities, in relation to Cybersecurity, IAM issue identification, and development of risk mitigation plans. \nManage Incidents / Investigations - MS Defender / Sentinel \n \nPlan / Implement / Manage IAM Solutions - Azure AD / Entra, etc. \n \nAdminister User Accounts / Permissions / Access Controls for Internal / External Users / Devices / Applications \n \nConfigure / Manage Authentication / Authorization Protocols - SSO / SAML / OAuth / OpenID Connect \n \nMonitor / Audit IAM Activities / Events - Report on Compliance / Performance Metrics \n \nInvestigate / Resolve IAM Issues / Incidents - Provide Technical Support / Guidance to Users / Stakeholders \n \nReview / Update IAM Policies / Procedures / Best Practices \n \nResearch / Evaluate New IAM Technologies / Trends - Recommend Improvements / Enhancements \n \nAbout the Project \n:  There are 2 team members currently on their Cybersecurity Team (Cybersecurity Director / Cybersecurity Engineer).  This will be the 3 \nrd \naddition to their team with the goal of adding 1 additional Cybersecurity Engineer in the 4 \nth \nquarter of 2024.  Because the team size is small in nature and because they are not a silohed environment, it is imperative that any new addition is a MS Cybersecurity SME that is capable of moving seamlessly between any area of MS Cybersecurity.  Essentially, they need an SME who is confident across ALL areas of MS Cybersecurity so that you have either already encountered similar issues and know how to resolve them and/or you know how to locate the answer quickly and implement.   The Cybersecurity Engineer will have ownership of envisioning, planning, deploying, and optimizing MS Cybersecurity Solutions, ensuring they align seamlessly with their unique security, technical, and business initiatives. \nJOB REQUIREMENTS \n \nCybersecurity Certifications (required) - CISSP (strongly preferred), SC-900, AZ-500, etc. \n \nCybersecurity Engineer - MS Azure AD (Conditional Access / PIM / AzIP / Azure MFA) / IAM / Entra / AD \n \nIAM Tools / Concepts (advanced) - Active Directory / LDAP / Azure AD / PIM / RBAC / Identity Federation / Separation of Duties / Least Privilege, etc. \n \nMS Security Solutions Deployment (hands-on) - M365 Defender (AAD IPC / MDO / MDE / MCAD / MDI) / MS Sentinel / Defender for Cloud / Azure Arc / InTune / MS Information Protection \n \nManage Incidents / Investigations - MS Defender / Sentinel \n \nAuthentication / Authorization Protocols (in-depth) - SSO / SAML / OAuth / OpenID Connect \n \nInfrastructure Architecture (understand of various components) - OnPrem / Hybrid Public Cloud / End-User Technology / Virtualization / Security / LAN/WAN / Data Center, etc. \n",
            "dateupdated": 1723738283
        },
        {
            "id": "a7005875-7d93-400e-9a5e-1939f7ed9b3b",
            "title": "Scrum Master(Local to VA)",
            "location": "Richmond, Virginia, USA",
            "company": "Solomons International",
            "description": "The Virginia Department of Transportation (VDOT) Information Technology Division is seeking a senior technical Project Scrum Master to drive the project delivery of the development and implementation of a cloud-based data management platform that will support the agency s data management needs. The successful candidate will have a proven track record of developing and implementing effective cloud-based solutions for complex data management problems. The candidate must have data security, cloud infrastructure, with knowledge of transportation related data preferred. \n \nThe selected candidate will: \n \nDrives consistent project delivery through the entire project lifecycle, including: project plans, release plans, resource allocation, and management of project risks, scope, schedule, and delivery of value. \n \nCoordinates Agile Ceremonies such as Sprint Planning, Daily Standups, Retrospectives, Sprint Demos, Story Refinement, and Release Planning. \n \nTracks and communicates project's progress from a schedule, cost, and risk perspective to the project team, stakeholders, and management. \n \nEstablishes an environment where the teams can be effective and helps removing obstacles. \n \nProtects the team from outside interruptions and distractions. \n \nEnsures a good relationship between the team and product owner as well as others outside the team. \n \nTracks and reports team velocity and other project metrics. \n \nPromotes continuous improvement and helps teams to increase productivity. \n \nHelps Product Owner and team with Product backlog management. \n \nAdheres to VDOT and VITA project management practices as defined. \n \nAdditional responsibilities as assigned. \n \nCommunicate timelines and expectations to technical and business staff. \n \nCollaborate with stakeholders to understand project requirements and support data management needs. \n \nEnsure data is collected, stored, and processed securely and in compliance with all applicable regulations. \n \nAnalyze data and provide insights to support decision-making by project management teams. \n \nProvide training and support for end-users to ensure the platform is used effectively. \n \nDemonstrable capability and experience in planning, implementing and maintenance of local master data systems and processes across business units and functions. \n \nUnderstanding of data and leveraging it to deliver business value. Ability to discuss requirements with data teams \n \nExperience in data governance concepts, and data governance implementations. \n \nAbility to use agile approach and methodology to drive master data governance processes. \n \nEnsure documentation of requirements and uses cases, facilitate design workshops for assigned project. \n \nEnsure definition of test objectives, designed test plans and test cases for assigned project. \n \nProvide the management of project milestones and deliverables for on-time and on-budget delivery. \n \nDefine, measure, and clearly communicate progress with metrics. \n \nQualifications \n \nSolid understanding of software development life cycle models as well as expert knowledge of Agile project management principles and practices. \n \nExperience managing cloud-based solutions for data management and analytics. \n \nAbility to work with customers, understand their business practices and manage their expectations. \n \nAbility to set clear performance standards and hold team members accountable, while keeping team engaged and on track. \n \nAbility to help Product Owners to create and prioritize Product Backlog. \n \nStrong interpersonal skills including mentoring, coaching, collaborating, and team building. \n \nStrong analytical, organizational and decision-making skills. \n \nAbility to analyze and document business and system processes. \n \nAbility to balance the competing demands for quality, scope, schedule, and cost. \n \nWell-versed with Scrum and Kanban Agile methodologies. \n \nPMP and CSM Certifications required. \n \nSAFe Certification preferred. \n \nExperience with SAFe framework is a plus. \n \nPreferred: \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nExcellent analytical, problem-solving, and communication skills. \n \nKnowledge of transportation data and project management with transportation data is a plus. \n \nExperience in IT Infrastructure delivery(networking, physical plant, vendor management, site provisioning) is preferred. \n \nExperience managing large, multi-stream projects. \n \nPMP or Qualified under Commonwealth of Virginia Qualification Standards for IT Project Managers for Category 4Projects. See: \n \nMicrosoft Office products (Word, Excel, Access, Outlook, Visio, PowerPoint, Project Server) \n \nRequired/Desired Skills \n \nSkill \n \nRequired /Desired \n \nAmount \n \nof Experience \n \nExperience managing cloud-based solutions for data management and analytics. \n \nRequired \n \n8 \n \nYears \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nRequired \n \n8 \n \nYears \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nRequired \n \n8 \n \nYears \n \nKnowledge of transportation data and project management with transportation data is a plus \n \nRequired \n \n8 \n \nYears \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nRequired \n \n8 \n \nYears \n \nTechnical Business Analyst understanding of data integration and data project \n \nRequired \n \n8 \n \nYears \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nRequired \n \n8 \n \nYears \n \nExperience in both Agile and Waterfall project management. & Agile Scrum Maste \n \nRequired \n \n8 \n \nYears \n",
            "dateupdated": 1723644184
        },
        {
            "id": "aa427d47-80ee-488d-908f-ba7f8853bf61",
            "title": "Sr. Infrastructure Engineer",
            "location": "Richmond, Virginia, USA",
            "company": "Datasoft Technologies, Inc.",
            "description": "Sr. Infrastructure Engineer \nHybrid \nAbout the Job \nDuration: 12 Months Contract (possibility of extension) \n \nLocation: Hybrid- Richmond, VA \n \nPay rate: Hourly, depending on experience \n \nJob ID: 744400 \n \nResponsibilities: \nWe are seeking a highly skilled Senior Infrastructure Engineer with extensive experience managing Windows Server environments in both on-premises and cloud-based settings. The ideal candidate will have a proven track record in patching, backups, migrations, and implementing Active Directory. They should be adept at supporting a range of applications including Java, .Net, Oracle, Microsoft Dynamics, and various Warehouse technologies. The role demands both server-level support and custom production application support expertise. \n \nThe candidate should be familiar with security tools such as Tenable and have experience with SCCM and automated patch management. Proficiency in server security configurations, including end-point protection, is essential. Strong networking knowledge and in-depth understanding of OSI layer functionality and protocols are required. Experience with disaster recovery (DR) processes is crucial. Preferred qualifications include certifications as a Systems Engineer and Network Engineer. \n \nQualifications: \nExperience working with Windows Server in hybrid environments (on-premises and cloud). \n \nExperience providing guidance on disaster recovery/uptime management, best practices for infrastructure stability, etc. \n \nExperience performing regular patching and updates to ensure system security and stability. \n \nExperience overseeing backup operations and recovery processes in mission-critical environments. \n \nExperience planning & executing server migrations, including moving workloads from on-premises to the cloud. \n \nComfortable working in an environment that utilizes multiple frameworks/technologies, including .NET, Java, SQL, Oracle, Microsoft Dynamics, and more. \n \nExperience providing server-level support and troubleshooting issues for production applications. \n \nExperience working with security tools such as Tenable to manage vulnerability remediation, etc. \n \nExperience with tools like SCCM for automated patch management & deployment. \n \nExperience crafting disaster recovery (DR) plans to ensure minimal downtime and prevent data loss. \n \nStrong networking knowledge - including understanding OSI layer functionality and network protocols. \n \nAbility to work with cross-functional teams to address infrastructure needs and support application deployment. \n \nNice-to-haves: \nMicrosoft-focused certifications, such as: Azure Administrator Associate, Windows Server Hybrid Administrator Associate, etc. \n \nNetworking-focused certifications, such as: Network+, CCNA, etc. \n \nAbout our Company \n \nDataSoft Technologies is a highly recognized provider of professional IT Consulting services in the US. Founded in 1994, DataSoft Technologies, Inc. provides staff augmentation services for Information Technology and Automotive Services. Our team member benefits include: \nPaid Holidays/Paid Time Off (PTO) \n \nMedical/Dental Insurance \n \nVision Insurance \n \nShort Term/Long Term Disability \n \nLife Insurance \n \n401 (K) \n",
            "dateupdated": 1723644322
        },
        {
            "id": "ac036861-7c89-4e47-9024-8c511b25f5e8",
            "title": "Sr Azure Data Engineer + Healthcare/Pharma/Life science industry- Remote - W2 only - 10+ years candidates",
            "location": "Remote",
            "company": "Empower Professionals",
            "description": "Role: Sr Data Engineer \n \nLocation \n \n: \n \nRemote \n \nDuration: 6+ Months CTH \n \nW2 Only \n \nAdditional Info: Remote, EST hours. Background, Drug test, and flu shot \n \nProject Details: The client is a large healthcare system located in North Carolina. They are currently working through a myriad of healthcare initiatives and have a strong need on their data analytics team.\u00a0 The team is looking for an engineer to join the team ready to hit through ground running helping their engineers map out how to stand up their data lakes. \n \nMust Have Skills: \n \n\u2022 Azure Specific experience \n \n\u2022 Data Lake-stand up experience \n \n\u2022 Postgres SQL server experience \n \n\u2022 Moving data from on prem to the cloud and mapping the data \n \n\u2022 Experience within healthcare \n \nEducation/Certification Requirements: \n \nRequires a bachelor\u2019s degree in computer science, Information Systems, Business Administration or other related field or equivalent experience \n \nThanks \n \nAayushi \n \nSenior Technical Recruiter/Lead\u00a0|\u00a0Empower Professionals \n",
            "dateupdated": 1723732494
        },
        {
            "id": "affedc41-2030-460a-8e52-153bceb5923b",
            "title": "Data Engineering Lead - Azure",
            "location": "Atlanta, Georgia, USA",
            "company": "Indus Group Inc",
            "description": "Data Engineering Lead - Azure \n \nContract to Perm \n \nAtlanta, GA \n \nThe Data Engineering Lead (Marketing) position is part of our client s IT Marketing Technology team focused on enabling the development and roll-out of world-class modern Marketing Data Engineering capabilities. This role partners with teams responsible for Marketing and Digital Guest Engagement platforms that leverage world-class technology to create personalized, relevant, data-driven experiences. \n \nIn this role, you will lead teams designing and building Data & BI solutions that capture, explore, transform, and utilize curated data to support Marketing Business Unit s Data-driven transformation journey and decision-making process. In addition to leading the design and implementation of data products, you will also mentor and develop a team of contingent worker data engineers onsite and offshore. \n \nThe ideal candidate will have strong Microsoft Azure Cloud skills - Azure Data Factory, Azure Databricks, Power BI, SQL, Ability to guide and mentor junior engineers, Data and Analytics Thought leadership, and a passion towards Data and Analytics. \n \nResponsibilities: \n \nDevelopment (20%) \n \nDesign and implement scalable data solutions on Azure platform using Data Factory, Databricks, PySpark, Python and other related services. \n \nBuild data pipelines and workflows to ingest, transform, and load data from various sources. \n \nDevelop and maintain data models and schemas for efficient data storage and retrieval. \n \nDevelop and maintain CI/CD pipelines for automated deployment and testing of data solutions. \n \nLead development and production deployment of analytic Data and BI products (also potentially pilots and proof of concepts), determining appropriate design strategies and methodologies. \n \nMentoring (20%) \n \nManage and lead a technical team responsible for data engineering and analysis focusing on individual's professional development as well as overall team health and technical proficiency on their assigned project tasks. \n \nConduct product work reviews with team members. \n \nServe in the development of team members by actively facilitating new learning opportunities and experiences in the Data Engineering space. \n \nThought Leadership (20%) \n \nProvide industry thought leadership to fellow team members across business and technical project dimensions, solving complex business requirements. \n \nProactively consider the future state of the organization and how technology can support these efforts. \n \nAdvocate and define Marketing Data Engineering vision from a strategic perspective, including internal and external platforms, tools, and systems. \n \nMaintain overall MarTech industry Data knowledge on latest trends, technology, etc. \n \nCollaborations (20%) \n \nCollaborate and maintain relationships with cross-functional teams (Cloud Infra, Enterprise Data & IT-SEC) to ensure data solutions meet business requirements. \n \nContinuously evaluate and recommend new data technologies and approaches to improve data solutions. \n \nDevelop business partnerships and influence priorities by identifying solutions that are aligned with current business objectives and closely follow industry trends; understanding how to apply them and sharing knowledge with coworkers. \n \nCommunicate with partners, describing technology concepts in ways the business can understand, documenting initiatives in a concise and clear manner. \n \nPartner with Enterprise Data management & information security colleagues to ensure the adherence of Data Governance standards. \n \nDelivery Management (20%) \n \nFind creative solutions to challenging problems involving factors with potentially broad implications; reflecting on solutions, measuring impact, and using that information to ideate and optimize. \n \nExecute data strategies with an understanding of enterprise architecture, consumption patterns, platforms and application infrastructure. \n \nStay ahead of the impediments to ensure a smooth, on time and in budget, implementation of Data Projects \n \nCollect weekly status updates from Dev teams across multiple Data POD teams and consolidate for leadership project health reporting. \n \nRequired Experience/Technical Skills \n \n5+ years of hands-on data engineering experience with On-Prem and Cloud based Data tools/Platforms. \n \n3+ years of experience in data engineering with expertise specifically in Azure Data Factory, Databricks, PySpark, Python and related services. \n \nSoftware development experience using SaFe Agile methodologies. \n \nProven experience in leading and managing technical teams in data engineering and analysis. \n \nExperience in designing and developing data models and schemas. \n \nStrong proficiency in programming languages such as Python. \n \nExperience in developing and maintaining CI/CD pipelines for automated deployment and testing. \n \nGood understanding of cloud computing and its services (e.g., Azure, AWS, Google Cloud Platform). \n \nExcellent problem-solving skills and ability to work in a fast-paced environment. \n \nExperience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Data lakes, Data Security, Networking, Serverless, Testing / Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization \n \nSkilled leading and/or participating in system design and architectural activities including technical requirement writing experience and ability to lead collaboration sessions for important design reviews and decisions. \n \nProven experience succeeding in complex, matrix and cross-functional projects. \n \nAbility to personally deliver large scale initiatives in a fast-paced environment with high levels of complexity and ambiguity. \n \nExperience and comfort managing indirect teams; scrums, agile cross functional teams, vendor stakeholders. \n \nStrong collaboration skills and the ability to work in a team-based environment including employees, vendors and third-party contractors. \n \nAbility to inspire, influence and collaborate across a wide range of constituents across functions and organizational levels. \n \nExcellent mentoring skills and the desire to contribute to efforts beyond the scope of the day-to-day project work. \n \nEducation: \n \nBachelor s degree in computer science, Information Technology or a related study, or equivalent experience \n \nTechnical Stack: \n \nMicrosoft Azure Cloud: Azure Data Factory, APIM, Function Apps, Logic Apps, Key Vault, Azure App Insights, Azure SQL, Azure DevOps \n \nDatabases: Azure SQL, Databricks, MongoDB, \n \nDevOps: GitHub, Azure DevOps, CI/CD Pipelines \n \nProgramming Languages: SQL, PYTHON, SCALA, R \n \nAPI Development: Azure APIM, REST APIs, web services, security such as Oauth2, SAML, IDM, open API standards like swaggers, RAML, developer portal, \n \nAPI Testing: Postman, \n \nLog Analytics: Splunk, Dynatrace \n \nWeb/Mobile App Analytics: Google Analytics, Firebase, Google Tag management \n \nArchitecture modeling: Lucid Chart, Visio, ARIS, etc. \n \nGood to have, but not mandatory: \n \nExperience working with Loyalty Management data, and other Marketing business processes data. \n \nExperience with Campaign Management, Customer Data Platforms, Content Management, Advertising Technology, Personalization Engines as a Solution, etc. \n",
            "dateupdated": 1723733307
        },
        {
            "id": "b03e049e-9e26-4254-b022-ef08d5cf6426",
            "title": "Java Microservices Developer",
            "location": "Englewood Cliffs, New Jersey, USA",
            "company": "Marlabs LLC",
            "description": "Java Microservices Developer \n \nLocation: \n \nEnglewood Cliffs, NJ/ Ridgefield Park, NJ \n \nDuration: 12 Months \n \nNo of Positions: 2 \n \nRoles and Responsibilities: \n \nDesign, develop, test, deploy and maintain scalable Java-based microservices using Spring Boot. \n \nCollaborate with cross-functional teams to identify requirements and implement solutions that meet business needs. \n \nEnsure high availability, scalability, security, and performance of cloud-based applications on AWS platform. \n \nImplement DevOps practices such as continuous integration/continuous deployment (CI/CD) pipelines using tools like Jenkins or similar technologies. \n \nParticipate in code reviews to ensure adherence to coding standards and best practices. \n \nDesign, develop, test, deploy, and maintain Java-based microservices using Spring Boot framework. \n \nCollaborate with cross-functional teams to identify requirements and implement solutions that meet business needs. \n \nEnsure high availability, scalability, security, and performance of the system by following best practices in software engineering. \n \nParticipate in code reviews to ensure adherence to coding standards and quality guidelines. \n \nTroubleshoot issues related to application deployment on cloud platforms like AWS or Azure. \n \nJob Requirements: \n \nStrong understanding of Microservices architecture principles and design patterns. \n \nProficiency in writing clean, modularized code using Spring Boot framework. \n \nDeveloping RESTFUL Microservices using spring boot. \n \nExperience working with CI/CD pipelines using Maven/Jenkins/Azure DevOps. \n",
            "dateupdated": 1723649528
        },
        {
            "id": "b197c2c9-9f7f-4b90-b6fb-ac77e3efa63d",
            "title": "Scrum Master",
            "location": "Richmond, Virginia, USA",
            "company": "Tech Brand Staffing LLC",
            "description": "Job Title: VDOT Scrum Master \n \nLocation: Richmond, VA (Hybrid) \n \nDuration: 12 Months Contract \n \nSkill \n \nRequired \n \nyears req \n \nYears Used \n \nLast Used \n \nExperience managing cloud-based solutions for data management and analytics. \n \nRequired \n \n8 Years \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nRequired \n \n8 Years \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nRequired \n \n8 Years \n \nKnowledge of transportation data and project management with transportation data is a plus \n \nRequired \n \n8 Years \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nRequired \n \n8 Years \n \nTechnical Business Analyst understanding of data integration and data project \n \nRequired \n \n8 Years \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nRequired \n \n8 Years \n \nExperience in both Agile and Waterfall project management. & Agile Scrum Maste \n \nRequired \n \n8 Years \n \nDescription \n \n: \n \nThe Virginia Department of Transportation (VDOT) Information Technology Division is seeking a senior technical Project Scrum Master to drive the project delivery of the development and implementation of a cloud-based data management platform that will support the agency s data management needs. The successful candidate will have a proven track record of developing and implementing effective cloud-based solutions for complex data management problems. The candidate must have data security, cloud infrastructure, with knowledge of transportation related data preferred. \n \nThe selected candidate will: \n \nDrives consistent project delivery through the entire project lifecycle, including: project plans, release plans, resource allocation, and management of project risks, scope, schedule, and delivery of value. \n \nCoordinates Agile Ceremonies such as Sprint Planning, Daily Standups, Retrospectives, Sprint Demos, Story Refinement, and Release Planning. \n \nTracks and communicates project s progress from a schedule, cost, and risk perspective to the project team, stakeholders, and management. \n \nEstablishes an environment where the teams can be effective and helps removing obstacles. \n \nProtects the team from outside interruptions and distractions. \n \nEnsures a good relationship between the team and product owner as well as others outside the team. \n \nTracks and reports team velocity and other project metrics. \n \nPromotes continuous improvement and helps teams to increase productivity. \n \nHelps Product Owner and team with Product backlog management. \n \nAdheres to VDOT and VITA project management practices as defined. \n \nAdditional responsibilities as assigned. \n \nCommunicate timelines and expectations to technical and business staff. \n \nCollaborate with stakeholders to understand project requirements and support data management needs. \n \nEnsure data is collected, stored, and processed securely and in compliance with all applicable regulations. \n \nAnalyze data and provide insights to support decision-making by project management teams. \n \nProvide training and support for end-users to ensure the platform is used effectively. \n \nDemonstrable capability and experience in planning, implementing and maintenance of local master data systems and processes across business units and functions. \n \nUnderstanding of data and leveraging it to deliver business value. Ability to discuss requirements with data teams \n \nExperience in data governance concepts, and data governance implementations. \n \nAbility to use agile approach and methodology to drive master data governance processes. \n \nEnsure documentation of requirements and uses cases, facilitate design workshops for assigned project. \n \nEnsure definition of test objectives, designed test plans and test cases for assigned project. \n \nProvide the management of project milestones and deliverables for on-time and on-budget delivery. \n \nDefine, measure, and clearly communicate progress with metrics. \n \nQualifications \n \nSolid understanding of software development life cycle models as well as expert knowledge of Agile project management principles and practices. \n \nExperience managing cloud-based solutions for data management and analytics. \n \nAbility to work with customers, understand their business practices and manage their expectations. \n \nAbility to set clear performance standards and hold team members accountable, while keeping team engaged and on track. \n \nAbility to help Product Owners to create and prioritize Product Backlog. \n \nStrong interpersonal skills including mentoring, coaching, collaborating, and team building. \n \nStrong analytical, organizational and decision-making skills. \n \nAbility to analyze and document business and system processes. \n \nAbility to balance the competing demands for quality, scope, schedule, and cost. \n \nWell-versed with Scrum and Kanban Agile methodologies. \n \nPMP and CSM Certifications required. \n \nSAFe Certification preferred. \n \nExperience with SAFe framework is a plus. \n \nPreferred: \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud.\\ \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nExcellent analytical, problem-solving, and communication skills. \n \nKnowledge of transportation data and project management with transportation data is a plus. \n \nExperience in IT Infrastructure delivery(networking, physical plant, vendor management, site provisioning) is preferred. \n \nExperience managing large, multi-stream projects. \n \nPMP or Qualified under Commonwealth of Virginia Qualification Standards for IT Project Managers for Category 4Projects. See: \n \nMicrosoft Office products (Word, Excel, Access, Outlook, Visio, PowerPoint, Project Server) \n \nSpecial Instructions to Applicants: \n \nThis position requires a fingerprint-based background check. \n",
            "dateupdated": 1723649291
        },
        {
            "id": "b3a32e71-88b3-4ccf-937f-e90d3b1471af",
            "title": "AGE - Sr. Front End Developer",
            "location": "Columbus, Ohio, USA",
            "company": "RICEFW Technologies Inc",
            "description": "Local to OHIO required \n \nHybrid : 2 weeks/week \nODA is seeking for an experienced, skilled, and motivated senior Front-End web application Developer with responsibility for developing and maintaining both front-end components of ODA web applications \n. \nMandatory Requirements \n \n4 years college degree or equivalent technical study or above \n \n10 years proven work experience as a Front-end developer: \n \nImplementation of interactive UI with Asp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools     Entity Framework; experience in browser testing and debugging \n \n7 years Hands on experience with markup languages, Angular 8 and above, Bootstrap \n \n3 years Azure DevOp experience \n \n5 years hands experience using Python 2.7 & above \n \nUnderstanding of layout aesthetics; Knowledge of SEO principles & Familiarity with software like Adobe Suite, Photoshop, and content management systems \n \nRequired Hands-on Experience: \n \nconverting the ASP.NET Web Forms to Angular Components and reuse the components in various Modules \n \nAngular CLI for creating components, Services, pipes, Directives \n \ncreating the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \nversion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \nbuilding process using Jenkins for Continuous Integration and version control \n \ncreating and consuming SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \nin building and maintaining server-side applications and APIs using languages such as Node.js, Python, or Ruby on Rails \n \nintegrating third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \nimplementing API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \ndesigning and implementing user interfaces using modern web technologies such as HTML5,CSS3, and JavaScript frameworks like React, Angular, or Vue.js \n \nin designing, testing, troubleshooting, and implementing application system solutions to maximize user experience for internal and external stakeholders \n \noptimizing the data storage and retrieval processes for efficient complaint management by leveraging the SQL database structure and constructs. \n \nimplementing secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \nexperience with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \nexperience Micro-services architecture and containerization technologies like Docker and Kubernetes is a plus \n \nResponsibilities: \n \nUse markup languages like HTML to create user-friendly web pages \n \nMaintain and improve website \n \nOptimize applications for maximum speed \n \nDesign mobile-based features \n \nCollaborate with back-end developers and web designers to improve usability \n \nGet feedback from, and build solutions for, users and customers \n \nWrite functional requirement documents and guides \n \nCreate quality mock-ups and prototypes \n \nHelp back-end developers with coding and troubleshooting \n \nEnsure high quality graphic standards and brand consistency \n \nStay up to date on emerging technologies \n \nIllustrate design ideas using storyboards, process flows and sitemaps \n \nDesired Skills: \n \nExcellent analytical skills, attention to detail, and problem-solving skills. \n \nProven ability to handle multiple tasks and projects simultaneously. \n \nGood communication skills with both technical and non-technical clients \n \nAbility to work with project team member when the requirement is not clear. \n \nMust possess excellent written and oral communication skills. \n \nStrong experience in creating good solutions w/o mature, detailed, codified business requirements. \n \nWorking experience in delivering expected results in unstructured environments. \n \nWorks productively and effectively independently without significant management oversight. \n \nRequired/Desired Skills \nSkill \n \nRequired /Desired \n \nAmount \n \nof Experience \n \nDevelopment experience using Angular and Web Forms/MVC 5.0 Framework in .NET & ASP.NET environment with proficiency in #, Java Script, CSS, and jQuery \n \nRequired \n \n10 \n \nYears \n \nDesigning & Implementing user interfaces using modern web technologies such as HTML5, CSS3, and Java Script framework like React, Angular, or Vue.js \n \nRequired \n \n10 \n \nYears \n \nHands on experience with mark-up languages, Angular 8 and above, Bootstrap \n \nRequired \n \n7 \n \nYears \n \nHands on Experience using Python 2.7 & above \n \nRequired \n \n5 \n \nYears \n \nAzure DevOps Experience \n \nHighly desired \n \n3 \n \nYears \n \nTechnical Documentation skills; Communication skills with both non-technical and technical clients \n \nRequired \n \n5 \n \nYears \n \nQuestions \nNo. \n \nQuestion \n \nQuestion1 \n \nAre you willing to report to the office located in downtown Columbus, Ohio twice a week (minimum)? \n \nQuestion2 \n \nDo you understand, and will abide by, the provision in your subcontract with OST that it is PROHIBITED for government equipment to be taken or used outside of the United States by your contractors? The consequences of this occurring can and will result in repercussions to you, the prime vendor, regardless if the candidate works for a sub-vendor of yours. It will also result in immediate termination of the contractor, and make them ineligible for rehire in the program. \n",
            "dateupdated": 1723666551
        },
        {
            "id": "b440fdc2-e8ff-4eec-a4d4-56e45bae63eb",
            "title": "Business Intelligence (Advanced Analytics Developer)",
            "location": "San Francisco, California, USA",
            "company": "Stellent IT LLC",
            "description": "Job Title:- Azure cloud data engineer with strong Power BI, ADF and Sql \n \nLocation:- San Francisco, California Onsite \n \nContract \n \nJob Description: \n \nProvides development leadership and expertise for advanced BI analysis and analytics. \n \nGuides and moves forward an advanced BI/Data Mart system providing sophisticated and measurable business benefits. \n \nDrives data, ETL and system architecture and development. \n \nOwns the advanced analytics data environment to ensure that the data refresh from various sources, to facilitate research, is happening at regular intervals. \n \nSupports a group of multi-disciplinary data professionals and analysts. \n \nDrives development (coding using PL/SQL, Perl or any other scripting language, ad-hoc queries using SQL). \n \nEnsures that the data infrastructure can scale to meet defined performance, load, and functional objectives Effectively manages the execution of parallel projects of varying scope and duration. \n \nResponsible for all database objects including tables, indices, triggers, views, sequences, packages, and procedures. \n \nWorks with Systems and Database Administration for infrastructure needs related to support, storage, backups, monitoring, performance bottlenecks. \n \nParticipates with applications development and quality assurance in the management of application releases. \n \nAdvises senior management on \"best practices\" concerning web analytics, data warehousing, data architecture, and data development. \n \nWorks with business intelligence and other source system owners to build data refresh plan for research environment. \n \nOwns web click stream data collection and supports product managers to implement best practices for data definition. \n \nSupports project management and documentation needs of the group. \n \nSkill Set: \n \nExperience with Oracle 8i, 9i and 10g including PL/SQL, SQL loader, external tables, partitioning and performance tuning. \n \nStrong knowledge of Oracle data structures, data dictionary, and RDBMS structures. Experience as data architect and/or DW/BI architecture. \n \nExperience in database design and administration, strong in performance tuning, software installation, scripting, PL/SQL coding, backup & recovery process. \n \nAt least 2 medium to large scale DW/BI project implementation experience. \n \nExperience working with DW/BI environment to be able understand the concepts of STAR, data cleansing, transformation and aggregations. \n \n4+ years, current, development experience and inclination towards development. \n \n1+ years' experience with web analytics products like web trends, NetTracker, Omniture etc.. \n \nExperience working in an environment that has come across customer integration issues or has addressed it using MDM. \n \nAbility to express business and technical concepts clearly and concisely both verbally and in writing. \n \nAggressive approach to staying current with developments within the internet world, related web analytics & data management. \n \nExperience working in a team-oriented, collaborative environment. \n \nGood to Have Skills: \n \nExperience working with various business applications like campaign management, CRM, ERP. \n \nExperience with Java scripts or any other web front end scripting. \n \nExperience with column-oriented database solutions such as HBase or Infobright. \n \nExperience with Hadoop. \n \nOracle database administration experience. \n \nExperience working with various data reporting tools like Business Objects, MicroStrategy, COGNOS. \n \nExperience working with ETL tools like Data Stage, Informatica, Hummingbird. \n \nExperience working with meta data management. Experience with SAS. \n \nAdditional Skills: \n \nSenior Azure Cloud Data Engineer with a strong background in Power BI, Azure Data Factory (ADF) and SQL. The candidate will be responsible for designing, developing, and implementing data integration solutions in the Azure cloud environment. Design and implement ETL processes using Azure Data Factory to integrate data from various sources into PostgreSQL / Azure SQL Database. Develop and maintain data models in Azure SQL Database to support reporting and analytics requirements. Create interactive and visually appealing dashboards and reports using Power BI. Experience in the retail domain will be an additional advantage. Strong analytical and problem-solving skills, excellent communication and collaboration skills. Have to collaborate with cross-functional teams to deliver high-quality data solutions that drive business intelligence and analytics initiatives. \n \nTechnical Skills: \n \nPower BI, DAX \n \nAzure Cloud \n \nAzure Data Factory (ADF) \n \nAzure SQL, PostgreSQL \n \nVisual Studio \n \nTest Driven Development \n \nPython, PowerShell \n \nGitHub, Github Actions, JIRA \n \nTools : IntelliJ, Splunk, New Relic \n \nSr. IT Technical Recruiter \n \nPhone:- \n \nEmail: \n \nGtalk: \n \nLinkedin id:- \n",
            "dateupdated": 1723736793
        },
        {
            "id": "b512c11d-2560-4765-a9f7-3b9c82b7cd23",
            "title": "Sr. Microsoft Developer (Remote 100%)/Fulltime",
            "location": "Remote",
            "company": "Esolvit, Inc.",
            "description": "Role Title: \n \nMicrosoft Developer \n \nLocation: \n \nSan Antonio (Remote 100%) \n \nDuration: Long term \n \nEducation: Bachelor s degree \n \nJob type: Temp to Perm (Temporary resources to be converted to permanent AFS/ASM W2 after 6 months of service with no placement fee; include annual salary expectations) \n \nClient: LOC (The Library of Congress) \n \nthrough \n \nAFS (Accenture federal Services). \n \nTechnical Skills: \n \n3-5 years of experience Microsoft Power Platform Infrastructure \n \n3-5 years of experience Azure Devops \n \n3-5 years of experience Microsoft Windows Communication Foundation (WCF) \n \n3-5 years of experience ASP.NET Web API \n \n3-5 years of experience Amazon Web Services (AWS) \n \nRole Description: \n \nUtilize modular architectures, next-generation integration techniques and a cloud-first, mobile-first mindset to provide vision to Application Development Teams. Work with an Agile mindset to create value across projects of multiple scopes and scale. Oracle SQL Dev experience nice to have. \n \nAzure DevOps and Git, RESTful services and WCF, C#, ASP.NET MVC/Web API and .NET Core, JavaScript/ jQuery/ Power Shell Script, Angular v6 or higher, Toad (or Oracle SQL Developer); or equivalent. \n \nDemonstrate experience with Agile development methodology and DevOps with excellent verbal and written communication skills. \n",
            "dateupdated": 1723665228
        },
        {
            "id": "b76ed3fb-239a-489a-a11a-f6fa3a4b0d05",
            "title": "Release Manager",
            "location": "Renton, Washington, USA",
            "company": "Sriven Systems Inc.",
            "description": "Job Title :  Release Manager \n \nLocation : Renton, WA, \n \nDuration :12 Months Contract (Hybrid) \n \nJob Description \n \nThey will be coordinating with development teams in North America but also Europe to ensure successful software release management. 5+ years  experience as a Release Manager, owning all aspects of the software release process from planning and coordination to execution and monitoring Experience supporting the application development process within a cloud environment. Understanding of cloud development and cloud services concepts (IaC, security, IAM) ESSENTIAL FUNCTIONS   Cloud   Design, develop, install, configure, \n \n5+ years  experience as a Release Manager, owning all aspects of the software release process from planning and coordination to execution and monitoring \n \nExperience supporting the application development process within a cloud environment. \n \nUnderstanding of cloud development and cloud services concepts (IaC, security, IAM) \n \nESSENTIAL FUNCTIONS \n \nCloud \n \nDesign, develop, install, configure, administer, and maintain highly scalable, available, and elastic solutions that implement industry best practices using AWS, MS Azure, Google Cloud Platform and on-premises hardware. \n \nUnderstanding of Infrastructure as Code (IaC) concepts, feels comfortable managing and provisioning computer data centers through machine-readable definition files. \n \nInstall and configure cloud resources in AWS, Azure, or Google Cloud Platform, to include tagging, access, & monitoring \n \nSupport on-prem and cloud servers, including security configurations, patching, and troubleshooting. \n \nResolve system emergencies with impact on the integrity of user data and systems. \n \nFollow, design, configure, implement, and maintain system security strategies, policies, and procedures. \n \nEnsure system availability, performance, capacity, and continuity via proper response to incidents, events, and problems. \n \nBasic understanding of security technologies (Digital Certificates, LDAP, PKI, SSO, SSL, TLS, IAM, etc.) \n \nPerform admin on local/remote operating systems including installation, scripting & problem analysis. \n \nExperience in installation, administration, and configuration of Middleware technologies (Web/App/API/Microservice/Messaging tiers) a plus \n \nExperience with container technology is a plus. \n \nEffectively communicate to stakeholders for clarity and definition \n \nMake presentations to management team and professional peers. \n \nBe on-call to support business critical apps/systems in emergency situations. \n",
            "dateupdated": 1723733607
        },
        {
            "id": "b7b2400d-bec1-4be7-b3c6-5d4cf1cd4e33",
            "title": "BI Architect",
            "location": "Boston, Massachusetts, USA",
            "company": "TrustIT LLC",
            "description": "Title: BI Architect \n \nLocation: \n \nBoston, MA 02116 \n \nDuration: Contract \n \nPosition Summary: \n \nClient is seeking a contract Senior BI Architect to design, develop, and implement our organization s BI strategy for a health data warehouse project for approximately fifteen (15) months. The project team, consisting of temporary and permanent staff, will rebuild an existing data warehouse using new ETL, BI, and database platforms with an eye towards cost containment and improved technical performance.  This key role will work with Senior Management and our Data Analysts to identify business goals and objectives and then design and implement a BI solution that meets those goals. \n \nThe Senior BI Architect will also research and recommend an enterprise-level BI tool, work with business teams to gain consensus on that tool and help train users on how to use it. \n \nResponsibilities: \n \nTo be considered for this position, the candidate must demonstrate specific experience in: \n \nLeading the design and implementation of semantic layers on top of Snowflake and/or Postgres, in an MS Azure environment. \n \nAnalyzing business needs and recommending an appropriate BI tool that will provide the required performance for Data Analysts. \n \nLeading a business wide BI solution implementation. \n \nAssisting clients in a consulting capacity, with implementing and using BI tools and technologies. \n \nTroubleshooting BI issues and problems and providing support to BI users. \n \nDeveloping documentation and training materials as required to support the BI users. \n \nWorking with healthcare data, preferably in the payer space. \n \nCloud technologies, preferably MS Azure and Snowflake. \n \nQualifications: \n \nThe ideal candidate will have: \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years  experience working in the BI space at an Architect level. \n \n5+ years  experience implementing BI solutions in Azure cloud environments. \n \n2+ years  experience working with Snowflake and Postgres databases. \n \nDemonstrable experience in evaluating business needs and implementing BI strategies to meet those needs. \n \nA combination of technical expertise and leadership skills to effectively navigate the complexities supporting multiple in-house business units. \n",
            "dateupdated": 1723656951
        },
        {
            "id": "b80e4eda-e741-430f-a7cb-4a5a8734bf9b",
            "title": "Direct Client Requirement for Kubernetes Engineer with Azure --- Hybrid",
            "location": "Plano, Texas, USA",
            "company": "Kairos",
            "description": "Hi, \n \nPlease let me know if you're comfortable with the position detailed below. This position is an urgent hire. \n \nRole: Kubernetes Engineer with Azure \n \nLocation: Plano, TX (Hybrid) \n \nDuration: Long Term \n \nRequired Skills: \n \nKubernetes, Terraform, On-prem, Azure, Linux, Git Pipelines \n \n. \n \nCertification of Kubernetes is Must and Any Azure Microsoft Certification \n \nWe need 2 Kubernetes Engineers with minimum of 2-3 years of experience of deploying and managing clusters, Monitoring & Logging Tools Prometheus, Grafana. \n \nMust have Terraform experience. \n \nNeed: More than 13+ Yrs. and need only locals. \n \nQualifications and Requirements. \n \nBachelor's degree in computer science or related Technology field or equivalent experience. \n \n13+ years of work experience. \n \nCloud Specific Qualifications and Requirements. \n \n6+ years of working in and building Infrastructure within a cloud platform   Azure, AWS, Google (with relatable experience). \n \n3+ years scripting or coding experience with one or more languages. \n \nTechnical experience in infrastructure, build and deployment, including private and public cloud, networking, connectivity, storage, virtualization, and access control. \n \nDemonstrable experience with a range of Azure cloud capabilities including but not limited to storage, key vaults, virtual networking, web apps, Azure Active Directory, virtual machines, access management and automated deployments. \n \nDemonstrable experience with software development preferably with one or more languages, such as PowerShell, Python, C#. \n \nDemonstrable experience creating and managing CI/CD pipelines using tools such as Team City or Azure DevOps. \n \nDemonstrable experience support Windows or Linux OS. \n \nPlease can you send me below Details for Submission. \n \nFull Name: \n \nCurrent Location: \n \nContact: \n \nEmail: \n \nWork Authorization: \n \nAvailability: \n \nCurrently working: \n \nAny interviews in pipeline: \n \nLinkedIn Link: \n \nPavan Kumar Anumolu | Sr. Recruiter | Kairos Technologies Inc. \n \nM:  | E: \n",
            "dateupdated": 1723649779
        },
        {
            "id": "b92dcd29-a367-40af-ab08-343b23bff99a",
            "title": "Site Reliability Engineer",
            "location": "Remote or San Jose, California, USA",
            "company": "Danta Technologies",
            "description": "Looking for MLOps_SRE_DevOPS candidate. Remote position. \n \nBasic Qualifications \n \nBA / BS degree with 4+ years of experience (or) MS degree with 2+ years of experience as a SRE Engineer \n \nExpertise in infrastructure automation tools like Terraform, Ansible or Cloud Formation \n \nStrong experience with cloud services (AWS, Google Cloud Platform, Azure) and container orchestration tools (Kubernetes, Docker) \n \nProficiency in programming languages such as Python, Go \n \nDeep understanding of networking, security and database technologies \n \nPreferred Qualifications \n \nBachelor's degree in Computer Science, Software Engineering, or a related field; a Master's degree is a plus. \n \nFamiliarity with AI and machine learning concepts and the ability to collaborate effectively with data scientists and AI engineers. \n \nStrong problem-solving skills and the ability to troubleshoot complex technical issues. \n \nKnowledge of security best practices and compliance standards. \n \nExcellent teamwork and communication skills to lead and mentor cross-functional teams effectively. \n \nNotes \n \n:- All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance. \n \nBenefits \n \n: Danta offers a compensation package to all W2 employees that are competitive in the industry. It consists of competitive pay, the option to elect healthcare insurance (Dental, Medical, Vision), Major holidays and Paid sick leave as per state law. \n \nThe rate/ Salary range is dependent on numerous factors including Qualification, Experience and Location. \n",
            "dateupdated": 1723676655
        },
        {
            "id": "bd6b1cf8-0de2-4109-81d1-88196e6abaec",
            "title": "IT Project Manager",
            "location": "Richmond, Virginia, USA",
            "company": "V-Soft Consulting Group, Inc",
            "description": "IT Project Manager \n \nPrimary Location: Richmond, Virginia \n \nV-Soft Consulting is currently hiring for an \n \nIT       Project Manager \n \nfor our premier client in \n \nRichmond, Virginia \n \n. \n \nWHAT YOULL NEED: \n \nTechnical Requirements and Certifications \n \nPMP Certification through PMI or Qualified. \n \nEducation and Experience \n \nShould have 15 years of overall IT experience.         Experience with technology infrastructure is preferred.         Application Development experience is a plus. \n \nMust have a minimum of 10 years of experience         managing large projects in a Portfolio and a bachelor's   degree. \n \nShould be proficient in Project Management tools         such as Microsoft Project, Visio, and Office   required. \n \nShould possess financial literacy including         budgeting, accounting, investing and managing   credit. \n \nShould have a minimum of 5 years experience in         procurement management including original development of         Statements of Work (SOWs), Requests for Quotation (RFQs) and   contracts. \n \nStrong experience in developing, executing, and         managing a portfolio of projects. \n \nStrong experience leading the business and IT         resources through the discovery and documentation of business         and technical requirements in request for proposal and statement         of requirement formats. \n \nExperience with VITAs CTP system and ECOS process         is strongly preferred. \n \nExperience with the core IT procurement processes         (RFP, VITA Statewide Contract, and CAI SOW) is preferred. \n \nKnowledge, Skills and Abilities \n \nStrong analytical, organizational, and         decision-making skills. \n \nExceptional interpersonal skills for collaborating         and team building. \n \nAbility to plan in a rapidly changing environment         and to provide guidance for changes as required for the life of         the project. \n \nExceptional verbal and written communication skills         with the demonstrated ability to simplify and briefly,         succinctly communicate complex issues to multiple   audiences. \n \nAbility to lead others to implement new approaches,         systems, structures, and methods. \n \nAbility to define and balance the competing demands         for quality, scope, schedule, and cost. \n \nCommunicate timelines and expectations to technical         and business staff. \n \nSolid understanding of software development life         cycle models. \n \nExceptional knowledge of both Agile and Waterfall         project management principles and practices. In addition, the         ability to blend them together in the right proportions to fit a         particular project and business environment. \n \nKnowledge of process engineering and re-engineering         techniques and practices. \n \nWHAT YOULL DO: \n \nJob Responsibilities: \n \nOriginate and oversee proposals, statements of         work, statements of requirements and RFP responses through         selection/acquisition. Facilitate the technical and planning         aspects of the technology procurement   process. \n \nManage working relationships with key stakeholders         at all levels, including executive management, business         management, vendors, project sponsors, suppliers, and technology   management. \n \nCoordinate across multi-disciplinary teams to         develop plans, goals, objectives, policies, and procedures that         will enable future execution of a project or initiative.         Incorporate agency best practices into those project   plans. \n \nEnsure plans minimally include tasks, schedules,         identification of potential risks, checkpoints, reporting of         status and appropriate allocation of resources from all required   disciplines. \n \nSeamlessly transition developed plans to internal         VDOT and/or vendor teams for successful execution using PMI   best-practices. \n \nProvide oversight to ensure projects in execution         include a framework for governance encompassing adequate         meetings, reporting, metrics, risk and issue management, and         quality assurance. Validate that the assigned project team(s)         adhere to project governance standards throughout the project   lifecycle. \n \nMonitor progress by third-party vendors and define         and measure their progress with pre-defined metrics and   milestones. \n \nSet goals for initiatives that are consistent with         technical objectives and the agencys overall technology   strategy. \n \nExhibit significant emotional quotient (EQ) in         handling project challenges and maintain a positive project         culture in line with VDOTs mission and shared values. \n \nInterested? \n \nQualified candidates should send their resumes to \n \nV-Soft Consulting Group is recognized among the top 100     fastest growing staffing companies in North America, V-Soft     Consulting Group is headquartered in Louisville, KY with strategic     locations in India, Canada and the U.S. V-Soft is known as an agile,     innovative technology services company holding several awards and     distinctions and has a wide variety of partnerships across diverse     technology stacks. \n \nAs a valued V-Soft Consultant, youre eligible for full     benefits (Medical, Dental, Vision), a 401(k) plan, competitive     compensation and more. V-Soft is partnered with numerous Fortune 500     companies, exceptionally positioned to advance your career growth. \n \nV-Soft Consulting provides equal employment     opportunities to all employees and applicants for employment and     prohibits discrimination and harassment of any type without regard     to race, color, religion, age, sex, national origin, disability     status, genetics, protected veteran status, sexual orientation,     gender identity or expression, or any other characteristic protected     by federal, state or local laws. \n \nFor more information or to view all our open jobs,     please visit  or call . \n \n#LI-AK2 \n \n#INDSP \n",
            "dateupdated": 1723655313
        },
        {
            "id": "bf77b900-f4b6-4d6c-aa72-44204b74d037",
            "title": "Snowflake Admin",
            "location": "Chicago, Illinois, USA",
            "company": "Rackera Inc",
            "description": "Title: \n \nSnowflake Admin \n \nLocation: \n \nChicago, IL \n \nJob Description : \n \n8-10 years of Snowflake experience from Governance perspectives, performance perspective, App troubleshooting perspective \n \nHave in depth knowledge about the Snowflake administration \n \nWork towards resource optimization/ utilization and be part of the discussion with external teams advising them on the best practices. \n \nExperience of integration of external teams and technologies and design consideration for adequate use of warehouse solution. \n \nWell versed with Snowflake Devops procedures, grants, privileges with snowflake costing optimization background. \n \nApplication service delivery experience is must and candidate should know about files, batch processing. \n \nCapital Markets domain experience and ESG domain experience would be a plus \n \nAzure pipeline experience with basic azure fundamentals (AZ-900 certified) will be a plus \n",
            "dateupdated": 1723674761
        },
        {
            "id": "c61f5c50-e63f-4c59-9095-b520ed70f392",
            "title": "Job Opportunity of Scrum Master",
            "location": "US",
            "company": "Software Technology Inc",
            "description": "Local candidates only please \n \n*Candidate must also be able to work onsite 2-3 days/week. \nThe Virginia Department of Transportation (VDOT) Information Technology Division is seeking a senior technical Project Scrum Master to drive the project delivery of the development and implementation of a cloud-based data management platform that will support the agency's data management needs. The successful candidate will have a proven track record of developing and implementing effective cloud-based solutions for complex data management problems. The candidate must have data security, cloud infrastructure, with knowledge of transportation related data preferred. \nThe selected candidate will: \nDrives consistent project delivery through the entire project lifecycle, including: project plans, release plans, resource allocation, and management of project risks, scope, schedule, and delivery of value. \nCoordinates Agile Ceremonies such as Sprint Planning, Daily Standups, Retrospectives, Sprint Demos, Story Refinement, and Release Planning. \nTracks and communicates project's progress from a schedule, cost, and risk perspective to the project team, stakeholders, and management. \nEstablishes an environment where the teams can be effective and helps removing obstacles. \nProtects the team from outside interruptions and distractions. \nEnsures a good relationship between the team and product owner as well as others outside the team. \nTracks and reports team velocity and other project metrics. \nPromotes continuous improvement and helps teams to increase productivity. \nHelps Product Owner and team with Product backlog management. \nAdheres to VDOT and VITA project management practices as defined. \nAdditional responsibilities as assigned. \nCommunicate timelines and expectations to technical and business staff. \nCollaborate with stakeholders to understand project requirements and support data management needs. \nEnsure data is collected, stored, and processed securely and in compliance with all applicable regulations. \nAnalyze data and provide insights to support decision-making by project management teams. \nProvide training and support for end-users to ensure the platform is used effectively. \nDemonstrable capability and experience in planning, implementing and maintenance of local master data systems and processes across business units and functions. \nUnderstanding of data and leveraging it to deliver business value. Ability to discuss requirements with data teams \nExperience in data governance concepts, and data governance implementations. \nAbility to use agile approach and methodology to drive master data governance processes. \nEnsure documentation of requirements and uses cases, facilitate design workshops for assigned project. \nEnsure definition of test objectives, designed test plans and test cases for assigned project. \nProvide the management of project milestones and deliverables for on-time and on-budget delivery. \nDefine, measure, and clearly communicate progress with metrics. \nQualifications \nSolid understanding of software development life cycle models as well as expert knowledge of Agile project management principles and practices. \nExperience managing cloud-based solutions for data management and analytics. \nAbility to work with customers, understand their business practices and manage their expectations. \nAbility to set clear performance standards and hold team members accountable, while keeping team engaged and on track. \nAbility to help Product Owners to create and prioritize Product Backlog. \nStrong interpersonal skills including mentoring, coaching, collaborating, and team building. \nStrong analytical, organizational and decision-making skills. \nAbility to analyze and document business and system processes. \nAbility to balance the competing demands for quality, scope, schedule, and cost. \nWell-versed with Scrum and Kanban Agile methodologies. \nPMP and CSM Certifications required. \nSAFe Certification preferred. \nExperience with SAFe framework is a plus. \nPreferred: \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \nExcellent analytical, problem-solving, and communication skills. \nKnowledge of transportation data and project management with transportation data is a plus. \nExperience in IT Infrastructure delivery(networking, physical plant, vendor management, site provisioning) is preferred. \nExperience managing large, multi-stream projects. \nPMP or Qualified under Commonwealth of Virginia Qualification Standards for IT Project Managers for Category 4Projects. See: ;/p> \n \nMicrosoft Office products (Word, Excel, Access, Outlook, Visio, PowerPoint, Project Server) \n \nSpecial Instructions to Applicants: \n \nThis position requires a fingerprint-based background check. \n \nRequired/Desired Skills \n \nSkill \n \nRequired /Desired \n \nAmount \n \nof Experience \n \nExperience managing cloud-based solutions for data management and analytics. \n \nRequired \n \n8 \n \nYears \n \nStrong knowledge of cloud infrastructure and software systems, including Azure and Google Cloud. \n \nRequired \n \n8 \n \nYears \n \nExperience with data processing and storage tools (e.g., Spark, Azure Data Factory, Azure Data Lake Storage, Azure Event Hub, Azure SQL, Synapse). \n \nRequired \n \n8 \n \nYears \n \nKnowledge of transportation data and project management with transportation data is a plus \n \nRequired \n \n8 \n \nYears \n \nExperience in IT Infrastructure delivery (networking, physical plant, vendor management, site provisioning) is preferred. \n \nRequired \n \n8 \n \nYears \n \nTechnical Business Analyst understanding of data integration and data project \n \nRequired \n \n8 \n \nYears \n \nExperience in the roll-out and adoption of governance tools such as Alation, Collibra, Informatica, or Microsoft Purview. \n \nRequired \n \n8 \n \nYears \n \nExperience in both Agile and Waterfall project management. & Agile Scrum Maste \n \nRequired \n \n8 \n \nYears \n",
            "dateupdated": 1723653035
        },
        {
            "id": "c6899560-9f8e-48a8-af9a-309470d28986",
            "title": "Sr .Net Full Stack Developer",
            "location": "Columbus, Ohio, USA",
            "company": "GoAhead Solutions",
            "description": "Seeking a Sr. Full Stack Web Application Developer with exp. in API integration for developing both front-end and back-end components of group web applications. \n \nDuration: \n \nthrough 6-30-25 \n \nWork location: \n \nColumbus (hybrid 2 days a week onsite) \n \nRate: \n \n$70.00 per hr. Corp to Corp (all inclusive) \n \n-10 years proven work experience as a frontend developer: \n \n-Designing and developing the web applications robust and scalable web applications from concept to production using Angular & Web Forms/MVC 5.0 framework in .NET & ASP.NET environment with proficiency in C#, JavaScript, CSS, and jQuery \n \n-Implementation of interactive UI with Asp.Net MVC, HTML5, CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap, usage of ORM tools Entity Framework; experience in browser testing and debugging \n \n-7 yrs. hands-on exp. with markup languages, Angular 8 and above & Bootstrap \n \n-7 yrs. develop & manage SQL databases by planning, developing & maintaining the databases using Oracle or Microsoft SQL Server \n \n-3 yrs. Azure DevOps exp. \n \n-5 yrs. hands-on exp. using Python2.7 & above \n \n-Exp. integrating third-party APIs & services to extend the functionality of our applications & ensure seamless data exchange \n \nMust have hands-on exp. in: \n \n-Design and developing the web applications robust and scalable web applications from concept to production using Angular and MVC (5.0) framework in .NET &ASP.NET environment with proficiency in C# and Angular \n \n-Implement ofinteractive UI withAsp.Net MVC, HTML5,CSS3, jQuery, JavaScript, Angular 8 or better, and Bootstrap; Usage of ORM tools   Entity Framework \n \nConvert ASP.NET Webforms to Angular component sand reuse the components in various \n \nmodules \n \n-Angular CLI for creating components, Services, pipes, Directives \n \nCreate the SQL tables, Views, Queries, Triggers and Stored procedures to store the data from the applications. \n \nVersion control using GIT and be able to use GIT Bash commands to clone, commit and push code repositories \n \nBuild process using Jenkins for Continuous Integration and version control \n \nCreate and consume SOAP, REST API Web Services for integration with various back-end systems and integrating third-party services. \n \nBuilding & maintaining server-side applications & APIs using languages such as Node.js, Python, or Ruby on Rails \n \nIntegrate third-party APIs and services to extend the functionality of our applications and ensure seamless data exchange \n \n-Implement API security measures like authentication, authorization, and encryption including role-based access control (RBAC) to control system access. \n \n-Design & implement UI using modern web technologies such as HTML5, CSS3 & JavaScript frameworks like React, Angular, or Vue.js \n \n-Design, test, troubleshoot & implement application system solutions to maximize user experience for internal and external stakeholders \n \n-Optimize the data storage & retrieval processes for efficient complaint mgt. by leveraging the SQL database structure & constructs. \n \n-Implement secure coding practices throughout the development lifecycle to help prevent security vulnerabilities from being introduced into software \n \n-Exp. with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \n-Exp. Microservices architecture and containerization technologies like Docker and Kubernetes is a plus \n \nExp/skills: \n \n-Exp. with cloud platforms such AWS, Google Cloud Platform, or Microsoft Azure is preferred \n \n-Familiarity w./ Microservices architecture and containerization technologies like Docker and Kubernetes is a plus \n \n-Exp. with continuous integration & deployment (CI/CD) pipelines using Azure DevOps exp. (minimum 3 years) \n \n-Leverage SQL database structure and optimize data storage and retrieval processes for efficient complaint management \n \n-Able to create Data Warehouse functionality by defining and capturing metadata and rules associated with ETL processes in various applications \n \nAbility to do the security scan the applications and fix the software vulnerabilities within the system \n \nDesired skills \n \n: \n \nExcellent analytical skills, attention to detail, and problem-solving skills. \n \nProven ability to handle multiple tasks and projects simultaneously. \n \nGood communication skills with both technical and non-technical clients \n \nAbility to work with project team members when the requirement is not clear. \n \nMust possess excellent written and oral communication skills. \n \nStrong experience in creating good solutions w/o mature, detailed, codified business requirements. \n \nWorking experience in delivering expected results in unstructured environments. \n \nWorks productively and effectively independently without significant management oversight. \n",
            "dateupdated": 1723669049
        },
        {
            "id": "c7f7a4b4-f239-491c-bb2f-ff52396f7399",
            "title": "Power BI Architect",
            "location": "Santa Clara, California, USA",
            "company": "Sryven",
            "description": "Job Title: \n \nPower BI Architect (Azure Data Platform) \n \nLocation: Santa Clara, CA (Onsite) \n \nDuration: Long Term Contract \n \nNote: Need local to CA \n \nEducational Qualification: \n \nBachelor s or Master s degree in Computer Science, Information Systems, or a related field. \n \nAbout the Role: \n \nWe are seeking a highly skilled Power BI Architect with extensive experience in migrating from Tableau to Power BI. The ideal candidate will be responsible for designing, developing, and implementing business intelligence solutions that leverage Power BI s capabilities, ensuring a seamless transition from Tableau. \n \nKey Responsibilities: \n \nMigration Planning: \n \nDevelop and execute a comprehensive migration strategy from Tableau to Power BI, including data source connections, visualization migration, and testing. \n \nArchitecture Design: \n \nDesign and implement scalable and efficient Power BI architectures that meet business requirements. \n \nData Integration: \n \nEstablish and manage data connections, ensuring data integrity and consistency across various sources. \n \nDashboard Development: \n \nCreate interactive and visually appealing dashboards and reports using Power BI, ensuring they meet user requirements and business goals. \n \nPerformance Optimization: \n \nOptimize Power BI solutions for performance, scalability, and usability. \n \nStakeholder Collaboration: \n \nWork closely with business stakeholders to understand their needs and translate them into technical requirements. \n \nTraining and Support: \n \nProvide training and support to end-users to ensure successful adoption of Power BI. \n \nDocumentation: \n \nMaintain comprehensive documentation of the migration process, architecture, and best practices. \n \nPrimary (Must have skills) \n \nTechnical Skills: \n \nProficiency in Power BI, including DAX, Power Query, and data modeling. Experience with Tableau and its migration to Power BI. \n \nAnalytical Skills: \n \nStrong analytical and problem-solving skills, with the ability to interpret complex data sets and derive meaningful insights. \n \nCommunication Skills: \n \nExcellent verbal and written communication skills, with the ability to convey technical information to non-technical stakeholders \n \nExperience Range \n \nMinimum of 5 years of experience in business intelligence and data analytics, with at least 2 years of experience in migrating from Tableau to Power BI. \n \nSecondary Skills (Good To have) \n \nExperience with other data visualization tools and programming languages (e.g., Python, R). \n \nKnowledge of cloud platforms (e.g., Azure, AWS) and big data technologies. \n \nFamiliarity with data governance and security best practices. \n \nExperience in managing BI projects, including planning, execution, and delivery. \n \nRelevant certifications in Power BI or other BI tools are a plus. \n \nSoft skills/other skills (If any) \n \nAnalytical Skills: \n \nStrong analytical and problem-solving skills, with the ability to interpret complex data sets and derive meaningful insights. \n \nCommunication Skills: \n \nExcellent verbal and written communication skills, with the ability to convey technical information to non-technical stakeholders \n \n. \n \nLeadership Skills: \n \nProven ability to lead and manage teams, with a track record of successful project delivery. \n \nPresentation Skills: \n \nEffectively presenting project updates and outcomes to stakeholders and executives. \n",
            "dateupdated": 1723648552
        },
        {
            "id": "cc95e896-2605-40c6-bbcd-81910f14f6fb",
            "title": "Salesforce Solutions Architect",
            "location": "California, USA",
            "company": "E-Solutions, Inc.",
            "description": "Position Title: Salesforce Solutions Architec \n \nJob Location: North Chicago, IL \n \nRemote/Onsite: Onsite \n \nJob Type : Contract \nJD: \n \nExperience in architecting the solutions in server, client, and cloud technologies, and should have in-depth knowledge in system development life cycle, software development methodologies (Waterfall, Agile) and Patient services domain. \n \nExperience in architecting and implementing custom web, mobile, and integration solutions using .NET or similar stack. \n \nExperience in implementing solutions in salesforce.com platform such as service cloud/health cloud/marketing cloud/force.com, and MarTech platforms such as CDP/DMP/Marketing Automation Platform. \nKNOWLEDGE, SKILLS, AND ABILITIES \n \nKnowledge in programming languages such C#, Python, REST APIs and database technologies such as SQL, NoSQL, etc. \n \nExperience in implementing solutions involving Salesforce platforms (Service/Health/Marketing) in the eco system. \n \nKnowledge in DevOps concepts and experience in using CI/CD Tools. \n \nProven experience in architecture roles including architectural principles, helping define the reference architecture, building technology roadmaps aligned with business strategy, and helping to institute governance to ensure alignment of investment to strategy/architecture. \n \nProven experience in engineering, design concepts, algorithms, and experience in designing systems leveraging emerging or best-in-class technologies. \n \nStrong problem solving and critical thinking skills that build trust and serve to positively influence partners and teammates. \n \nShould have good understanding in relationship between business processes, applications, databases, operating systems, processing platforms, storage platforms, security systems and networks. \n \nStrong written and verbal communication, presentation, and technical writing skills, coupled with a strong interest in further developing and integrating enterprise business processes with technology skills. \n\"Disclaimer: E-Solutions Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. We especially invite women, minorities, veterans, and individuals with disabilities to apply. EEO/AA/M/F/Vet/Disability.\" \nSalesforce Solutions Architect1Salesforce,DevOps,integration solutionsN/AContractUnited States",
            "dateupdated": 1723734953
        },
        {
            "id": "ccc589e3-d9de-4d11-a661-f300e82551e2",
            "title": "CLOUD NATIVE APPLICATION DEVELOPER (AWS)",
            "location": "Atlanta, Georgia, USA",
            "company": "Lucid Technologies",
            "description": "Role/Title: CLOUD NATIVE SOFTWARE APPLICATION DEVELOPER (AWS) \n \nHybrid, Atlanta, Georgia \n \nAgency Interview Type: Web Cam Interview Only \n \nCandidates must be located in and work in GA to start this position if offered. Do you and your candidate accept this requirement? \n \nIf selected and your candidate is not local, is your candidate wiling to relocate to the Atlanta area beginning Day 1? \n \nThe client has agreed to allow the selected local candidate to work a hybrid situation with on-site work to be determined by the manager. Do you and your candidate accept this requirement? \n \nCandidates must have experience developing software applications in an  AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nGeneral Description: \n \nAs an AWS Cloud Developer at GTA you will play a crucial role in designing, developing, and maintaining scalable native cloud software applications on the AWS platform. \n \nJob Description: \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nSkills Matrix: \n \nProven experience developing cloud application software Required 8 Years \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 Required 5 Years \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python Required 5 Years \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines Required 5 Years \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies Required 5 Years \n \nWork experience with XML, XSD, WSDL, and other related technologies Required 5 Years \n \nAgile methodologies and SCRUM framework Required 3 Years \n \nExperience with CI/CD pipelines and DevOps practices Highly desired \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) Highly desired \n \nAWS certifications (e.g., AWS Certified Developer) Highly desired \n \nThanks & Regards \n \nManala Priyanka \n \nUS IT Recruiter \n \nLucid Technologies Inc \n \nEmail: \n \nW: ;/div> \n",
            "dateupdated": 1723736412
        },
        {
            "id": "ce1c0a99-c51a-414d-bc8e-72c646ab8f8e",
            "title": "System Analyst - MUST RESIDE IN TEXAS",
            "location": "Remote",
            "company": "Luna Data Solutions, Inc.",
            "description": "We are currently hiring an experienced Systems Analyst with a focus on WebSphere for a long-term contract worked remotely within the Austin, TX metropolitan area \n \n(YOU MUST CURRENTLY RESIDE IN THE AUSTIN, TEXAS METROPOLITAN AREA TO BE CONSIDERED) \n \n. If selected, you will be identifying alternative solutions, performing studies and cost/benefit analysis of alternatives. The roles and responsibilities associated with this position may include, but not be limited to, the following: \n \nAnalyzing user requirements, procedures, and problems to automate processing or to improve existing computer system(s). \n \nConferring with personnel of organizational units involved to analyze current operational procedures, identify problems, and learning specific input and output requirements, such as: \n \nForms of data input \n \nHow data is to be summarized, and formatted for reports. \n \nCollaborating with the team that is the focal point for all Middleware activities between the client's Operations management and Social Services Applications. \n \nCoordination of all of the client's Releases and Maintenance schedules with respect to Middleware servers and the applications that those server host. \n \nAssessing issues as they arise within the client's operational ecosystem, communicating up to management, and leading the effort of all required fixes. \n \nAdvising any technical implementation, schedules, automation, and division of labor within the Middleware Team. \n \nPerforming work related to supporting the client's applications on-premise and those which will be migrated and hosted on AWS Cloud Services. \n \nMinimum Requirements: \n \n5 yrs. experience installing, deploying, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines. \n \n5 yrs. experience tuning large complex Java based web applications in a Service Oriented Architecture. \n \n5 yrs. experience troubleshooting large complex Java based web applications in a Service Oriented Architecture. \n \n5 yrs. experience / knowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model. \n \n4 yrs. experience creating pipelines in Jenkins to automate WebSphere Application Server configurations. \n \n4 yrs. experience creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments. \n \n4 yrs. experience with different scripting methodologies - UNIX, Jython, YAML, JSON \n \n4 yrs. experience / Knowledge of Java and all phases of the SDLC (Systems Development Life Cycle). \n \n4 yrs. experience using Application Performance Management tools such as DynaTrace and Splunk \n \nPreferred Qualifications: \n \n3 yrs. experience  with IBM Business Automation Workflow \n \n2 yrs. experience with IBM Operational Decision Manager \n \n1 yr. experience with IBM DataPower \n \n1 yrs. experience with Adobe Experience Manager \n \n1 yrs. experience with AWS solution architecture and management \n \nThis is a long-term contract opportunity in Austin, Texas and no sponsorship can be provided. Candidates must be able to pass a background check. Luna Data Solutions, Inc. provides equal employment opportunities to all employees. All applicants will be considered for employment and prohibits discrimination and harassment of any type without regard to age, race, color, religion, sexual orientation, gender identity, sex, national origin, genetics, protected veteran status, and/or disability status. \n",
            "dateupdated": 1723655404
        },
        {
            "id": "cf22a280-6b65-4545-9495-262a1982ed33",
            "title": "ETL DataStage Developer (VA)",
            "location": "Richmond, Virginia, USA",
            "company": "SAI Technologies",
            "description": "Hello, \nI hope you are doing well ! \nRole : DataStage ETL Developer \n \nLocation :  Richmond, VA (Hybrid) Locals only \n \nDuration : Long Term contract \n \nMode of interview : Both Web Cam and In Person Interview \n \nJob Description:- \n \nExperienced ETL developer with skills in IBM InfoSphere/DataStage product line. \n \nMust also have ability to do data analysis, develop requirements and data models. \n \nWe are looking for an individual with expertise in IBM DataStage to join our team. \n \nMust have background in Data Warehousing, Oracle PL/SQL and MS SQL server development. \n \nMust have background in building interfaces between business applications. \n \nExperience working in Agile/Scrum process is highly desired. \n \nBackground in web service development IIB and/or ADF development would be a big plus. \n \nAbility to communicate with business users and developers an absolute must. \n \nClear communication skills - written and oral is a REQUIREMENT. \n \nExperience working with SSIS,Azure Cloud, ADF and Data Bricks. \n \nExperience with other data integration tools and techniques including IIB, MFT,web services, messaging and other modern data warehousing. \n \nExperience working with Oracle PL/SQL and SQL Server Database Development. \n",
            "dateupdated": 1723646738
        },
        {
            "id": "cf7d9538-4365-4a47-b8a2-131c48ee2609",
            "title": "Java/microservice/Salesforce Experts",
            "location": "Remote",
            "company": "Tekfortune Inc.",
            "description": "Job Tittle: Java/microservice/Salesforce Experts \n \nLocation: Remote \n \nDuration: 3+ Months Contract (With Possible Extension) \n \nThis specific project is around salesforce. Optum acquired RVO Health. RVO Health and Optum are both using Salesforce. Originally client moved from Client Salesforce to another instance of Salesforce. Client now needs to move off of Salesforce by end of year and do a lift and shift over to Iterable from Salesforce (Salesforce was not being utilized to fullest capacity). Need people that are Java experts. This will involve extensive Java/microservice work moving and connecting new micro services from both Client side of the house and Client side of the house. \n \nThe CICD work will be completed already. This team will not be responsible for importing any data. Need to create and move existing microservices to hit Iterable. \n \nNeed two home run hitters. Backend Java Experts with Salesforce migration experience \n \n. \n \nTechnical Stack \n \nIterable - Will Win \n \nSalesForce - Must Have. Previous migration/lift and shift from Salesforce to Iterable would absolutely win here. \n \nJava \n \nSpringboot \n \nAzure - Not as vital. Most of infrastructure and pipeline is already in place. \n",
            "dateupdated": 1723660620
        },
        {
            "id": "cfcec404-b18a-40cc-8902-19bc42d6dd15",
            "title": "DevOps engineer",
            "location": "Seattle, Washington, USA",
            "company": "TechWish",
            "description": "Looking for Locals only \n \nWorking closely with a wide range of container automation tooling such as Kubernetes and AWS EKS \n \nDesign, implement, and maintain a secure scalable compute platform as it evolves with the industry \n \nChampion SRE methodologies around monitoring, alerting, and establishing SLOs, SLAs \n \nIdentify and execute on opportunities to optimize existing systems, improve infrastructure and eliminate work through automation \n \nWork alongside other teams in helping provide post mortem analysis of why services broke or became degraded. \n \nDesign and build automation suites to streamline operational support. \n \nGood understanding of CNCF tools like ArgoCD, Crossplane and Kyverno \n \nEstablished understanding of observability fundamentals (Logging, Metrics, Tracing) \n \nAbility to learn quickly, master our existing systems and identify areas of improvement \n \nHave a strong technical background and ability to think creatively to solve problems. \n \nAcquainted with Kubernetes Operators, Controllers and CRDs functionalities \n \nParticipate in our on-call rotation for production services we build \n \nDeep understanding and application of computer science fundamentals: data structures, algorithms, and design patterns. \n \nYou have exposure to and understanding of cloud (AWS, Google Cloud, Azure, etc.) architectures/services. \n \nExcellent understanding of Multi cluster management, operating at Scale \n \nEstablished understanding of observability fundamentals (Logging, Metrics, Tracing) \n",
            "dateupdated": 1723735244
        },
        {
            "id": "cfeb727e-16b9-463f-a240-28c01b0d0dc2",
            "title": "Scrum Master/Project Manager",
            "location": "Maryland Heights, Missouri, USA",
            "company": "TalentBridge",
            "description": "Job Description: \nManages the entire project lifecycle from project definition through implementation. Accountable for meeting agreed upon scope, cost, schedule and quality measures. Develops project plan and drives project milestones. \n \nEstablishes effective communication plan with project team and key stakeholders. Provides day-to-day direction to project resources. \n \nEnsures effective change management occurs throughout the course of the project. Responsible for preparation of documentation, status reports and budgets. Role requires excellent oral and written communications, interpersonal, negotiation, project planning, judgment, leadership, decision-making, analysis and problem-solving skills. \n \nspecialized knowledge of MS Project, Visio, Excel, Word. \n \nRequired Skills: \nMust be an Agile Scrum Master and an expert Jira, Confluence and subsequent reporting. Must be able to manage multiple projects in Dev Ops and operational support. \n \nThis position is on a Dev Ops team so experience in that space with pipeline and CI/CD platform support including AWS, GitLab, Cluster Manager, Rancher, etc. is important. \n \n#INDIT",
            "dateupdated": 1723665950
        },
        {
            "id": "d3dcf243-5de9-4ab5-abdf-1975ce257b8c",
            "title": "Database Administrator :: Columbus, OH (Once in a week onsite)",
            "location": "Ohio, USA",
            "company": "Halcyon Solutions, Inc.",
            "description": "Hi \nGreetings of  the Day! \nPlease find the below needs and let me know your interest. \nTitle: Database Administrator \nLocation: Columbus, OH (Once in a week onsite) \nDuration: long term Contract \nThis position is for (1) Database Administrator 2 \n \nExperience: \n \n3-4 plus years and preferred education: 4 year college degree or equivalent technical study with advance study preferred. \nProven experience as a Database Administrator with expertise in multiple database systems (SQL server, My SQL ) \n \nInstall, configure and maintain database system, including but not limited to SQL server, Oracle, MySQL, and PostgreSQL \n \nExperience in migrating SSIS packages to newer versions and Modernization \n \nExperience with database backup and recovery. \n \nProficiency in SQL and database programming \n \nExperience with cloud database services (Microsoft Azure SQL) \n \nKnowledge of NoSQL databases (e.g cosmos db ) \n \nCertification in database management like Microsoft Azure Database is a plus. \n \nThanks & Regards \n \nSainath| Halcyon Solutions Inc \n \nTalent Acquisition Specialist \n \nEmail: \n",
            "dateupdated": 1723650354
        },
        {
            "id": "d4cce992-9174-4b73-85bd-b389f8f76302",
            "title": "SQL DBA/Engineer - W2",
            "location": "Rock Island, Illinois, USA",
            "company": "XFORIA Inc",
            "description": "SQL DBA/Engineer \n \nType: \n \n6-12mon Contract (with possible conversion) \n \nLocation: \n \nRock Island, IL (Hybrid, 3 Days Onsite) \n \nNote: Need candidates who has solid HCM experience in building custom solutions. \n \nExperience and Education: \n \nResponsibilities: \n \nMigrate from SQL Change Automation to Flyway for database source control (SQL Change Automation is end of life) \n \n~215 database projects to migrate \n \nLevel up on Azure database knowledge and experience \n \nAzure SQL Database \n \nAzure SQL Managed Instance \n \nAzure Data Factory \n \nMore Databricks \n \nAutomate Azure database maintenance and monitoring (ties into IaC templates) \n \nPlatformize our on prem database, reporting, and other resource provisioning processes \n \nThese are all currently built specific to the database team \n \nMigrate Power BI Report Server to the Power BI cloud service. \n \nTransition reporting permissions to App Catalog \n \nGeneral database environment upkeep \n \nReduce inbox noise (handful of maintenance scripts require updates) \n \nResolve database drift not attributed to ongoing projects \n \nFix compatibility level issues introduced with the SQL 2022 upgrade \n \n. \n \nRequired Skills: \n \nDatabase Administration (Microsoft SQL Server) *** Very important. \n \nPowerShell *** Very important, significant experience, not just that they ve used it. \n \nDatabase Development (Microsoft SQL Server)   Somewhat important. \n \nDatabase Administration (Azure SQL Database)   Nice to have. \n \nDatabricks. \n \nPower BI. \n \nSQL Server. \n \nPowershell/python/terraform-significant experince-presceen on this. \n \ndatabase development-SQL. \n \nAzure SQL Database/databricks/PowerBI. \n \nterraform-programming languages. \n \nMigrate Powerbi reports to cloud. \n",
            "dateupdated": 1723659792
        },
        {
            "id": "d50235e9-0b31-4e3f-aac2-2bbd9658f5bd",
            "title": "Subject Matter Expert",
            "location": "Remote or Baltimore, Maryland, USA",
            "company": "Global CI",
            "description": "Your Success is Our Success. \n \nGlobal CI is an award-winning 30-year IT Services company founded on the principles of providing high-quality, value-added technology consulting services. Our vision is to create a better future by improving the lives of the people we serve through emerging technologies. Join us and together we will advance the future of technology services. \n \nGlobal CI offers competitive compensation and non-salary benefits to all eligible employees. \n \nJob Description \n \nAs a Subject Matter Expert, you will play a pivotal role in advising our customers on their cloud adoption and transformation journeys. Your expertise in cloud technologies, coupled with strategic thinking and business acumen, will enable our clients to leverage cloud solutions effectively to achieve their business objectives. \n \nAs a Subject Matter Expert, you will need to be an expert in single or multiple technical disciplines. Provides Expert guidance and insight into specific technologies and their application and independently performs a variety of system design and integration tasks where a specific subject matter expertise is necessary. \n \nPrimary Responsibilities: \n \nPlans and performs research, design assessment, development, integration and other assignments in a specific technical area. \n \nSupervises broad team of systems engineers. \n \nResponsible for highly complex technical/engineering areas. \n \nMay perform other duties, as assigned. \n \nFacilitate session(s) to understand detailed requirements (infra, security, etc.): overview of shared services offerings, introduce managed services available, additional deep dives as requested \n \nDemonstrate a thorough understanding and expertise in CMS Hybrid Cloud Product and Service offerings \n \nDevelop and maintain close advisory relationships with the Application Development Organizations (ADOs) being supported within your portfolio \n \nEnsure all ADOs supported within the portfolio maintain a strong security posture \n \nThrough weekly/monthly reviews of performance and cost data, lead performance and cost optimization efforts \n \nLead all application migration and modernization efforts \n \nCoordinate and ensure all production readiness activities are complete prior to any major cutovers are conducted \n \nCreate and maintain application profiles \n \nCoordinate Escalations on behalf of CMS IUSG's Shared Service Providers and O&M Teams. \n \nApply Product Management principles to develop, maintain, optimize, and evangelize various products across the CMS ecosystem. \n \nMaintain domain knowledge expertise in cloud operations and DevOps best practices. \n \nInfluence development of solutions that impact strategic project/program goals and business results while also leading work of other technical staff. \n \nResolve highly complex problems using significant application of technical knowledge, conceptualizing, reasoning, and interpretation. \n \nBasic Qualifications: \nBachelor's degree or equivalent and seventeen (17) years of general experience. Sixteen (16) years of general experience is equivalent to a bachelor's degree. With a master's degree, fifteen (15) years of general experience is required. With a PhD, thirteen (13) years of general experience is required. \n \nExperience managing a portfolio of applications \n \nExperience successfully working across multiple vendors \n \nKnowledge of cloud-based security tools, best practices and policies including demonstrated experience protecting all layers of the application stack. \n \nKnowledge of the Software Delivery Life Cycle (SDLC). \n \nExcellent writing and verbal communication skills. \n \nAbility to manage conflict effectively. \n \nAbility to adapt and be productive in a fast-paced dynamic environment. \n \nExcellent communication and collaboration skills supporting multiple stakeholders and business operations. \n \nSelf-starter, self-managed, and a team player. \n \nPreferred Qualifications: \nCloud Certification (e.g., AWS SysOps Administrator, Azure Administrator). \n \nAgile-based knowledge and skill, including experience with Scrum Ceremonies and work management tools (e.g., (JIRA, Confluence). \n \nSecurity Skills Knowledge of information assurance compliance and information security basics. \n \nBenefits include: \n \nComprehensive medical, dental, vision, life, and short & long-term disability insurance + health savings account \n \nMatching 401k retirement plan + IRA's and Roth IRA's \n \nGenerous paid time off and paid holidays \n \nEmployee recruitment/referral bonus \n \nPaid community service hours \n \nTuition reimbursement \n \nEmployee discounts \n \nAt Global Commerce & Information, Inc. we celebrate, support, and are committed to creating a diverse and inclusive environment. We're proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or any other legally protected characteristics. \n \nGlobal Commerce & Information, Inc maintains a drug-free workplace. \n",
            "dateupdated": 1723737618
        },
        {
            "id": "d5719fac-eef3-46d5-89a0-873655c1b08d",
            "title": "Sr React Developer with Node and Azure",
            "location": "Atlanta, Georgia, USA",
            "company": "V-Soft Consulting Group, Inc",
            "description": "Sr React Developer with Node and Azure \n \nPrimary Location: Atlanta, Georgia \n \nMultiple locations: Atlanta, Seattle, Minneapolis \n \nNeed locals only \n \nV-Soft Consulting is currently hiring for a \n \nSr       React Developer with Node and Azure \n \nfor our premier     client in \n \nAtlanta, Georgia \n \n. \n \nKnowledge, Skills and Abilities \n \nReact (SME Level). \n \nJavaScript/TypeScript. \n \nNode JS and Azure. \n \nResponsive Application Design. \n \nJest, RTL, or similar test   libraries. \n \nCloud Native Development. \n \nMicroservices. \n \nWeb API. \n \nWHAT YOULL DO: \n \nJob Responsibilities: \n \nWill play a pivotal role in building and         modernizing web application projects, with a particular focus on         creating dynamic, scalable, and responsive applications using         React and micro-frontend architectures. \n \nWill help lead web development strategy, advocating         for best practices in frontend development, and ensuring         projects align with the latest industry standards and customer expectations. \n \nScope and Impact: \n \nLead the development and implementation of complex         web applications, focusing on high-performance solutions using         React and micro-frontend architectures. \n \nEvaluate and adopt new technologies and frameworks         to improve the scope and quality of our web platforms and         portfolios, ensuring they meet market demands and technological advancements. \n \nInterested? \n \nQualified candidates should send their resumes to \n \nV-Soft Consulting Group is recognized among the top 100     fastest growing staffing companies in North America, V-Soft     Consulting Group is headquartered in Louisville, KY with strategic     locations in India, Canada and the U.S. V-Soft is known as an agile,     innovative technology services company holding several awards and     distinctions and has a wide variety of partnerships across diverse     technology stacks. \n \nAs a valued V-Soft Consultant, youre eligible for full     benefits (Medical, Dental, Vision), a 401(k) plan, competitive     compensation and more. V-Soft is partnered with numerous Fortune 500     companies, exceptionally positioned to advance your career growth. \n \nV-Soft Consulting provides equal employment     opportunities to all employees and applicants for employment and     prohibits discrimination and harassment of any type without regard     to race, color, religion, age, sex, national origin, disability     status, genetics, protected veteran status, sexual orientation,     gender identity or expression, or any other characteristic protected     by federal, state or local laws. \n \nFor more information or to view all our open jobs,     please visit  or call . \n \n#LI-DC1 \n",
            "dateupdated": 1723659804
        },
        {
            "id": "d597dddc-9b46-404d-9924-f949d82463f2",
            "title": "Hybrid In Illinois || Lead Tricentis Tosca Test Engineer",
            "location": "Chicago, Illinois, USA",
            "company": "Trail Blazer Consulting LLC",
            "description": "Lead Tosca Test Engineer. \n \nMode of interview: 2 Virtual rounds. \n \nLocation: Must reside or be able to relocate to Chicago, IL \n \nInterview: Video. \n \nType: Hybrid. \n \nJOB: \n \nJob Description \n \nDevelop automation roadmap and automation strategy for Navistar leveraging Tricentis Tosca for functional automation. Qtest as test management repository and Neo Load for Non-Functional Automation \n \nMust have hands on experience in setting up and troubleshooting Tosca. \n \nSupport test automation solutions for different environments and multiple platforms across Navistar landscape (Web, Windows, ERP, Sales Force and API's) \n \nExcellent hands-on experience with integrating SolMan, Jira, Jenkins with Tosca Experience to implement CICD pipeline. \n \nExperience working with Jenkins. \n \nExperience with integrating the Tricentis TOSCA product suite with DevOps pipeline and with databases including customizing/extending other related functionalities. \n \nFamiliarity with Selenium automated testing and converting selenium scripts to Tosca. \n \n12 plus years  experience in software test automation minimum of 5 years  with and Qtest hands on experience \n \nExcellent analytical and problem-solving skills and ability to work within a team and in collaboration with different teams. \n \nMinimum of 3 years  experience in Tricentis Qtest is mandatory. \n \nMinimum of 1 years  experience with Neo Load is recommended. e. Relevant certifications in Tricentis Tosca, Qtest and Neo Load are a plus \n",
            "dateupdated": 1723656226
        },
        {
            "id": "d6c57349-ca25-4a0f-8c31-61ed26dbe610",
            "title": "Senior Cloud AWS Engineer - Remote / Telecommute",
            "location": "Richmond, Virginia, USA",
            "company": "Cynet Systems",
            "description": "We are looking for \n \nSenior Cloud AWS Engineer - Remote / Telecommute \n \nfor our client in \n \nRichmond, VA \n \nJob Title: Senior Cloud AWS Engineer - Remote / Telecommute \n \nJob Location: Richmond, VA \n \nJob Type: Contract \n \nJob Description: \n \nResponsibilities: \n \nEngage with architects, developers and technical support teams to achieve success in deployment of Cloud application services within a managed service GovCloud environment. \n \nAnalyze, define and document requirements for data, workflow, and logical processes. \n \nAnalyze and translate business, information and technical requirements to create patterns for solutions that integrate across applications, systems and platforms to achieve business objectives. \n \nAssess foundational services, integration services, cloud operations and management capabilities. \n \nSupport preparation of documentation including application designs, Assessments, Security Management, Implementation Plans and post implementation documentation. \n \nLead by example, demonstrating high performance in the areas of customer satisfaction, collaboration, teamwork, and reliability. \n \nParticipate in the establishment of local standards, patterns, and practices for cloud integration, while providing input and influence to broader organizational standards and initiatives. \n \nResponsible for the planning and engineering of an organization's systems infrastructure. Includes the implementation and design of hardware and software. \n \nMonitors the performance of systems. \n \nPerforms a variety of complicated tasks. \n \nWorks under general supervision. \n \nBachelor's Degree or equivalent experience with 3 years of relevant work experience. \n \nThe Cloud Engineer Services Team is looking for a seasoned IaC/Pipeline professional to assist in our efforts to migration application from existing data centers into AWS Gov Cloud. \n \nIn this role candidate Terraform and AWS service expertise to integrate highly scalable, flexible, and resilient cloud solutions that address customer needs while reflecting cloud principles and best practices. \n \nAs a member of the Cloud Engineer Service s Chapter, candidate will work directly within an. \n \nApplication Development Team to implement blueprints/solutions which establish a foundation for resilient and effective environments. \n \nQualifications: \n \n4+ years hands-on IT solution delivery engineering experience with cloud services including planning, development, migration and integration of applications and services from on premises infrastructure to cloud based platforms. \n \n1+ years of interpretive programing experience such as Python (preferred). \n \n1+ years shell scripting, Bash preferred. \n \n2+ years of for hands-on IaC/CaC contributions leveraging Terraform and Cloud Formation. \n \n2+ years of automated application deployment via automated pipelines. \n \nleveraging Blue/Green or Carney deployment practices. \n \nSolid understanding of performance/load and functional automated testing practices; automated testing experience a plus. \n \nSolid understanding of the evaluation of application performance management utilization metrics (CPU, memory, garbage collection, etc...). \n \nAnsible experience/awareness a plus. \n \nSolid understanding of the DevOps Infinity Loop a plus. \n \nExperience with enterprise public cloud platforms such as AWS and Microsoft Azure; including AWS networking, computing, and security services (e.g. VPC, EC2, AWS Config, AWS Inspector, Guard Duty). \n \nExperience with CI and Source Code Management tooling (e.g. Git, GitLab) utilizing standard branching strategies. \n \nFlexibility to adjust to multiple demands, shifting priorities, ambiguity, and rapid change. \n \nComprehensive knowledge pertaining to concepts and principles in functional area. \n \nGeneral knowledge of department/business lines, Reserve Banks, and System operations, policies, procedures, and technologies a plus. \n \nExcellent interpersonal, negotiation, creativity, attention to detail, and oral and written communications skills tailored for the intended audience. \n \nContinual improvement, technically curious mindset. \n \nThe individual is responsible for understanding and applying risk management discipline in decision making and contributing to his or her function s risk management. \n \nWorks under direction and guidance in planning details of procedures and methods to attain definite objectives. \n \nMakes decisions within established or widely accepted standards. \n \nAchieves assigned/planned results by decisions and actions based on professional methods, training, business principles, and practical experience. \n",
            "dateupdated": 1723670033
        },
        {
            "id": "d7b3ef5e-8021-4248-89be-7c66c604586b",
            "title": "Senior BI Architect",
            "location": "Boston, Massachusetts, USA",
            "company": "IT-SCIENT",
            "description": "Senior BI Architect \n \nRequired Documents : \nCandidate employed by another MA Govt Agency now or in last 12 months? If yes, for most recent engagement, enter MA Govt Agency name, Rate Card Position Title, and Vendor Bill Rate \n \nHow many years of direct experience does the candidate have designing and implementing Business Intelligence strategies? \n \nHow many years of experience does the candidate have managing within an IT environment? \n \nList any relevant professional certifications that the candidate has. \n \nRole : \n \nSenior BI Architect \n \nLocation : [Boston, MA, 02116], Massachusetts, United States \nPosition Summary \n \nCHIA is seeking a contract Senior BI Architect to design, develop, and implement our organization's BI strategy for a  health data warehouse project for approximately fifteen (15) months. The project team, consisting of temporary and permanent staff, will rebuild an existing data warehouse using new ETL, Business Intelligence, and database platforms with an eye towards cost containment and improved technical performance. This key role will work with Senior Management and our Data Analysts to identify business goals and objectives and then design and implement a BI solution that meets those goals. \nThe Senior BI Architect will also research and recommend a new enterprise level BI tool, work with business teams to gain consensus on that tool and help train users on how to use it. \nResponsibilities \n \nTo be considered for this position, the candidate must demonstrate specific experience in: \nLeading the design and implementation of semantic layers on top of Snowflake and/or Postgres, in an MS Azure environment. \n \nAnalyzing business needs and recommending an appropriate BI tool that will provide the required performance for Data Analysts. \n \nLeading a business wide BI solution implementation. \n \nAssisting staff in a consulting capacity, with implementing and using BI tools and technologies. \n \nTroubleshooting BI issues and problems and providing support to BI users. \n \nWorking with Health Care data, preferably in the payer space. \n \nCloud technologies, preferably MS Azure and Snowflake. \n \nQualifications \n \nThe ideal candidate will have: \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years' experience working in the Business Intelligence space at an Architect level. \n \n5+ years' experience implementing BI solutions in Azure cloud environments. \n \n2+ years' experience working with Snowflake and Postgres databases. \n \nDemonstrable experience in evaluating business needs and implementing BI strategies to meet those needs. \n \nA combination of technical expertise and leadership skills to effectively navigate the complexities supporting multiple in-house business units. \n",
            "dateupdated": 1723649461
        },
        {
            "id": "dabfa82d-e786-4490-8838-38ae008cb30b",
            "title": "BI Architect",
            "location": "Boston, Massachusetts, USA",
            "company": "Stellar IT Solution",
            "description": "Role: \n \nBI architect \n \nLocation: Boston, MA (2 days onsite) \n \nJob Description \n \nTop Skills' Details \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years' experience working in the BI space at an Architect level. \n \n5+ years' experience implementing BI solutions in Azure cloud environments. \n \n2+ years' experience working with Snowflake and Postgres databases. \nPosition Summary: \n \nCHIA is seeking a contract Senior BI Architect to design, develop, and implement our organization's BI strategy for a health data warehouse project for approximately fifteen (15) months. The project team, consisting of temporary and permanent staff, will rebuild an existing data warehouse using new ETL, BI, and database platforms with an eye towards cost containment and improved technical performance. This key role will work with Senior Management and our Data Analysts to identify business goals and objectives and then design and implement a BI solution that meets those goals. \n \nThe Senior BI Architect will also research and recommend an enterprise-level BI tool, work with business teams to gain consensus on that tool, and help train users on how to use it. \n \nResponsibilities: \n \nTo be considered for this position, the candidate must demonstrate specific experience in: \n \nLeading the design and implementation of semantic layers on top of Snowflake and/or Postgres, in an MS Azure environment. \n \nAnalyzing business needs and recommending an appropriate BI tool that will provide the required performance for Data Analysts. \n \nLeading a business wide BI solution implementation. \n \nAssisting clients in a consulting capacity, with implementing and using BI tools and technologies. \n \nTroubleshooting BI issues and problems and providing support to BI users. \n \nDeveloping documentation and training materials as required to support the BI users. \n \nWorking with healthcare data, preferably in the payer space. \n \nCloud technologies, preferably MS Azure and Snowflake. \n \nQualifications: \n \nThe ideal candidate will have: \n \nDemonstrated project experience with multiple leading cloud BI tools. \n \n5+ years' experience working in the BI space at an Architect level. \n \n5+ years' experience implementing BI solutions in Azure cloud environments. \n \n2+ years' experience working with Snowflake and Postgres databases. \n \nDemonstrable experience in evaluating business needs and implementing BI strategies to meet those needs. \n \nA combination of technical expertise and leadership skills to effectively navigate the complexities supporting multiple in-house business units. \nAdditional Skills & Qualifications: \n \nPlease include answers to Sample Questions in submittals!! \n \nInclude answers to these questions on the Candidate Bid Sheet. \n \nHow many years of direct experience does the candidate have designing and implementing Business Intelligence (BI) strategies? \n \nHow many years of experience does the candidate have managing within an IT environment? \n \nPlease list any relevant professional certifications the candidate has.",
            "dateupdated": 1723672862
        },
        {
            "id": "dbf439e6-b9c2-4fa1-bbd2-9ddab3b226d9",
            "title": "ETL Developer",
            "location": "Richmond, Virginia, USA",
            "company": "Swanktek",
            "description": "Role: ETL Developer \n \nLocation: Richmond, VA(Hybrid) \n \nDuration: Long Term \n \n* Experienced ETL developer with skills in IBM InfoSphere/DataStage product line. Must also have ability to do data analysis, develop requirements and data models. \n \n* We are looking for an individual with expertise in IBM DataStage to join our team. \n \n* Must have background in Data Warehousing, Oracle PL/SQL and MS SQL server development. \n \n* Must have background in building interfaces between business applications. \n \n* Experience working in Agile/Scrum process is highly desired. \n \n* Background in web service development IIB and/or ADF development would be a big plus. \n \n* Ability to communicate with business users and developers an absolute must. \n \n* Clear communication skills - written and oral is a REQUIREMENT. \n \nSkill Required / Desired Amount of Experience: \n \nAdvanced skills in IBM's Infosphere Data Stage product line Required 10Years. \n \nExperience working with Oracle PL/SQL and SQL Server Database Development Required 8Years. \n \nBackground in data integration between business systems Required 6Years. \n \nRequirements analysis and data modeling Highly desired 6Years. \n \nExperience working with SSIS, Azure, ADF and Data Bricks Nice to have 6Years. \n \nExperience with other data integration tools and techniques including IIB, MFT, web services, messaging and other modern data warehousing Nice to have 6Years. \n",
            "dateupdated": 1723651687
        },
        {
            "id": "e1f2c6b4-f8a5-4569-84fe-4d74b217c5d2",
            "title": "\"AWS CLOUD NATIVE Developer\"",
            "location": "Atlanta, Georgia, USA",
            "company": "Cloud Resources LLC",
            "description": "AWS CLOUD NATIVE Developer \n \nAtlanta, GA - Locals only \n \nPlease dont share DevOps or Data Engineer Resume \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nAgile methodologies and SCRUM framework \n \nExperience with CI/CD pipelines and DevOps practices \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n \nAWS certifications (e.g., AWS Certified Developer) \n",
            "dateupdated": 1723736054
        },
        {
            "id": "e2047d6e-3baa-443a-822b-d7d7cd4d4ccb",
            "title": "AWS ENGINEER/DEVELOPER - HYBRID",
            "location": "Atlanta, Georgia, USA",
            "company": "ARK Infotech Spectrum",
            "description": "Candidates must have experience developing software applications in an AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nProject Overview: \n \nThe GTA CJEP project is a modernization of the Criminal Justice Exchange Program that shares data between different agencies, counties, cities, etc.  This project will take the current Software AG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API s and web services will be leveraged to facilitate this modernized solution as much as possible. \n \nPosition Overview: \n \nAs an AWS Cloud Developer at GTA you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services, custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nSkill \n \nYears Used \n \nLast Used \n \nProven experience developing cloud application software \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nAgile methodologies and SCRUM framework \n \nExperience with CI/CD pipelines and DevOps practices \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n \nAWS certifications (e.g., AWS Certified Developer) \n",
            "dateupdated": 1723732690
        },
        {
            "id": "e6022679-fdc0-4159-acaa-ec5f09331a6d",
            "title": "C2C | HCL - DevSecOps Engineer (Cloud Security & Compliance Focus) || Austin, TX- Local Onsite",
            "location": "Austin, Texas, USA",
            "company": "Altezzasys",
            "description": "Hi, \n \nPlease find the below job description. \n \nJob Title: \n \nDevSecOps Engineer (Cloud Security & Compliance Focus) \n \nLocation: \n \nLocal Texas candidates. \n \nDepartment: \n \nCloud CISO Engineering/Information Security \n \nNote from the Client: \n \nLook for Devops with cloud security \n \nSummary: \n \nWe are seeking a highly motivated and security-conscious DevSecOps Engineer to join our team. You will be a critical part of our security and compliance efforts, ensuring the integrity and confidentiality of our systems and data. Your hands-on experience with Istio, Envoy, Kubernetes, and Terraform, coupled with your security penetration testing or automated API testing experience, makes you an ideal candidate to drive our security initiatives in a cloud-native environment. \n \nResponsibilities: \n \nSecurity Architecture and Implementation: \n \no Design and implement secure cloud-native architectures with a focus on Istio service mesh and Kubernetes container orchestration. \n \no Harden and secure containerized workloads and Microservices using best practices. \n \no Leverage Terraform for infrastructure as code (IaC) deployments, ensuring security is baked into the process from the start. \n \no Implement security controls and monitoring solutions to detect and respond to potential threats. \n \nCompliance and Security Auditing: \n \no Collaborate with security and compliance teams to ensure adherence to industry standards and regulations. \n \no Conduct regular security audits and penetration testing to identify vulnerabilities and recommend remediation strategies. \n \no Develop and maintain documentation for security policies, procedures, and incident response plans. \n \nDevSecOps Integration: \n \no Integrate security practices and tools into the CI/CD pipeline to automate security testing and vulnerability scanning. \n \no Implement and maintain security tools for code analysis, dependency management, and vulnerability tracking. \n \no Promote a culture of security awareness and collaboration within the development and operations teams. \n \nIncident Response: \n \no Participate in incident response activities, including investigation, containment, and recovery. \n \no Analyze security incidents and identify root causes to prevent future occurrences. \n \nQualifications: \n \nHands-on Experience: \n \no Strong practical experience with Istio service mesh, Envoy proxy, Kubernetes, and Terraform. \n \no Proficiency in security penetration testing methodologies or automated API testing tools. \n \no Familiarity with cloud security best practices and cloud-native technologies. \n \nSecurity and Compliance Knowledge: \n \no Understanding of security principles, vulnerabilities, and mitigation techniques. \n \no Knowledge of industry security standards and compliance regulations. \n \no Experience in conducting security audits and vulnerability assessments. \n \nPassion for Security: \n \no A strong desire to stay abreast of the latest security trends and technologies. \n \no Enthusiasm for sharing knowledge and promoting security best practices within the team. \n \nStrong Communication and Collaboration: \n \no Ability to effectively communicate complex security concepts to technical and non-technical stakeholders. \n \no Excellent teamwork and collaboration skills, working effectively with cross-functional teams. \n \nAdditional Desirable Skills: \n \nExperience with cloud platforms such as AWS, Azure, or Google Cloud Platform. \n \nProgramming/scripting skills (Python, Java, Bash, etc.) \n \nCertifications in security and cloud technologies (CISSP, CCSP, etc.) \n \nThanks & Regards \n \nRatnesh Singh \n \nUS IT Recruiter \n \nRatnesh.Singh(@)AltezzaSys(.)com \n",
            "dateupdated": 1723668701
        },
        {
            "id": "e781ae14-1a5e-43c9-82bd-8bc6b6bc50ba",
            "title": "DevOps Engineer 24-00303",
            "location": "Pleasanton, California, USA",
            "company": "ZealTech, Inc.",
            "description": "Location: Pleasanton, CA (Hybrid - 2 days. Tuesday & Wednesday) \n \nDuration: Longterm \n \nJob Description \n \nWe are seeking a skilled DevOps Engineer to join our team and contribute to the efficient and reliable operation of our infrastructure. The ideal candidate will have a strong background in AWS, Kubernetes, and automation tools, and a passion for building and maintaining scalable, high-performance systems. \n \nResponsibilities: \n \nDesign, implement, and maintain cloud-based infrastructure on AWS. \n \nManage and optimize Kubernetes clusters for efficient container orchestration. \n \nAutomate infrastructure provisioning and configuration using Ansible. \n \nCollaborate with development teams to implement CI/CD pipelines using Bitbucket and Synk. \n \nMonitor system performance and troubleshoot issues. \n \nImplement security best practices to protect infrastructure and data. \n \nContribute to knowledge sharing and documentation using Confluence. \n \nQualifications: \n \nProven experience as a DevOps Engineer with a strong understanding of DevOps principles and practices. \n \nIn-depth knowledge of AWS services (EC2, S3, RDS, VPC, IAM, etc.). \n \nProficiency in Kubernetes and containerization technologies. \n \nStrong scripting skills (Python, Bash). \n \nExperience with configuration management tools like Ansible. \n \nFamiliarity with version control systems (Bitbucket). \n \nExperience with CI/CD pipelines and tools (Synk). \n \nKnowledge of Linux and Windows operating systems. \n \nAbility to troubleshoot and resolve complex technical issues. \n \nStrong communication and collaboration skills. \n \nPreferred Qualifications: \n \nExperience with infrastructure as code (IaC) tools like Terraform. \n \nKnowledge of monitoring and logging tools (e.g., CloudWatch, ELK stack). \n \nExperience with database administration (MySQL, PostgreSQL). \n",
            "dateupdated": 1723658317
        },
        {
            "id": "e81f83da-3286-4d3e-a191-af29e2322236",
            "title": "Devops engineer",
            "location": "US",
            "company": "VDart, Inc.",
            "description": "DevOps Engineer \n \nLocation: Remote (Canada/LATAM) \n \nMultiple Openings Available \n \nKey Responsibilities: \n \nDevelop and maintain cloud infrastructure using AWS or other cloud platforms. \n \nImplement and manage Kubernetes clusters (EKS) and containerized applications. \n \nUtilize Helm for package management within Kubernetes. \n \nWrite and maintain scripts and code in various programming languages to automate processes. \n \nUse Terraform/Terragrunt for infrastructure provisioning and management. \n \nWork with ServiceMesh (Istio) to manage and secure service-to-service communications. \n \nImplement observability tools like Datadog or Prometheus to monitor system health and performance. \n \nCollaborate using GitHub Actions for CI/CD pipelines. \n \nApply security and policy management using tools such as Kyverno, OPA, or GateKeeper. \n \nEmbrace and implement SRE (Site Reliability Engineering) concepts to ensure system reliability and performance. \n \nManage continuous delivery with ArgoCD. \n \nRequired Skills: \n \nCloud Platforms (AWS or any Cloud): Must Have \n \nKubernetes (EKS): Must Have \n \nHelm: Must Have \n \nProgramming/Scripting Language: Must Have \n \nInfrastructure as Code (Terraform/Terragrunt): Must Have \n \nServiceMesh (Istio) & Networking Knowledge: Must Have \n \nPreferred Skills: \n \nObservability Tools (Datadog/Prometheus): Good to Have \n \nCI/CD with GitHub Actions: Good to Have \n \nSecurity Tools (Kyverno/OPA/GateKeeper): Good to Have \n \nSRE Concepts: \n \nGood to Have \n \nArgoCD \n \n: Good to Have \n \nVDart Group, a global leader in technology, product, and talent management, empowers businesses with comprehensive solutions through our four distinct, industry-leading business units. With a diverse team of over 4,000 professionals across 13 countries, we deliver strong results across various industries, including Fortune 500 companies. \nLeveraging our deep expertise as a global provider of resources and solutions, we serve a wide range of industry verticals, including BFSI, Automotive, Healthcare, Mobility, Energy, Life Sciences, Manufacturing, Consumer Industries, and Technology. \nWith over 16 years of experience, VDart has evolved to meet the needs of leading technology brands, placing and training more than 20,000 professionals and shaping the industry's future. \nOur continuous reinvention, providing resources for IT solutions and unique digital solutions, has positioned us as a top growth leader in digital talent management and technology consulting. \nCommitted to \" \n \nPeople, Purpose, Planet \n \n,\" we prioritize social responsibility and sustainability, as evidenced by our EcoVadis Bronze Medal Certification and participation in the UN Global Compact. \nOur dedication to delivering strong results has earned us recognition as a trusted advisor for businesses seeking to drive innovation and growth, including many Fortune 500 companies. \nJoin our network! Partner with VDart Group to leverage our global network, industry expertise, and proven track record with a diverse clientele.",
            "dateupdated": 1723651316
        },
        {
            "id": "e8406fb4-482d-4158-93db-0e8008a6d5a3",
            "title": "ADAS - Dev/Ops Engineer",
            "location": "Remote or San Jose, California, USA",
            "company": "Abidi Solutions",
            "description": "Job Title: \n \nADAS - Dev/Ops Engineer \n \nLocation:  San Jose, CA \n \nEmployment Type: Contractor \n \nHybrid Onsite - some flexibility for hybrid WFH; core work days Tue-Thu in office \n \n- Seasoned Python developer \n \n- Solid understanding of C/C++ and build systems (like cmake, etc.) \n \n- Solid understanding of version control systems (like git, etc.) \n \n- practical CI / CD know-how from previous positions / jobs (like in GitLab, Jenkins, etc.) \n \n- Experience with Azure services \n \n- Experienced in shell programming (like bash) \n \n- Advanced knowledge with Linux is a plus \n \n- Practical experience with tools like JIRA, CodeBeamer, etc. is a plus \n \n- Knowledge with ROS 1 or 2, ADTF and streaming frameworks are a plus \n \n- Experience with embedded systems is a plus \n \nBased on the current tasks in the DevOps and Tools team, would rather prefer to hire a software developer with 'practical experience' in DevOps than a DevOps guru / certified DevOps person. \n \nThey need a developer/automation engineer for the \"DevOps\" role in the automotive industries in CA - any of the OEMs, etc; coming from the auto domain would be super helpful for their ramp up at Audi. Also person doesn't have to be super skilled at cloud platform integration as they have their own local servers. Its a smaller office and team so this will be a ops person who can set up new users on the fly, grant permissions, able to code in Linux for server configurations, automate repetitive tasks in the pipeline on the server, etc. \n \nRole Summary: \n \nThe role is to support with DevOps tools, targeting automated testing and continuous integration of software products. The tasks will include automation of variated development processes: supporting data collection from test fleet, automation of Labelling, SIL and HIL processes, integration of different Project Management tools (e.g Jira, Codebeamer), linking automated tests to PM tools, implementing build and test servers for multiple platforms, work on deployment infrastructure. Software will be developed for multiple platforms, from embedded SW supporting data collection in the test fleet, up to modules running in the cloud. As side task, the candidate will be required to assist on the development of concept products in vehicle or cloud. The candidate is required to have very good programming skills, especially in C++ and Python languages, and to be able to design solutions for complex problems. The candidate is expected to work on multiple projects simultaneously, so teamwork, good planning, organization and time management skills are required. \n \nRole Responsibilities: \n \nDevelopment of Tools for Process Automation (65%) \n \nDocumentation and Project Management (25%) \n \nDevelopment of Concept Products in vehicle or cloud (10%) \n \nRequired: \n \n+3 years of experience with software development \n \nBachelors Degree in Engineering (computer science or comparable) \n \nDesired: \n \nMasters or PhD in in Engineering (computer science or comparable) \n \nRequired Skills: \n \nProven programming experience (C/C++, Python, Java Script) \n \nExpertise in Continuous Integration and automated tests environments \n \nExperience using REST/Swagger APIs \n \nKnowledge on industry development processes like A-SPICE, ISO9001. \n \nExperience using GitLab/GitHub, Artifactory, Conan, Jenkins/Bamboo \n \nExperience with Linux and Windows OS \n \nDesired Skills: \n \nExperience developing for ARM / Linux environments \n \nExperience with Azure or AWS APIs \n \nExperience with CMake and cross-compilation \n \nExperience with Docker and VMWare \n \nExperience with CodeBeamer, Zephyr \n \nExperience with Unit Tests, SIL, HIL and Simulation \n \nWork Flexibility: \n \nFlexibility to travel (domestic and international) \n \nFull time position \n \nHybrid On-Site position \n",
            "dateupdated": 1723734948
        },
        {
            "id": "e92c3411-7140-4510-9865-1cb2a407113d",
            "title": "Sr Java Developer",
            "location": "Remote or US",
            "company": "Spar Information Systems",
            "description": "Hello Everyone, \nHope you are doing good!!!! \n \nMy name is Pavan and I work with SPAR Information System., I have a great opportunity for you, please find the job details below, if you are interested in applying please send me your updated resume and best time for you to discuss about this opportunity in details. \n \nRole: Sr Software Engineer (Java) \n \nLocation: Remote \n \nDuration: \n \n3 Months Contract to hire \n \nPosition Description \n \nOur Senior Engineer is a key member of the engineering staff working on Web solutions ensuring that we provide -less experience to our customers and maintain the highest standards of protection and availability. Our team thrives and succeeds in delivering high quality technology products and services in a hyper-growth environment where priorities shift quickly. The ideal candidate has broad and deep technical knowledge, typically ranging from front-end UIs through back-end systems and all points in between, and a proven background in JavaScript, ReactJS, Java, Linux, Microservices, Containers (Kubernetes), and designing, implementing, and maintaining front-end UIs. \nPosition Responsibilities \n \nAs a Senior Engineer, you will: \nScope, design, and build scalable, resilient distributed systems \n \nBuild product definition and leverage your technical skills to drive towards the right solution \n \nEngage in cross-functional collaboration throughout the entire software lifecycle \n \nLead in design sessions and code reviews with peers to elevate the quality of engineering across the organization \n \nDefine, create, and support reusable application components/patterns from a business and technology perspective \n \nUtilize programming languages like JavaScript, TypeScript, Java, C#, Python, and Container Orchestration services including Docker and Kubernetes, and a variety of Azure tools and services across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) to perform advanced-level Java application design under minimal direction \n \nUtilizes developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) to perform advanced-level Mobile/Web/UI design, implementation, and maintenance activities under minimal direction \n \nMentor other engineers \n \nConsistently share best practices and improve processes within and across teams \n \nQualifications \n \nFluency and specialization with at least two modern languages such as JavaScript, TypeScript, JSX, Java, C++, Python or C# including object-oriented design \n \nProven understanding of micro-services architecture and extensible REST APIs \n \nAdvanced understanding of DevOps Concepts and Cloud Architecture \n \nExperience building the architecture and design (architecture, design patterns, reliability, and scaling) of new and current systems \n \nExperience with application monitoring tools and performance assessments \n \nKnowledge of security protocols and products: Understanding of Active Directory, Windows Authentication, SAML, OAuth \n \nIn-depth knowledge of CS data structures and algorithms \n \nKnowledge of Kubernetes or willingness and ability to learn \n \nExperience with continuous delivery and infrastructure as code \n \nKnowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) \n \nExperience in Web Application Frameworks \n \nExperience in securing web applications \n \nStrong problem-solving ability \n \nAbility to excel in a fast-paced, startup-like environment \n \nExperience \n \n4+ years of professional software development experience within Web frameworks/SDKs/languages \n \n3+ years of experience with architecture and design \n \n3+ years of experience with AWS, Google Cloud Platform, Azure, or another cloud service \n \n2+ years of experience in open-source frameworks \n \nEducation \n \n, Information Systems, or equivalent education or work experience \n \nThanks & Regards, \n \nPavan Raikhelkar \n \nLEAD \n \nTALENT ACQUISITION SPECIALIST \n \nDirect Number:- \n \nPhone:  x 323 \n \nFax : \n \nEmail: \n \nWebsite: \n \n(An E-verify Company) \n \nNOTE: \n \nWe respect your online privacy. This is not an unsolicited mail. Under bill 1618 title III passed by the 105th us congress this mail cannot be considered Spam as long as we include contact information and a method to be removed from our mailing list. If you are not interested in receiving our e-mails, please reply with a \"REMOVE\" in the subject line. We apologize for any inconvenience caused by this mail.",
            "dateupdated": 1723663881
        },
        {
            "id": "e9bac219-178e-4d67-8c0d-1203b11ce8d2",
            "title": "DevSecOps Sr. Engineer",
            "location": "Remote",
            "company": "Chabez Tech LLC",
            "description": "Title: DevSecOps Sr. Engineer \n \nRate: $60-65/hr on C2C | $55/hr on W2 \n \nLocation: Remote/(Phoenix, AZ) \n \nDevSecOps Sr. Engineer: \n \nDevSecOps Integration: \n \nCollaborate with development, operations, and security teams to embed security practices into the entire software development lifecycle Implement and maintain automated security controls throughout the CI/CD pipeline. \n \nProven experience in both DevOps and SRE roles, with a focus on security integration. Strong knowledge of cloud platforms (e.g., AWS, Azure, Google Cloud Platform) and container orchestration tools (e.g., Kubernetes). Proficiency in scripting languages (e.g., Python, Bash) for automation. Infrastructure as Code (IaC): Leverage Infrastructure as Code principles to automate the provisioning and configuration of infrastructure components with a strong focus on security. Implement security controls using tools such as Terraform, Ansible, or Chef. \n \nContinuous Monitoring and Incident Response: Establish and maintain continuous monitoring solutions to detect security incidents and vulnerabilities. Develop and execute incident response plans in collaboration with relevant teams. \n \nSRE Best Practices: \n \nApply SRE principles to enhance system reliability, performance, and availability. \n \nImplement and maintain service level objectives (SLOs) and service level indicators (SLIs) for critical services. \n \nSecurity Automation: \n \nDevelop and maintain security automation scripts and tools to streamline security operations tasks. Integrate security testing tools into the CI/CD pipeline for automated vulnerability scanning. \n \nCollaboration with Development Teams: Work closely with software development teams to understand application architecture and provide guidance on secure coding practices. Conduct regular security reviews of code and architecture. \n \nThreat Modeling: \n \nPerform threat modeling exercises to identify and address potential security risks in applications and infrastructure. \n \nProvide recommendations for mitigating identified threats. \n \nSecurity Awareness and Training: \n \nPromote security awareness and provide training to development and operations teams on secure coding and operational practices. \n \nStay informed about the latest security threats and trends. \n \nQualifications: \n \nBachelor s degree in Computer Science, Information Security, or a related field. Relevant industry certifications such as CISSP, AWS Certified Security, or Certified Kubernetes Security Specialist (CKS). Skills: Expertise in security best practices and methodologies. \n \nHands-on experience with security tools and technologies. Strong problem-solving and analytical skills. \n \nThanks & \n \nShankar,  US IT Recruiter \n \nChabezTech LLC | \n \n4 Lemoyne Dr #102, Lemoyne, PA 17043, USA \n \nEmail:  shankar | www. \n \nContact: +1 \n",
            "dateupdated": 1723654514
        },
        {
            "id": "f092b592-1d5a-42c2-98a2-2b30371b08d7",
            "title": ".net Architect",
            "location": "San Ramon, California, USA",
            "company": "Ace Technologies, Inc.",
            "description": "We are looking for a .Net Arch who is a hands-on arch/delivery lead with good communication. They should have experience in building UI-based applications (React/Angular), Winforms/WCF on Azure Cloud - and must have AWM (Asset Wealth Management)/Financial Services experience. \n \nWe need a solid .NET Architect with experience in building UI-based applications (React/Angular), Winforms/WCF on Azure Cloud. \n \nMust have played a role of Sr. Architect \n \nMust have a solid communication to collaboratively drive building \n \nTarget Architecture of the application \n \nTech Leadership across Client Teams \n \nBuild a tech roadmap for the product \n \nProvide Tech Leadership to the implementation team for migration of client's on-prem EWS application to cloudAWM experience required \n",
            "dateupdated": 1723656329
        },
        {
            "id": "f2b99b0c-0231-4765-aed5-0166ae51bdda",
            "title": "Business Intelligence (Advanced Analytics Developer)/ Azure Cloud Engineer - Locals Only",
            "location": "San Francisco, California, USA",
            "company": "Serenity Info Tech, Inc.",
            "description": "IT - Business Intelligence (Advanced Analytics Developer) \n \nLocation: San Francisco, CA - Onsite \n \nJD: \n \nProvides development leadership and expertise for advanced BI analysis and analytics. Guides and moves forward an advanced BI/Data Mart system providing sophisticated and measurable business benefits. Drives data, ETL and system architecture and development. Owns the advanced analytics data environment to ensure that the data refresh from various sources, to facilitate research, is happening at regular intervals. Supports a group of multi-disciplinary data professionals and analysts. Drives development (coding using PL/SQL, Perl or any other scripting language, ad-hoc queries using SQL). Ensures that the data infrastructure can scale to meet defined performance, load, and functional objectives Effectively manages the execution of parallel projects of varying scope and duration. Responsible for all database objects including tables, indices, triggers, views, sequences, packages, and procedures. Works with Systems and Database Administration for infrastructure needs related to support, storage, backups, monitoring, performance bottlenecks. Participates with applications development and quality assurance in the management of application releases. Advises senior management on best practices concerning web analytics, data warehousing, data architecture, and data development. Works with business intelligence and other source system owners to build data refresh plan for research environment. Owns web click stream data collection and supports product managers to implement best practices for data definition. Supports project management and documentation needs of the group. \n \nSkill Set: \n \nExperience with Oracle 8i, 9i and 10g including PL/SQL, SQL loader, external tables, partitioning and performance tuning. Strong knowledge of Oracle data structures, data dictionary, and RDBMS structures. Experience as data architect and/or DW/BI architecture. Experience in database design and administration, strong in performance tuning, software installation, scripting, PL/SQL coding, backup & recovery process. At least 2 medium to large scale DW/BI project implementation experience. Experience working with DW/BI environment to be able understand the concepts of STAR, data cleansing, transformation and aggregations. 4+ years, current, development experience and inclination towards development. 1+ years experience with web analytics products like web trends, NetTracker, Omniture etc.. Experience working in an environment that has come across customer integration issues or has addressed it using MDM. Ability to express business and technical concepts clearly and concisely both verbally and in writing. Aggressive approach to staying current with developments within the internet world, related web analytics & data management. Experience working in a team-oriented, collaborative environment. Good to Have Skills: Experience working with various business applications like campaign management, CRM, ERP. Experience with Java scripts or any other web front end scripting. Experience with column oriented database solutions such as HBase or Infobright. Experience with Hadoop. Oracle database administration experience. Experience working with various data reporting tools like Business Objects, MicroStrategy, COGNOS. Experience working with ETL tools like Data Stage, Informatica, Hummingbird. Experience working with meta data management. Experience with SAS. \n \nThanks & Regards, \n \nMansi Jain \n",
            "dateupdated": 1723670823
        },
        {
            "id": "f3763ca5-3667-448c-9daf-b22783d15e67",
            "title": "AWS Cloud Developer-hybrid in GA",
            "location": "Atlanta, Georgia, USA",
            "company": "NovaLink Solutions",
            "description": "As an AWS Cloud Developer, you will play a crucial role in designing, developing, and maintaining scalable native cloud software applications on the AWS platform. \n \nProject Overview: \n \nThe CJEP project is a modernization of the Criminal Justice Exchange Program that shares data between different agencies, counties, cities, etc.  This project will take the current SoftwareAG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API s and web services will be leveraged to facilitate this modernized solution as much as possible. \n \nPosition Overview: \n \nAs an AWS Cloud Developer you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services, custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nRequirements \n \nSkill \n \nRequired / Desired \n \nAmount \n \nof Experience \n \nProven experience developing cloud application software \n \nRequired \n \n8 \n \nYears \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nRequired \n \n5 \n \nYears \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nRequired \n \n5 \n \nYears \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nRequired \n \n5 \n \nYears \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nRequired \n \n5 \n \nYears \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nRequired \n \n5 \n \nYears \n \nAgile methodologies and SCRUM framework \n \nRequired \n \n3 \n \nYears \n \nExperience with CI/CD pipelines and DevOps practices \n \nHighly desired \n \nExperience with containerization (e.g., Docker) and orchestration (e.g., Kubernetes) \n \nHighly desired \n \nAWS certifications (e.g., AWS Certified Developer) \n \nHighly desired \n",
            "dateupdated": 1723731902
        },
        {
            "id": "f5c21978-f9fa-4d7a-8a6a-70ff47379b7f",
            "title": "AWS Cloud Developer",
            "location": "Atlanta, Georgia, USA",
            "company": "Qlogic LLC New York",
            "description": "Role: AWS Cloud Developer \n \nLocation: Atlanta, GA \n \nDuration: 12 months \n \nVisa: Any \n \nAs an AWS Cloud Developer at GTA you will play a crucial role in designing, developing, and maintaining scalable native cloud software applications on the AWS platform. \n \nCandidates must have experience developing software applications in an  AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nProject Overview: \n \nThe GTA CJEP project is a modernization of the Criminal Justice Exchange Program that shares data between different agencies, counties, cities, etc.  This project will take the current SoftwareAG centric solution and produce a Cloud Native solution in AWS to move and consolidate data for counties that sign-up for the service.  The touchpoints for this data sharing will be third party vendors as well as state and county systems.  Current API s and web services will be leveraged to facilitate this modernized solution as much as possible. \n \nPosition Overview: \n \nAs an AWS Cloud Developer at GTA you will play a crucial role in designing, developing, and maintaining scalable cloud solutions on the AWS platform. You will collaborate closely with cross-functional teams in a SCRUM Agile environment to deliver high-quality software solutions that meet business objectives. The ideal candidate will have extensive experience with SOAP-based web services,custom header implementation, and handling MTOM (Message Transmission Optimization Mechanism) attachments \n \nKey Responsibilities: \n \nDesign, develop, and deploy cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3, and others as needed. \n \nImplement serverless architectures using AWS Lambda functions with Python. \n \nBuild and orchestrate workflows using AWS Step Functions and AWS State Machines. \n \nDesign, develop, and implement SOAP-based web services using services technologies. \n \nCreate and manage custom headers for web services to ensure security, authentication, and data integrity. \n \nImplement MTOM attachments such as PDF for efficient transmission of binary data in web services. \n \nCollaborate with Product Owners, Scrum Masters, and other team members to refine user stories and deliver solutions iteratively. \n \nEnsure code quality, performance, and scalability through automated testing, code reviews, and adherence to best practices. \n \nTroubleshoot and resolve issues in development, testing, and production environments. \n \nStay current with AWS services, tools, and best practices and share your knowledge within the team. \n \nQualifications: \n \nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience). \n \nProven experience with XML, XSD, WSDL, and other related technologies \n \nProven experience as a software developer with a strong understanding of cloud computing principles and practices. \n \nHands-on experience designing and developing applications on AWS cloud services, particularly Lambda, API Gateway, DynamoDB, and S3. \n \nProficiency in Python programming language; familiarity with other languages is a plus. \n \nExperience with AWS Step Functions and State Machines is highly desirable. \n \nFamiliarity with Agile methodologies and SCRUM framework. \n \nStrong problem-solving skills and ability to work effectively in a team environment. \n \nExcellent verbal and written communication skills. \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n",
            "dateupdated": 1723733520
        },
        {
            "id": "f8cb8573-99da-4ae6-907c-d7eb418bf510",
            "title": "Aws Cloud Native Software Application Developer",
            "location": "Atlanta, Georgia, USA",
            "company": "22nd Century Technologies, Inc.",
            "description": "Job Title: \n \nAws Cloud Native Software Application Developer \n \nLocation with zip code: \n \nAtlanta, GA \n \nDuration: \n \n10 Months \n \nNote: \n \nCandidates must have experience developing software applications in an AWS Cloud environment. \n \nThis is NOT a DevOps or Cloud Engineer position. \n \nRequired Experience: \n \nProven experience developing cloud application software \n \nWork experience designing, developing, and deploying cloud-native applications on AWS using services such as Lambda, API Gateway, DynamoDB, S3 \n \nWork experience Implementing serverless architectures using AWS Lambda functions with Python \n \nWork experience building and orchestrate workflows using AWS Step Functions and AWS State Machines \n \nWork experience designing, developing, and implementing SOAP-based web services using services technologies \n \nWork experience with XML, XSD, WSDL, and other related technologies \n \nAgile methodologies and SCRUM framework \n \nPreferred Qualifications: \n \nAWS certifications (e.g., AWS Certified Developer) are a plus. \n \nExperience with CI/CD pipelines and DevOps practices. \n \nFamiliarity with containerization (e.g., Docker) and orchestration (e.g., Kubernetes). \n \nAbout our Company: - \n \n22nd Century Technologies, Inc., is one of the fastest growing IT Service Integrator and Workforce Solution companies in the United States. Founded in 1997, 22nd Century Technologies is a Certified National Minority Business Enterprise with 6,000+ people including 600+ Cyber SMEs nationwide supporting our customers in all 50 states, Canada, and Mexico. With HQs in Somerset, NJ and Mclean, VA, 22nd Century has 14 offices throughout the United States. As part of our unrelenting focus on quality and compliance, 22nd Century Technologies  delivery is based on Certified Matured Processes including CMMI L3 Dev & SVC, ISO 20000, ISO 27001, and ISO 9001 quality processes. With a strong focus on the public sector, 22nd Century currently holds government contracts with 14 out of 15 Federal Executive agencies including DoD, 37 other Federal agencies, 50 States, 115+ Local agencies, and 37 School Districts. In the last three years, we have expanded our services to Fortune 500 and other commercial clients and currently support 80+ commercial clients. \n \nRecognized among \n \nBest Company to Work For  by Forbes, 22nd Century Technologies, Inc., \n \nconsistently exceeds our clients  expectations by focusing on their absolute satisfaction with jobs while keeping our employees motivated. \n \n22nd Century Technologies is an Equal Opportunity Employer\" and  s & all other parties authorized to work in the US are encouraged to apply.\" \n \nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. \n",
            "dateupdated": 1723738283
        },
        {
            "id": "fb530c88-e2f5-4e3e-9482-152d35f031b9",
            "title": "senior system engineer",
            "location": "New York, New York, USA",
            "company": "Hirex",
            "description": "SENIOR SYSTEM ENGINEER  WITH VMWARE EXPERIENCE \n \n5 DAY ONSITE IN BROOKLYN, NY \n \n12 MONTHS CONTRACT \n \nNEED 13 YEARS OF EXP MUST HAVE HANDS ON EXPEREICNE WITH VMWARE \n \nTASKS: \n \n- Providing implementation services for the VMware VCF Software suite of tools (SDDC, vSphere, vSAN, NSX-T, Aria) \n \n- Configure T L4/L7 Distributed Firewall rules and IDS/IPS functionality \n \n- Configure NSX-T Advanced Local and Global Load balancer \n \n- Implement Software updates and security patches to the VCF environment. \n \n- Administer and support the following technologies. \n \nVMware NSX-T Datacenter 3.1.3/3.2.x \n \nMANDATORY SKILLS/EXPERIENCE : \n \nMinimum 8 years of hands-on experience in software designed network technologies. \n \nAbility to work independently. \n \nBGP peering between NSX-T and Cisco ACI. \n \nNSX-T Distributed and Gateway Firewalls T1/SR with App ID based Layer7 Firewall rules. \n \nAvi Global (DNS) and Local load balancing, with detailed understanding of various loadbalanced methods and layer7 monitoring of pools for SNAT VIPs. \n \nUnderstanding of VxLAN/Geneve based Federated stretch NSX-T segments. \n \nMust have the ability to understand VMware ESXi vSphere/vCenter 7.x/8.x NSX-T VDS T1/T0 Segments. \n \nUnderstanding of VCF Cloud foundation, supporting an on-premises cloud solution with NSX- T extensions into AWS and Azure. \n \nThe engineer will be required to implement Workspace One/Horizon VDI solution integrated Azure AD and NSX-T identity-based Firewalling. \n \nStrong understanding of IP/IPv6 based networks, subnetting, and advanced routing protocols is required. \n \nUnderstanding of configuring, and administering VMWare IT server, networking and SAN storage solutions. \n \nUnderstanding of hyper converged infrastructure and vSAN technology. \n \nUnderstanding of Automation: Python, Terraform and Ansible pipelines. \n \nProficient in Microsoft Visio \n \nDetailed understanding of the following protocols and compliance: \n \nBGP \n \nNSX-T Geneve \n \nDNS \n \nCertificate Authority Service \n \nAzure AD Services and IDP solutions \n \nMicrosoft Active Directory \n \nIpv4 and IPv6 protocols \n \nSecurity Frameworks: NIST800-53 R4, PCI DSS 3.2.1, IRS Pub1075 \n \nCertification Preffered \n \nVMware Certified Advanced Professional - Network Virtualization Design 2023 \n \nDESIRABLE SKILLS/EXPERIENCE: \n \nKnowledge of Aria suite of products including vROPs, vCenters, VRA, and Log Insight. Knowledge of VMware Horizon. \n \nCisco CCNP Enterprise   Preferred \n \nVMware Certified Design Expert - Network Virtualization 2023   Preferred \n",
            "dateupdated": 1723669076
        },
        {
            "id": "fb591816-408a-4c20-89a7-a115acf4d389",
            "title": "Systems Analyst - RHEL (Texas candidates only)",
            "location": "Remote",
            "company": "Daman Consulting",
            "description": "Job Title \n \n: Systems Analyst \n \nLocation \n \n: Remote (Any location within the State of Texas). \n \nRole type : \n \n12-Month Contracts (High chances of extension) \n \nJob Description \n \nUnderstands business objectives and problems, identifies alternative solutions, and performs studies and cost/benefit analysis of alternatives. Analyzes user requirements, procedures, and problems to automate processing or to improve existing computer systems: Confers with personnel of organizational units involved to analyze current operational procedures, identify problems, and learn specific input and output requirements, such as forms of data input, how data is to be; summarized, and formats for reports. Writes detailed descriptions of user needs, program functions, and steps required to develop or modify computer programs. Review computer system capabilities, specifications, and scheduling limitations to determine if the requested program or program change is possible within the existing system. \n \nRequirement \n \nInstall, deploy, configure, and administrate WebSphere ND clusters/cells on Red Hat Enterprise Linux; with upgrades, patches, and fixes as required by project deadlines. \n \nExperience tuning large complex Java based web applications in a Service Oriented Architecture. \n \nExperience troubleshooting large complex Java based web applications in a Service Oriented Architecture. \n \nKnowledge and application of DevOps and CI/CD methodologies; with experience automating one or more stages of the DevOps infinity loop model. \n \nExperience creating pipelines in Jenkins to automate WebSphere Application Server configurations. \n \nExperience creating Red Hat Ansible Platform playbooks to automate WebSphere Application Server installations and deployments. \n \nExperience with different scripting methodologies - UNIX, Jython, YAML, JSON \n \nKnowledgeable of Java and all phases of the SDLC (Systems Development Life Cycle). \n \nUse of Application Performance Management tools such as DynaTrace and Splunk \n",
            "dateupdated": 1723652751
        },
        {
            "id": "fc9a51d6-4520-4827-ad4b-b8517401e0fa",
            "title": "Devops Engineer (Google Cloud Platform Certification is Must)",
            "location": "Concord, California, USA",
            "company": "Resourcesys",
            "description": "Devops Engineer  (Google Cloud Platform Certification is Must) \n \nLocation: Concord, CA & Charlotte, NC \n \nGoogle Cloud Platform Certification is Must \n \nLead complex technology Cloud initiatives, including those that are companywide, with broad impact \n \nAct as a key contributor in automating the provisioning of Cloud Infrastructure using Infrastructure as Code (IaC) \n \nMake decisions in developing standards and best practices for engineering and large-scale technology solutions \n \nDesign, optimize, and document the engineering aspects of the Cloud platform \n \nLead and share understanding of industry best practices and how new technologies influence the Cloud technology team to meet deliverables and drive new initiatives \n \nReview and analyze complex, large-scale technology solutions in Cloud for strategic business objectives and solving technical challenges that require in-depth evaluation of multiple parameters, including intangibles or unprecedented technical factors \n \nCollaborate and consult with key technical experts, senior technology team, and external industry groups to resolve complex technical issues and achieve goals \n \nBuild and enable Cloud infrastructure, automate the orchestration for Google Cloud Platform for Wells Fargo Enterprise \n \nWork in a globally distributed team and provide innovative and robust Cloud centric solutions \n \nClosely work with Product Team and vendors to develop and deploy Cloud services to meet customer expectations \n \nCollaborate with architects, developers, and operations teams to ensure seamless integration and delivery of cloud-based systems \n \nGather and analyze data to diagnose the root cause of Cloud issues, recommend and implement solutions to resolve issues in timely manner \n \nRequired Qualifications: \n \n5+ years of Software Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education \n \n3+ years working with Google Cloud Platform (Google Cloud Platform) and a proven track record of building complex infrastructure programmatically with Infrastructure as Code (IaC) tools \n \n2+ years of hands-on experience with IaC tools Terraform and GitHub \n \nStrong understanding of Google Cloud Platform networking services, such as Virtual Private Cloud (VPC), Cloud Virtual Private Network (VPN), Cloud Interconnect, Virtual Network (Vnet) and Cloud Load Balancing \n \nKnowledge and understanding of Cloud service offerings such as Data, Analytics, AI/ML on Google Cloud Platform \n \nDemonstrated experience on at least three of the following key services: Big Query, Composer, Vertex AI, Document AI, Agent Builder, DataProc, Data Catalog, Notebook \n \nIn-depth knowledge of network protocols, security, and compliance standards \n \nExperience with scripting and automation tools for network provisioning and configuration \n \nKnowledge and understanding of Cloud service offerings on Security, Data Protection and Security policy implementations \n \nBasic understanding of Cloud computing concepts like landing zone and Blueprints \n \nDesired Qualifications: \n \nCloud certification on Google Cloud Platform \n \nExposure to Cloud governance and logging/monitoring tools \n \nExperience with Agile, CI/CD, DevOps concepts and Site Reliability Engineer (SRE) principles \n \nProficient on container-based solution services, have handled 2-3 large scale Kubernetes based infrastructure build out, provisioning of services in Azure or Google Cloud Platform \n \nExperience in scripting (Shell, Python) \n \nGood understanding of networking, firewalls, load balancing concepts (IP, DNS, Guardrails, Vnets) and exposure to database, cloud security, AD, authentication methods, RBAC \n \nExcellent verbal, written, and interpersonal communication skills \n \nAbility to articulate technical solutions to both technical and business audiences \n \nAbility to deliver & engage with partners effectively in a multi-cultural environment by demonstrating co-ownership & accountability in a matrix structure \n \nDelivery focus and willingness to work in a fast-paced, enterprise  environment \n \nEmail: \n",
            "dateupdated": 1723733145
        },
        {
            "id": "ffeedfe6-bbee-40a0-a187-6f2b5bde5052",
            "title": "Sr. Azure Data Engineer/Lead/Architect",
            "location": "Remote",
            "company": "Long Finch Technologies",
            "description": "Azure Data Engineer \n \nLocation-Fremont, CA / Remote \n \nJob Type-Long Term \n \nSQL, Python, Pyspark, Azure Synapse, Databricks, ADLS/ADF, Data Modeling, Design and Architecture \n \nMust have Skills : \n \nMin 5 years of experience in modern data engineering/data warehousing/data lakes technologies on cloud platforms like \n \nAzure, AWS, Google Cloud Platform, Data Bricks etc. Azure experience is preferred over other cloud platforms. \n \n10 + years of \n \nproven experience with \n \nSQL, schema design and dimensional data modelling. Hands on experience in SQL is a MUST. \n \nSolid knowledge of data warehouse best practices, development standards and methodologies \n \nHands on experience with \n \nETL/ELT tools like ADF, Informatica , Talend etc., and data warehousing technologies like Azure Synapse, Azure SQL, Amazon redshift , Snowflake , Google Big Query etc.. \n \nStrong experience with \n \nbig data tools(Databricks , Spark etc..) and programming skills in PySpark and Spark SQL. \n \nBe an independent self-learner with   let s get this done  approach and ability to work in Fast paced and Dynamic environment. \n \nExcellent communication and teamwork abilities. \n \nNice-to-Have Skills: \n \nEvent Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service,  Cosmo DB knowledge. \n \nSAP ECC /S/4 and Hana knowledge. \n \nIntermediate knowledge on Power BI \n \nAzure DevOps and CI/CD deployments, Cloud migration methodologies and processe \n",
            "dateupdated": 1723647925
        }
    ],
    "resumeList": [
        {
            "resumeid": "1723586578999306174",
            "resumename": "AWS Utsav Chaudhary Resume.docx.pdf",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "resumeid": "1723586585506819698",
            "resumename": "GCP Utsav Chaudhary Resume.pdf",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "resumeid": "1723586591906099998",
            "resumename": "Azure Utsav Chaudhary Resume.pdf",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "resumeid": "1723603544029857920",
            "resumename": "2023-fall-project0.pdf",
            "email": "keerthanat190@gmail.com"
        },
        {
            "resumeid": "1723649450709869672",
            "resumename": "Utsav Chaudhary Resume.pdf",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "resumeid": "1723649467858186752",
            "resumename": "ML-DevOps Utsav Chaudhary Resume.pdf",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "resumeid": "172365841217201568",
            "resumename": "Sandhya Samudrala.pdf",
            "email": "sandhyasamudrala24@gmail.com"
        },
        {
            "resumeid": "1723668795340557420",
            "resumename": "Python Utsav Chaudhary Resume.pdf",
            "email": "sample1test.it2@gmail.com"
        }
    ],
    "applyQueue": [
        {
            "jobid": "f5c21978-f9fa-4d7a-8a6a-70ff47379b7f",
            "timeofarrival": 1723738978,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "jobid": "e8406fb4-482d-4158-93db-0e8008a6d5a3",
            "timeofarrival": 1723739019,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "jobid": "3d5b7004-9f14-4dbd-82cc-92a9e90b85fc",
            "timeofarrival": 1723739046,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "jobid": "85e395b9-a1b3-4a99-9691-c7daccf51509",
            "timeofarrival": 1723739078,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "jobid": "25f00191-ee8e-4c2f-8f7e-010d0af841d8",
            "timeofarrival": 1723739088,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        },
        {
            "jobid": "e1f2c6b4-f8a5-4569-84fe-4d74b217c5d2",
            "timeofarrival": 1723739154,
            "selectedresume": "1723586578999306174",
            "email": "utsav28.devops@gmail.com"
        }
    ],
    "scoreBoard": []
}